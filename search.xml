<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据结构-6-图]]></title>
    <url>%2F2019%2F04%2F22%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-6-%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[实现邻接矩阵表示图邻接矩阵实现有向图、无向图、有权图、无权图的邻接矩阵表示方法 实现邻接表表示图实现有向图、无向图、有权图、无权图的邻接表表示方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# coding:utf-8# 邻接表：使用列表实现邻接表。# 构建邻接表n, m = map(int, input().split()) # 顶点数和边数u = [0 for i in range(m + 1)]v = [0 for i in range(m + 1)]w = [0 for i in range(m + 1)]first = [-1 for i in range(n + 1)]nex = [0 for i in range(m + 1)]for i in range(1, m + 1): # 读入边 u[i], v[i], w[i] = map(int, input().split()) nex[i] = first[u[i]] first[u[i]] = iprint(first[1:], nex[1:])# 遍历每个顶点的边for i in range(1, n + 1): k = first[i] while k != -1: print(u[k], v[k], w[k]) k = nex[k]'''input：4 51 4 94 3 81 2 52 4 61 3 7output:[5, 4, -1, 2] [-1, -1, 1, -1, 3]1 3 71 2 51 4 92 4 64 3 8'''# first中，1号顶点的第一条边是编号为5的边（即1 3 7）# next中，1号顶点，编号为5的边的下一条边编号为3（1 2 5），然后是1 4 9# 即找到1号顶点的一条边后，剩下的边都可以在next数组中找到# k=first[1]# while k!=-1:# print u[k],v[k],w[k]# k=next[k]# 每个顶点都设置了一个链表，保存了从顶底i出发的所有边的序号。# 用邻接表存储图的时间复杂度是O(M)，遍历每条边的时间复杂度也是O(M)# 如果一个图是稀疏图的话，M要远小于N^2。因此稀疏图用邻接表存储更合适。 实现图的深度优先搜索代码入下 1234567891011121314151617181920212223242526272829303132333435from collections import defaultdictclass Graph: def __init__(self): self.graph = defaultdict(list) # 使用&#123;v:[],v:[]&#125;表示 def add_edge(self, u, v): self.graph[u].append(v) def dfs_node(self, v, visited): visited[v] = True # 当前访问的标记为True print(v, end=" ") for i in self.graph[v]: if visited[i] == False: self.dfs_node(i, visited) def dfs(self): visited = [False] * (len(self.graph)) # visited中所有节点初始化为False for i in range(len(self.graph)): if visited[i] == False: self.dfs_node(i, visited)g = Graph()g.add_edge(0, 1)g.add_edge(0, 2)g.add_edge(1, 2)g.add_edge(2, 0)g.add_edge(2, 3)g.add_edge(3, 3)g.dfs()# 0 1 2 3 实现图的广度优先搜索实现 Dijkstra 算法、A* 算法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# coding:utf-8# Dijkstra算法：单源最短路径。求顶点1到其他顶点的最短路径。n,m=map(int,raw_input().split())inf=999999e=[[inf for i in range(n+1)] for i in range(n+1)]for i in range(n): e[i+1][i+1]=0for i in range(m): a,b,c=map(int,raw_input().split()) e[a][b]=cdis=[0 for i in range(n+1)]for i in range(1,n+1): #初始化dis列表 dis[i]=e[1][i]book=[0 for i in range(n+1)]book[1]=1for i in range(1,n+1): mi=inf #找到离1号顶点距离最近的点 for j in range(1,n+1): if book[j]==0 and dis[j]&lt;mi: mi=dis[j] u=j book[u]=1 for v in range(1,n+1): if e[u][v]&lt;inf and dis[v]&gt;dis[u]+e[u][v]: dis[v]=dis[u]+e[u][v]for i in range(1,n+1): print dis[i],'''input：6 91 2 11 3 122 3 92 4 33 5 54 3 44 5 134 6 155 6 4output:0 1 8 4 13 17'''# 用邻接矩阵存，时间复杂度O(N^2)，不能有负权边。# 基于贪心策略，每次扩展路径最短的点，更新与其相邻的点的路程。# M远小于N^2的图称为稀疏图，而M相对较大的图称为稠密图# 对于变数M少于N^2的稀疏图来说，用邻接表代替邻接矩阵，时间复杂度O(M+N)logN# M在最坏情况下是N^2，复杂度比邻接矩阵大。 实现拓扑排序的 Kahn 算法、DFS 算法对应的 LeetCode 练习题Number of Islands（岛屿的个数）英文版：https://leetcode.com/problems/number-of-islands/description/ 中文版：https://leetcode-cn.com/problems/number-of-islands/description/ Valid Sudoku（有效的数独）英文版：https://leetcode.com/problems/valid-sudoku/ 中文版：https://leetcode-cn.com/problems/valid-sudoku/]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-5-二叉树、堆]]></title>
    <url>%2F2019%2F04%2F19%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-5-%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%81%E5%A0%86%2F</url>
    <content type="text"><![CDATA[二叉树介绍：二叉搜索树 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129# coding: utf-8class Node(object): def __init__(self, val): self.left = None self.right = None self.val = valclass BST(object): def __init__(self): self.root = None # 插入 def insert(self, val): if self.root is None: self.root = Node(val) else: self.insert_node(self.root, val) def insert_node(self, current_node, val): if val &lt; current_node.val: if current_node.left is None: current_node.left = Node(val) else: self.insert_node(current_node.left, val) else: if current_node.right is None: current_node.right = Node(val) else: self.insert_node(current_node.right, val) # 查找 def find(self, val): if self.root is None: print("树为空，返回False") return False self.find_node(self.root, val) def find_node(self, node, val): if node is None: print("未找到，返回False") return False if val == node.val: print("找到了，返回True") return True elif val &lt; node.val: self.find_node(node.left, val) else: self.find_node(node.right, val) # 查找某个节点的前驱 def find_left_node(self, node): return node.left # 查找某个节点的后继 def find_right_node(self, node): return node.right # 前序遍历：中 左 右 def pre_order(self): print("=========前序遍历=========") if self.root is None: return self.pre_order_node(self.root) def pre_order_node(self, node): if node is None: return print(node.val) self.pre_order_node(node.left) self.pre_order_node(node.right) # 中序遍历：左 中 右 def in_order(self): print("=========中序遍历=========") if self.root is None: return self.in_order_node(self.root) def in_order_node(self, node): if node is None: return self.in_order_node(node.left) print(node.val) self.in_order_node(node.right) # 后序遍历：左 右 中 def post_order(self): print("=========后序遍历=========") if self.root is None: return self.post_order_node(self.root) def post_order_node(self, node): if node is None: return self.post_order_node(node.left) self.post_order_node(node.right) print(node.val) # 按层遍历 # 借助队列：将二叉树的节点加入队列，出队的同时将其非空左右孩子依次入队，出队到队列为空即完成遍历 def breadth_first(self): print("=========按层遍历=========") if self.root is None: return self.breadth_first_node(self.root) def breadth_first_node(self, node): queue = [node] while node and len(queue) != 0: print(queue[0].val) if queue[0].left is not None: queue.append(queue[0].left) if queue[0].right is not None: queue.append(queue[0].right) queue.pop(0)bst = BST()bst.find(3)bst.insert(7)bst.insert(1)bst.find(4)bst.insert(5)bst.pre_order()bst.in_order()bst.post_order()bst.breadth_first() 堆介绍：堆 支持的基本操作 操作 描述 时间复杂度 build 创建一个空堆 {\displaystyle O(n)} insert 向堆中插入一个新元素 {\displaystyle O(\log n)} update 将新元素提升使其匹配堆的性质 get 获取当前堆顶元素的值 {\displaystyle O(1)} delete 删除堆顶元素 {\displaystyle O(\log n)} heapify 使删除堆顶元素的堆再次成为堆 小顶堆及排序使用list模拟 根节点位置：根节点的数据总是在数组的位置[0] 节点的父节点位置：假设一个非根节点的数据在数组中的位置[i]，那么它的父节点总是在位置[(i-1)/2] 节点的孩子节点位置：假设一个节点的数据在数组中的位置为[i]，那么它的孩子（如果有）总是在下面的这两个位置：左孩子在[2i+1]，右孩子在[2i+2] 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364# coding:utf-8# 堆与最小堆排序：从小到大排序。节点编号从1开始。# 向下调整，每次跟孩子中较小的那个值交换def siftdown(i): #i为要调整的节点的编号 while i*2&lt;=n: #要调整的节点至少有左孩子 temp=i*2 if h[i*2]&lt;h[i] else i #temp标记值最小的节点编号 if i*2+1&lt;=n and h[i*2+1]&lt;h[temp]: temp=i*2+1 if temp!=i: h[i],h[temp]=h[temp],h[i] i=temp else: break #已经是堆，不需要调整# 向上调整，每次跟父节点比较def siftup(i): while i/2&gt;0: if h[i]&lt;h[i/2]: h[i],h[i/2]=h[i/2],h[i] i=i/2 else: break# 创建堆：调整二叉树中的节点，从n/2节点开始def creat(): for i in range(1,n/2+1)[::-1]: siftdown(i) # 删除顶部元素，尾部元素放到顶部调整，堆大小-1def deletetop(): global n temp=h[1] h[1]=h[n] n-=1 siftdown(1) return tempnum=int(raw_input()) h=map(int,raw_input().split()) #放入完全二叉树h.insert(0,0) #为了方便计算，输入值从1开始编号n=numcreat() #创建堆print h# 排序，每次删除顶部（最小），将尾部的元素放到顶部，向下调整for i in range(num): print deletetop(),'''input：1499 5 36 7 22 17 46 12 2 19 25 28 1 92output:[0, 1, 2, 17, 5, 19, 28, 46, 12, 7, 22, 25, 99, 36, 92]1 2 5 7 12 17 19 22 25 28 36 46 92 99每次删除最小，插入一个数再删除最小：删除堆顶，将元素插入堆顶向下调整。每次增加一个元素：插入末尾，向上调整。建立堆：1.每次siftup,O(NlogN)；2.放入一个完全二叉树再调整,O(N)堆排序：O(NlogN)，和快排一样''' 大顶堆及排序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# coding:utf-8# 最大堆排序：从小到大排序。节点编号从1开始。# 向下调整，每次跟孩子中较小的那个值交换def siftdown(i): #i为要调整的节点的编号 while i*2&lt;=n: #要调整的节点至少有左孩子 temp=i*2 if h[i*2]&gt;h[i] else i #temp标记值最小的节点编号 if i*2+1&lt;=n and h[i*2+1]&gt;h[temp]: temp=i*2+1 if temp!=i: h[i],h[temp]=h[temp],h[i] i=temp else: break #已经是堆，不需要调整# 创建堆：调整二叉树中的节点，从n/2节点开始def creat(): for i in range(1,n/2+1)[::-1]: siftdown(i) # 每次将最大的（堆顶）调整到最后，堆大小-1def heapsort(): global n for i in range(num-1): h[1],h[n]=h[n],h[1] n-=1 siftdown(1)num=int(raw_input()) h=map(int,raw_input().split()) #放入完全二叉树h.insert(0,0) #为了方便计算，输入值从1开始编号n=numcreat() #创建堆print hheapsort()print h[1:]'''input：1499 5 36 7 22 17 46 12 2 19 25 28 1 92output:[0, 99, 25, 92, 12, 22, 28, 46, 7, 2, 19, 5, 17, 1, 36][1, 2, 5, 7, 12, 17, 19, 22, 25, 28, 36, 46, 92, 99]''' 优先级队列 优先级队列和通常的栈和队列一样，只不过里面的每一个元素都有一个”优先级”，在处理的时候，首先处理优先级最高的。如果两个元素具有相同的优先级，则按照他们插入到队列中的先后顺序处理。 优先级队列可以通过链表，数组，堆或者其他数据结构实现。 · 如果使用无序数组，那么每一次插入的时候，直接在数组末尾插入即可，时间复杂度为O(1)，但是如果要获取最大值，或者最小值返回的话，则需要进行查找，这时时间复杂度为O(n)。 · 如果使用有序数组，那么每一次插入的时候，通过插入排序将元素放到正确的位置，时间复杂度为O(n)，但是如果要获取最大值的话，由于元阿苏已经有序，直接返回数组末尾的 元素即可，所以时间复杂度为O(1). 所以采用普通的数组或者链表实现，无法使得插入和排序都达到比较好的时间复杂度。所以我们需要采用新的数据结构来实现。下面就开始介绍如何采用二叉堆(binary heap)来实现优先级队列 参考：浅谈算法和数据结构: 五 优先级队列与堆排序 利用优先级队列合并 K 个有序数组求一组动态数据集合的最大 Top K对应的 LeetCode 练习题Invert Binary Tree（翻转二叉树） 英文版：https://leetcode.com/problems/invert-binary-tree/ 中文版：https://leetcode-cn.com/problems/invert-binary-tree/ Maximum Depth of Binary Tree（二叉树的最大深度） 英文版：https://leetcode.com/problems/maximum-depth-of-binary-tree/ 中文版：https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/ Validate Binary Search Tree（验证二叉查找树） 英文版：https://leetcode.com/problems/validate-binary-search-tree/ 中文版：https://leetcode-cn.com/problems/validate-binary-search-tree/ Path Sum（路径总和） 英文版：https://leetcode.com/problems/path-sum/ 中文版：https://leetcode-cn.com/problems/path-sum/]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-4-散列表(哈希表)]]></title>
    <url>%2F2019%2F04%2F16%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-4-%E6%95%A3%E5%88%97%E8%A1%A8-%E5%93%88%E5%B8%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[散列表（哈希表）实现一个基于链表法解决冲突问题的散列表参考：https://www.cnblogs.com/linxiyue/p/3795396.html 1234567891011121314151617181920212223242526272829303132333435363738394041424344class _ListNode(object): def __init__(self,key): self.key=key self.next=Noneclass HashMap(object): def __init__(self,tableSize): self._table=[None]*tableSize self._n=0 #number of nodes in the map def __len__(self): return self._n def _hash(self,key): return abs(hash(key))%len(self._table) def __getitem__(self,key): j=self._hash(key) node=self._table[j] while node is not None and node.key!=key : node=node.next if node is None: raise KeyError,'KeyError'+repr(key) return node def insert(self,key): try: self[key] except KeyError: j=self._hash(key) node=self._table[j] self._table[j]=_ListNode(key) self._table[j].next=node self._n+=1 def __delitem__(self,key): j=self._hash(key) node=self._table[j] if node is not None: if node.key==key: self._table[j]=node.next self._-=1 else: while node.next!=None: pre=node node=node.next if node.key==key: pre.next=node.next self._n-=1 break 实现一个 LRU 缓存淘汰算法 LRU全称是Least Recently Used，即最近最久未使用的意思。 LRU算法的设计原则是：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小。也就是说，当限定的空间已存满数据时，应当把最久没有被访问到的数据淘汰。 使用dict和list实现比较自然的想法：使用dict存&lt;key,value&gt;，使用list记录访问顺序，索引[0,…,capacity-1]，越小表示访问时间越近，每次pop()删除最末尾的元素。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# coding: utf-8class LRUCache(object): def __init__(self, capacity): """ :type capacity: int """ self.capacity = capacity self.lru_cache = &#123;&#125; self.sort_list = [] # 访问顺序 def get(self, key): """ :type key: int :rtype: int """ if key in self.lru_cache: value = self.lru_cache[key] self.sort_list.remove(key) self.sort_list.insert(0, key) else: value = -1 print("get", key, ": ", self.lru_cache, self.sort_list) return value def put(self, key, value): """ :type key: int :type value: int :rtype: None """ if key in self.lru_cache: self.lru_cache[key] = value self.sort_list.remove(key) self.sort_list.insert(0, key) else: if len(self.sort_list) == self.capacity: last_key = self.sort_list.pop() self.lru_cache.pop(last_key) self.sort_list.insert(0, key) self.lru_cache[key] = value print("put &lt;", key, ":", value, "&gt;: ", self.lru_cache, self.sort_list)# Your LRUCache object will be instantiated and called as such:cache = LRUCache(2)cache.put(1, 1)cache.put(2, 2)print("get value is: ",cache.get(1))cache.put(3, 3)cache.put(4, 4)print("get value is: ",cache.get(1))print("get value is: ",cache.get(3))print("get value is: ",cache.get(5))"""put &lt; 1 : 1 &gt;: &#123;1: 1&#125; [1]put &lt; 2 : 2 &gt;: &#123;1: 1, 2: 2&#125; [2, 1]get 1 : &#123;1: 1, 2: 2&#125; [1, 2]get value is: 1put &lt; 3 : 3 &gt;: &#123;1: 1, 3: 3&#125; [3, 1]put &lt; 4 : 4 &gt;: &#123;3: 3, 4: 4&#125; [4, 3]get 1 : &#123;3: 3, 4: 4&#125; [4, 3]get value is: -1get 3 : &#123;3: 3, 4: 4&#125; [3, 4]get value is: 3get 5 : &#123;3: 3, 4: 4&#125; [3, 4]get value is: -1""" 对应的 LeetCode 练习题哈希表并完成leetcode上的两数之和(1)及Happy Number(202)！(要求全部用哈希思想实现！) leetcode-1-两数之和代码见：leetcode-1-两数之和 中”方法二”，使用dict记录当前元素下标和匹配的值 LeetCode-202-快乐数Happy Number使用dict记录求过的数 12345678910111213141516171819202122232425class Solution(object): def isHappy(self, n): """ :type n: int :rtype: bool """ m_dict = &#123;&#125; while n != 1: # print(n) n = sum(int(i) ** 2 for i in str(n)) if n in m_dict: return False m_dict[n] = 1 return True s = Solution() print(s.isHappy(19)) """ 19 82 68 100 True """]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-3-排序、二分查找]]></title>
    <url>%2F2019%2F04%2F14%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-3-%E6%8E%92%E5%BA%8F%E3%80%81%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[排序排序算法实现实现归并排序、快速排序、插入排序、冒泡排序、选择排序、堆排序代码见排序算法总结 编程实现 O(n) 时间复杂度内找到一组数据的第 K 大元素123456789101112131415161718192021222324252627282930313233def quicksort(num ,low ,high): #快速排序 if low&lt; high: location = partition(num, low, high) quicksort(num, low, location - 1) quicksort(num, location + 1, high) def partition(num, low, high): pivot = num[low] while (low &lt; high): while (low &lt; high and num[high] &gt; pivot): high -= 1 while (low &lt; high and num[low] &lt; pivot): low += 1 temp = num[low] num[low] = num[high] num[high] = temp num[low] = pivot return low def findkth(num,low,high,k): #找到数组里第k个数 index=partition(num,low,high) if index==k:return num[index] if index&lt;k: return findkth(num,index+1,high,k) else: return findkth(num,low,index-1,k) pai = [2,3,1,5,4,6]# quicksort(pai, 0, len(pai) - 1) print(findkth(pai,0,len(pai)-1,0)) leetcode-239-返回滑动窗口中的最大值涉及队列 123456789101112131415161718class Solution(object): def maxSlidingWindow(self, nums, k): """ :type nums: List[int] :type k: int :rtype: List[int] """ d = collections.deque() out = [] for i, n in enumerate(nums): while d and nums[d[-1]] &lt; n: d.pop() d += i, if d[0] == i - k: d.popleft() if i &gt;= k - 1: out += nums[d[0]], return out 二分查找实现一个有序数组的二分查找算法需注意边界，参考：二分查找学习札记 (写的很详细) 代码如下 12345678910111213141516171819# coding: utf-8def binary_search(sort_list, e): print(sort_list) left = 0 right = len(sort_list) - 1 while left &lt;= right: mid = (left + right) // 2 if sort_list[mid] &lt; e: left = mid + 1 elif sort_list[mid] &gt; e: right = mid - 1 else: return mid return -1print(binary_search([1, 3, 4, 9, 10], 3)) # 1print(binary_search([1, 3, 4, 9, 10], 0)) # -1print(binary_search([], 0)) # -1 实现模糊二分查找算法（比如大于等于给定值的第一个元素）代码如下 1234567891011121314151617181920def binary_search(sort_list, target): left = 0 right = len(sort_list) - 1 while left &lt;= right: mid = (left + right) // 2 if sort_list[mid] &lt; target: left = mid + 1 else: right = mid - 1 if left &gt; len(sort_list) - 1: # 如果数组中所有元素都小于target，left会越界 return -1 return leftprint(binary_search([1, 3, 4, 9, 10], 3)) # 1print(binary_search([1, 3, 3, 4, 9, 10], 3)) # 1print(binary_search([1, 3, 4, 9, 10], 5)) # 3print(binary_search([1, 3, 4, 9, 10], 10)) # 4print(binary_search([1, 3, 4, 9, 10], 11)) # -1print(binary_search([], 0)) # -1 二分查找变种模式如下： 12345678910def binary_search(sort_list, target): left = 0 right = len(sort_list) - 1 while left &lt;= right: # 如果取值范围是[left,right]，这里必须是 &lt;= mid = (left + right) // 2 if sort_list[mid] ？？？ target: # &lt;？ &lt;=？ left = mid + 1 else: right = mid - 1 return ？？？ # 返回left？ right？ 确定return因为最后跳出while (left &lt;= right)循环条件是right &lt; left，且right = left - 1。最后right和left一定是卡在”边界值”的左右两边，如果是比较值为key，查找大于等于（或者是大于）key的元素，则边界值就是等于key的所有元素的最右边那个，其实应该返回left 确定比较符号查找大于等于key的元素，则知道应该使用判断符号&lt; 参考 二分查找的变种 【二分查找】原型和变种以及相关思考 对应的 LeetCode 练习题leetcode-69-Sqrt(x) （x 的平方根）英文版：https://leetcode.com/problems/sqrtx/ 中文版：https://leetcode-cn.com/problems/sqrtx/ 方法一12345678910111213141516171819202122232425# coding: utf-8class Solution(object): def mySqrt(self, x): """ :type x: int :rtype: int """ left = 0 # 非负数，范围[0,x] right = x while left &lt;= right: mid = (left + right) // 2 # 使用其他语言时，为避免溢出可以写为 mid = left + (right - left) // 2 # print(mid) if mid ** 2 &gt; x: # 使用其他语言时，为避免溢出可用除法代替乘法，写为 if mid &gt; x // mid: 下同：if mid + 1 &gt; x // (mid + 1) right = mid - 1 else: if (mid + 1) ** 2 &gt; x: # 在这里判断某些情况可减少循环次数，如x=4 return mid left = mid + 1 return rights = Solution()print(s.mySqrt(12)) # 3print(s.mySqrt(8)) # 2print(s.mySqrt(4)) # 2 方法二这种写法更简洁，参考：3-4 short lines, Integer Newton, Every Language 12345678910class Solution(object): def mySqrt(self, x): """ :type x: int :rtype: int """ r = x while r ** 2 &gt; x: r = (r + x // r) // 2 return r]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-2-数组、字符串]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-2-%E6%95%B0%E7%BB%84%E3%80%81%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[数组实现一个支持动态扩容的数组参考：python实现动态数组 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# coding:utf-8 class Array: def __init__(self, capacity): self.capacity = capacity self.size = 0 # 元素数目 self.data = [None] * self.capacity def resize(self, new_capacity): # 新建容量为new_capacity的数组，将原数组元素逐个移动到新数组中 new_arr = Array(new_capacity) for i in range(self.size): new_arr.append_element(self.data[i]) self.capacity = new_capacity self.data = new_arr.data print("Resize!!!Now Array is", self.data) def add_element(self, index, e): if index &lt; 0 or index &gt; self.size: print("index out of range") return -1 if self.size == self.capacity: # 如果满了则扩容2倍 self.resize(2 * self.capacity) for i in range(self.size - 1, index - 1, -1): # 从后往前，将元素逐个往后移动一位，空位给新元素e self.data[i + 1] = self.data[i] self.data[index] = e self.size += 1 print("Add element!!!Now Array is", self.data) def append_element(self, e): self.add_element(self.size, e) # 直接调用add_element，减少判断 a = Array(3) a.add_element(1, 1) a.add_element(0, 5) a.append_element(6) a.append_element(1) a.append_element(4) """ index out of range Add element!!!Now Array is [5, None, None] Add element!!!Now Array is [5, 6, None] Add element!!!Now Array is [5, 6, 1] Add element!!!Now Array is [5, None, None, None, None, None] Add element!!!Now Array is [5, 6, None, None, None, None] Add element!!!Now Array is [5, 6, 1, None, None, None] Resize!!!Now Array is [5, 6, 1, None, None, None] Add element!!!Now Array is [5, 6, 1, 4, None, None] """ 实现一个大小固定的有序数组，支持动态增删改操作需要注意数组始终有序，在下方代码中默认升序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# coding:utf-8class SortList: def __init__(self, n): self.slist = [] self.max_size = n # 固定长度为n self.now_size = 0 # 记录当前长度方便后续操作 def add_element(self, e): if self.now_size &gt;= self.max_size: print("self.now_size &gt;= self.max_size") return -1 i = 0 while (i &lt; self.now_size): if self.slist[i] &lt; e: i += 1 else: break self.slist.append(e) self.now_size += 1 print(self.slist) def remove_element(self, e): if self.now_size == 0: print("self.now_size == 0") return -1 # self.slist.remove(e) 直接使用remove可以实现功能。下方使用二分法找到对应元素索引再根据索引删除 ret = -1 # 待删除元素下标，不存在返回-1 start = 0 end = self.now_size while start &lt; end: mid = (start + end) // 2 if self.slist[mid] &lt; e: start = mid + 1 elif self.slist[mid] &gt; e: end = mid - 1 else: ret = mid break if ret == -1: print("element &#123;&#125; not found in slist".format(e)) return -1 del self.slist[ret] # 或self.slist.pop(ret); 或使用切片删除 # self.slist.pop(ret) self.now_size -= 1 print(self.slist) def replace_element(self, old, new): self.remove_element(old) self.add_element(new) print(self.slist)sl = SortList(3)sl.add_element(1)sl.remove_element(7)sl.remove_element(1)sl.add_element(2)sl.add_element(3)sl.add_element(4)sl.replace_element(3, 5)sl.add_element(1)sl.remove_element(4)"""[1]element 7 not found in slist[][2][2, 3][2, 3, 4][2, 4][2, 4, 5][2, 4, 5]self.now_size &gt;= self.max_size[2, 5]""" 实现两个有序数组合并为一个有序数组方法一return sorted(list1+list2)，先合并再排序 方法二使用一种比较朴素的方法来合并：遍历2个数组，将较小的数插入list 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# coding:utf-8def merge_sort_list(list1, list2): n1 = len(list1) n2 = len(list2) if (n1 == 0): return list2 elif (n2 == 0): return list1 list = [] print(list) p1 = 0 p2 = 0 while p1 &lt; n1 and p2 &lt; n2: if list1[p1] &lt;= list2[p2]: list.append(list1[p1]) p1 += 1 else: list.append(list2[p2]) p2 += 1 print(list) if p1 &lt; n1: list += list1[p1:] else: list += list2[p2:] return list# 一些测试用例list1 = [1, 3, 5, 6, 8]list2 = [0, 1, 2, 3, 4, 9, 10]print(merge_sort_list(list1, list2))print(sorted(list1 + list2)) # 用于对比结果"""[][0][0, 1][0, 1, 1][0, 1, 1, 2][0, 1, 1, 2, 3][0, 1, 1, 2, 3, 3][0, 1, 1, 2, 3, 3, 4][0, 1, 1, 2, 3, 3, 4, 5][0, 1, 1, 2, 3, 3, 4, 5, 6][0, 1, 1, 2, 3, 3, 4, 5, 6, 8][0, 1, 1, 2, 3, 3, 4, 5, 6, 8, 9, 10][0, 1, 1, 2, 3, 3, 4, 5, 6, 8, 9, 10]"""list1 = [1, 3, 5, 6, 8]list2 = []print(merge_sort_list(list1, list2))print(sorted(list1 + list2))"""[1, 3, 5, 6, 8][1, 3, 5, 6, 8]"""list1 = []list2 = [0, 1, 2, 3, 4, 9, 10]print(merge_sort_list(list1, list2))print(sorted(list1 + list2))"""[0, 1, 2, 3, 4, 9, 10][0, 1, 2, 3, 4, 9, 10]"""list1 = []list2 = []print(merge_sort_list(list1, list2))print(sorted(list1 + list2))"""[][]""" 哈希表学习哈希表思想，并完成leetcode上的两数之和(1)及Happy Number(202)！(要求全部用哈希思想实现！) 哈希表可简单理解为k-v，在python中，哈希表可用dict表示 leetcode-1-两数之和代码见：leetcode-1-两数之和 中”方法二”，使用dict记录当前元素下标和匹配的值 LeetCode-202-快乐数Happy Number使用dict记录求过的数 12345678910111213141516171819202122232425class Solution(object): def isHappy(self, n): """ :type n: int :rtype: bool """ m_dict = &#123;&#125; while n != 1: # print(n) n = sum(int(i) ** 2 for i in str(n)) if n in m_dict: return False m_dict[n] = 1 return True s = Solution() print(s.isHappy(19)) """ 19 82 68 100 True """ 对应的 LeetCode 练习题Three Sum（求三数之和）英文版：https://leetcode.com/problems/3sum/中文版：https://leetcode-cn.com/problems/3sum/代码见：leetcode-15-三数之和 Majority Element（求众数）英文版：https://leetcode.com/problems/majority-element/ 中文版：https://leetcode-cn.com/problems/majority-element/ 使用dict记录{当前num：出现次数} 1234567891011class Solution(object): def majorityElement(self, nums): """ :type nums: List[int] :rtype: int """ m_dict = &#123;&#125; for e in nums: m_dict[e] = m_dict.get(e, 0) + 1 if m_dict[e] &gt; len(nums) / 2: return e 或者调用Counter 1234567891011class Solution(object): def majorityElement(self, nums): """ :type nums: List[int] :rtype: int """ from collections import Counter num=dict(Counter(nums)) for key in num: if num[key]&gt;len(nums)/2: return key Missing Positive（求缺失的第一个正数）英文版：https://leetcode.com/problems/first-missing-positive/中文版：https://leetcode-cn.com/problems/first-missing-positive/思路：使用桶，大小为len(nums)，负数可以丢弃，大于len(nums)的数也可以丢弃。遍历一遍后nums后，遍历桶，返回第一个空位index代码如下：123456789101112131415161718192021222324class Solution(object): def firstMissingPositive(self, nums): """ :type nums: List[int] :rtype: int """ n = len(nums) + 1 # 0位置无效，多设置一位，使用index更直观 bucket = [0] * n for e in nums: # print(bucket) if e &gt; 0 and e &lt; n: # 求的是第一个缺失的正整数，&gt;n的数可以丢弃 bucket[e] = e # 非0值，设置为e方便debug # print(bucket) for i in range(1, n): if bucket[i] == 0: return i return n s = Solution() print(s.firstMissingPositive([1, 2, 0])) # 3 print(s.firstMissingPositive([1, 2])) # 3 print(s.firstMissingPositive([3, 4, -1, 1])) # 2 print(s.firstMissingPositive([7, 8, 9, 11, 12])) # 1 字符串实现一个字符集，只包含 a～z 这 26 个英文字母的 Trie 树Trie树又叫做前缀树（Prefix Tree） 将每个节点的children都是一个dict，根据dict中的key找下一个节点 12345678910111213141516171819202122232425262728293031323334# coding:utf-8 class Node(object): def __init__(self): self.children = &#123;&#125; self.is_end = False class Trie(object): def __init__(self): self.root = Node() def insert(self, word): node = self.root for w in word: if w not in node.children: node.children[w] = Node() node = node.children[w] node.is_end = True def search(self, word): node = self.root for w in word: if w not in node.children: return False node = node.children[w] return node.is_end t = Trie() t.insert("hi") t.insert("hello") print(t.search("a")) # False print(t.search("hi")) # True 实现朴素的字符串匹配算法字符串匹配：字符串”abcde”中是否含有字符串”bd” 朴素算法：暴力解，下面给出了2种方式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# coding:utf-8def find_str(str1, str2): n1 = len(str1) n2 = len(str2) if n2 == 0: return 0 for i in range(n1 - n2): for j in range(n2): # print(i, j) if str1[i + j] != str2[j]: break else: if j == n2 - 1: return i return -1def find_str2(str1, str2): p1 = 0 p2 = 0 while p1 &lt; len(str1) and p2 &lt; len(str2): # print(p1, p2) if str1[p1] == str2[p2]: p1, p2 = p1 + 1, p2 + 1 else: p1, p2 = p1 - p2 + 1, 0 # 注意p1取值为 p1 - p2 + 1 if p2 == len(str2): return p1 - p2 return -1str1 = "abcdefs"str2 = "bc"str3 = "ea"str4 = "jljljkjjjl"str5 = ""str8 = "ab"print(find_str(str1, str2))print(find_str2(str1, str2))print(str1.find(str2)) # 1 使用find用于检验结果print(find_str(str1, str3))print(find_str2(str1, str3))print(str1.find(str3)) # -1print(find_str(str1, str4))print(find_str2(str1, str4))print(str1.find(str4)) # -1print(find_str(str1, str5))print(find_str2(str1, str5))print(str1.find(str5)) # 0print(find_str(str1, str8))print(find_str2(str1, str8))print(str1.find(str8)) # 0str6 = ""str7 = ""print(find_str(str6, str7))print(find_str2(str6, str7))print(str6.find(str7)) # 0 对应的 LeetCode 练习题Reverse String （反转字符串）英文版：https://leetcode.com/problems/reverse-string/中文版：https://leetcode-cn.com/problems/reverse-string/代码见：leetcode-344-反转字符串 Reverse Words in a String（翻转字符串里的单词）英文版：https://leetcode.com/problems/reverse-words-in-a-string/中文版：https://leetcode-cn.com/problems/reverse-words-in-a-string/代码如下： 1234567class Solution(object): def reverseWords(self, s): """ :type s: str :rtype: str """ return " ".join(s.strip().split()[::-1]) String to Integer (atoi)（字符串转换整数 (atoi)）英文版：https://leetcode.com/problems/string-to-integer-atoi/中文版：https://leetcode-cn.com/problems/string-to-integer-atoi/代码见：leetcode-8-字符串转换整数(atoi)]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[文件、目录 绝对路径：『一定由根目录 / 写起』；相对路径：『不是由 / 写起』 比较特殊的目录 12345. 代表此层目录.. 代表上一层目录- 代表前一个工作目录~ 代表『目前使用者身份』所在的家目录~account 代表 account 这个使用者的家目录(account是个帐号名称) 常见的处理目录的命令 cd：Change Directory 变换目录 pwd：Print Working Directory 显示目前的目录 mkdir：make directory 创建一个新的目录 rmdir：删除一个空的目录。仅能删除空目录，要删除非空目录需使用rm -r命令 使用者能使用的命令是依据 PATH 变量所规定的目录去搜寻的； 不同的身份(root 与一般用户)系统默认的 PATH 并不相同。差异较大的地方在於 /sbin, /usr/sbin ； ls 可以检视文件的属性，尤其 -d, -a, -l 等选项特别重要！ 文件的复制、删除、移动可以分别使用：cp, rm , mv等命令来操作； 检查文件的内容(读档)可使用的命令包括有：cat, tac, nl, more, less, head, tail, od 等 cat -n 与 nl 均可显示行号，但默认的情况下，空白行会不会编号并不相同； touch 的目的在修改文件的时间参数，但亦可用来创建空文件； 一个文件记录的时间参数有三种，分别是 access time(atime), status time (ctime), modification time(mtime)，ls 默认显示的是 mtime。 新建文件/目录时，新文件的默认权限使用 umask 来规范。默认目录完全权限为drwxrwxrwx， 文件则为-rw-rw-rw-。 观察文件的类型可以使用 file 命令来观察； 搜寻命令的完整档名可用 which 或 type ，这两个命令都是透过 PATH 变量来搜寻档名； 搜寻文件的完整档名可以使用 whereis 或 locate 到数据库文件去搜寻，而不实际搜寻文件系统； 利用 find 可以加入许多选项来直接查询文件系统，以获得自己想要知道的档名。 chmod 文件权限 chmod 选项 文件名 变更文件或目录权限 r 读取权限，4 w 写入， 2 x 执行，1 chmod 750 filename/*.sh 批量修改为可执行文件 cd cd [相对路径或绝对路径] 最重要的就是目录的绝对路径与相对路径，还有一些特殊目录的符号 cd - 返回上一个目录（非上一层），上一层为cd .. cd ~ 或 cd 回到当前账号home目录，亦即是 /root 这个目录 cd ~vbird 到 vbird 这个使用者的家目录，亦即 /home/vbird pwd pwd [-P]：-P ：显示出确实的路径，而非使用链接 (link) 路径。 pwd 显示出目前的工作目录 pwd -P 显示出实际的工作目录，而非链接路径，P要大写 mkdir mkdir [-mp] 目录名称:-m ：配置文件的权限。直接配置，不需要看默认权限 (umask)-p ：帮助你直接将所需要的目录(包含上一级目录)递回创建起来！ mkdir -m 711 test2 创建权限为rwx—x—x的目录 mkdir -p 建立嵌套目录。-p, —parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多级目录 rmdir rmdir [-p] 目录名称：-p ：连同上一级『空的』目录也一起删除注意：只能删除空目录 假设有目录结构test1/test2/test3/test4，都是空目录 rmdir test1/test2/test3/test4 只会删除目录test4，现目录结构变为test1/test2/test3 rmdir -p test1/test2/test3/test4 效果等同于rm -r test1。rmdir -p test1/test2/test3 会报错：目录非空 虽然使用 rmdir 比较不危险，但是局限大，只能删空目录，日常大多用rm -r ls ls [-aAdfFhilnrRSt] 目录名称-a ：全部的文件，连同隐藏档( 开头为 . 的文件) 一起列出来(常用)-A ：全部的文件，连同隐藏档，但不包括 . 与 .. 这两个目录-d ：仅列出目录本身，而不是列出目录内的文件数据(常用)-f ：直接列出结果，而不进行排序 (ls 默认会以档名排序！)-F ：根据文件、目录等资讯，给予附加数据结构，例如：*:代表可运行档； /:代表目录； =:代表 socket 文件； |:代表 FIFO 文件；-h ：将文件容量以人类较易读的方式(例如 GB, KB 等等)列出来；-i ：列出 inode 号码，inode 的意义下一章将会介绍；-l ：长数据串列出，包含文件的属性与权限等等数据；(常用)-n ：列出 UID 与 GID 而非使用者与群组的名称 (UID与GID会在帐号管理提到！)-r ：将排序结果反向输出，例如：原本档名由小到大，反向则为由大到小；-R ：连同子目录内容一起列出来，等於该目录下的所有文件都会显示出来；-S ：以文件容量大小排序，而不是用档名排序；-t ：依时间排序，而不是用档名。 ls -t 以文件修改时间排序，修改时间越接近now排序越靠前，即修改顺序的逆序 ls -r, –reverse 依相反次序排列，可以理解为逆序。ls -tr 修改时间的顺序 命令及文件查找 命令文档名的查找：which或 type。这两个命令都是透过 $PATH 变量来搜寻档名； 文件文档名的查找：whereis, locate, find。whereis 或 locate 到数据库文件去搜寻，而不实际搜寻文件系统；利用 find 可以加入许多选项来直接查询文件系统，以获得自己想要知道的档名。 which 查找命令文档 which [-a] command-a ：将所有由 $PATH目录中可以找到的命令均列出，而不止第一个被找到的命令名称这个命令是根据$PATH这个环境变量所规范的路径，去搜寻命令的文档名。which 后面接的是要搜索的命令，若加上 -a 选项，则可以列出所有的可以找到的同名文档 在终端机模式当中，连续输入两次tab按键就能够知道使用者有多少命令可以下达。 这些命令的完整文档路径可以透过 which 或 type 来搜索 which cd 常用命令cd 无法通过which找到，因为cd是bash内建的命令，而which默认是找$PATH内所规范的目录。cd需要通过type cd来查找 whereis 查找特定文件 whereis [-bmsu] 文件或目录名-b :只找 binary 格式的文件-m :只找在说明档 manual 路径下的文件-s :只找 source 来源文件-u :搜寻不在上述三个项目当中的其他特殊文件 通常先使用 whereis 或者是 locate 来查找文件，如果真的找不到了，才以 find 来查找(find 是直接搜寻硬盘)。因为 whereis 与 locate 是利用数据库来搜寻数据，所以相当的快速，而且并没有实际的搜寻硬盘， 比较省时间 为什么whereis 比 find 快？这是因为 Linux 系统会将系统内的所有文件都记录在一个数据库文件里面， 而当使用 whereis 或者是底下要说的 locate 时，都会以此数据库文件的内容为准， 因此，有的时后你还会发现使用这两个运行档时，会找到已经被杀掉的文件！ 而且也找不到最新的刚刚创建的文件呢！这就是因为这两个命令是由数据库当中的结果去搜寻文件的所在啊 locate locate [-ir] keyword-i ：忽略大小写的差异；-r ：后面可接正规表示法的显示方式 locate passwd ，那么在完整档名 (包含路径名称) 当中，只要有 passwd 在其中， 就会被显示出来 限制：使用 locate 来寻找数据的时候特别的快， 这是因为 locate 寻找的数据是由『已创建的数据库 /var/lib/mlocate/』 里面的数据所搜寻到的，所以不用直接在去硬盘当中存取数据 就是因为是经由数据库来搜寻的，而数据库的创建默认是在每天运行一次 (每个 distribution 都不同，CentOS 5.x 是每天升级数据库一次！)，所以当你新创建起来的文件， 却还在数据库升级之前搜寻该文件，那么 locate 会告诉你『找不到！』呵呵！因为必须要升级数据库呀！ 那能否手动升级数据库哪？当然可以啊！升级 locate 数据库的方法非常简单，直接输入『 updatedb 』就可以了！ updatedb 命令会去读取 /etc/updatedb.conf 这个配置档的配置，然后再去硬盘里面进行搜寻档名的动作， 最后就升级整个数据库文件罗！因为 updatedb 会去搜寻硬盘，所以当你运行 updatedb 时，可能会等待数分钟的时间喔！ updatedb：根据 /etc/updatedb.conf 的配置去搜寻系统硬盘内的档名，并升级 /var/lib/mlocate 内的数据库文件； locate：依据 /var/lib/mlocate 内的数据库记载，找出使用者输入的关键字档名。 find find [PATH] [option] [action] 与时间有关的选项：共有 -atime, -ctime 与 -mtime ，以 -mtime 说明-mtime n ：n 为数字，意义为在 n 天之前的『一天之内』被更动过内容的文件；-mtime +n ：列出在 n 天之前(不含 n 天本身)被更动过内容的文件档名；-mtime -n ：列出在 n 天之内(含 n 天本身)被更动过内容的文件档名。-newer file ：file 为一个存在的文件，列出比 file 还要新的文件档名 与使用者或群组名称有关的参数：-uid n ：n 为数字，这个数字是使用者的帐号 ID，亦即 UID ，这个 UID 是记录在 /etc/passwd 里面与帐号名称对应的数字。这方面我们会在第四篇介绍。 -gid n ：n 为数字，这个数字是群组名称的 ID，亦即 GID，这个 GID 记录在 /etc/group，相关的介绍我们会第四篇说明～ -user name ：name 为使用者帐号名称喔！例如 dmtsai-group name：name 为群组名称喔，例如 users ；-nouser ：寻找文件的拥有者不存在 /etc/passwd 的人！-nogroup ：寻找文件的拥有群组不存在於 /etc/group 的文件！ 当你自行安装软件时，很可能该软件的属性当中并没有文件拥有者， 这是可能的！在这个时候，就可以使用 -nouser 与 -nogroup 搜寻。 与文件权限及名称有关的参数：-name filename：搜寻文件名称为 filename 的文件；-size [+-]SIZE：搜寻比 SIZE 还要大(+)或小(-)的文件。这个 SIZE 的规格有： c: 代表 byte， k: 代表 1024bytes。所以，要找比 50KB 还要大的文件，就是『 -size +50k 』 -type TYPE ：搜寻文件的类型为 TYPE 的，类型主要有：一般正规文件 (f), 装置文件 (b, c), 目录 (d), 连结档 (l), socket (s), 及 FIFO (p) 等属性。 -perm mode ：搜寻文件权限『刚好等於』 mode 的文件，这个 mode 为类似 chmod 的属性值，举例来说， -rwsr-xr-x 的属性为 4755 ！ -perm -mode ：搜寻文件权限『必须要全部囊括 mode 的权限』的文件，举例来说， 我们要搜寻 -rwxr--r-- ，亦即 0744 的文件，使用 -perm -0744， 当一个文件的权限为 -rwsr-xr-x ，亦即 4755 时，也会被列出来， 因为 -rwsr-xr-x 的属性已经囊括了 -rwxr--r-- 的属性了。 -perm +mode ：搜寻文件权限『包含任一 mode 的权限』的文件，举例来说，我们搜寻 -rwxr-xr-x ，亦即 -perm +755 时，但一个文件属性为 -rw------- 也会被列出来，因为他有 -rw.... 的属性存在！ 额外可进行的动作：-exec command ：command 为其他命令，-exec 后面可再接额外的命令来处理搜寻到 的结果。 -print ：将结果列印到萤幕上，这个动作是默认动作！ find -name abc.sh 按文件名查找文件abc.sh，会在硬盘查找，尽量少用find，先使用whereis和locate tar 打包压缩及解压 tar -zcvf one.tar.gz 1/ 将文件夹1压缩打包为one.tar.gz tar -cvf one.tar.gz 1/ 不压缩打包，更快，但是文件大小不减小 tar -xzvf 解压。未压缩可使用tar -xvf 解压 vim删除文件中所有内容方法1: 按ggdG方法2: :%d 区块选择 区块选择的按键 v 字符选择，会将光标经过的地方反白选择！ V 行选择，会将光标经过的行反白选择！ [Ctrl]+v 区块选择，可以用长方形的方式选择资料 y 将反白的地方复制起来，p粘贴 d 将反白的地方删除掉 crontab linux下用来周期性执行任务或等待处理某些事情的一个守护进程。用户所建立的crontab文件中，每一行都代表一项任务，每个的每个字段代表一项设置：共6个字段，前5个是时间设定，第6个是要执行的命令，格式如下：minute hour day month week commandminute： 表示分钟，可以是从0到59之间的任何整数。hour：表示小时，可以是从0到23之间的任何整数。day：表示日期，可以是从1到31之间的任何整数。month：表示月份，可以是从1到12之间的任何整数。week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 crontab -l 列出 crontab FILENAME 将文件FILENAME新增为定时任务，会覆盖之前crontab任务，慎用 crontab -e 修改 alias alias 新命令=&#39;原命令 -选项/参数&#39; 设置命令别名 alias -p 查看系统已设置的别名 令别名永久生效：(如果没有.bashrc文件就创建)vim ~/.bashrc在文件最后加上别名设置，如：alias 90=&#39;ssh admin@111.111.111.90&#39;完成后：source ~/.bashrc 如果再某台机器上设置的alias干扰正常用法，可以使用\rm filename或者使用/bin/rm filename来删除，使用这两种方式使用的就不是alias中设置的rm了。 shell统计和排序 wc -l 统计行数 1234bash-3.2$ wc -l filename.txt 3 filename.txtbash-3.2$ cat filename.txt | wc -l 3 uniq 的一个特性：检查重复行的时候只会检查相邻的行。所以去重前需要先保证有序：sort | uniq。或者直接使用sort -u sort 默认以字符升序排列 awk awk -F 指定输入文本分隔符拆分。awk -F&quot;\t&quot; &#39;{print $5}&#39; 表示以”\t”为分隔符切分文本，并打印第5列（从1开始计数）。{print $0} 表示打印整行。 awk -v var=value 赋值一个用户定义变量，将外部变量传递给awk grep grep -n 显示行号 grep -A 3 -B 3 显示前后3行 数组 arrayshell脚本中的list(array)does linux shell support list data structure? 12345678910111213141516171819202122232425262728293031323334353637383940414243array=("item 1" "item 2" "item 3") # 这么创建list，中间能够包含空格。如果中间不包含空格，可以不加引号，如：array=(red orange white "light gray")# 创建list及访问元素（推荐），元素本身可以包含空格array=("item 1" "item 2" "item 3")for i in "$&#123;array[@]&#125;"; do # The quotes are necessary here echo "$i"done#item 1#item 2#item 3# 如果$&#123;array[@]&#125;不加引号，则元素被空格分开for i in $&#123;array[@]&#125;; do echo $idone#item#1#item#2#item#3# 使用如下方式list='"item 1" "item 2" "item 3"'for i in $list; do echo $idone#"item#1"#"item#2"#"item#3"# 将$list看做一个字符串，并非list（array）for i in "$list"; do echo $idone#"item 1" "item 2" "item 3" 使用array存储命令12345678910cmd_str_list=(&quot;sh run.sh a&quot;&quot;sh run.sh b&quot;)for ((i = 0; i &lt; $&#123;#cmd_str_list[@]&#125;; i++))do cmd_str=&quot;$&#123;cmd_str_list[$i]&#125;&quot; echo $&#123;cmd_str&#125; eval $&#123;cmd_str&#125;done 参考: Bash array with spaces in elements ls结果分配给数组 array=($(ls file))在Linux Bash中，将ls结果分配给数组。可用下标访问 数组拷贝参考：How to copy an array in Bash? 123456a=(foo bar "foo 1" "bar two") #create an arrayb=("$&#123;a[@]&#125;") #copy the array in another one for value in "$&#123;b[@]&#125;" ; do #print the new array echo "$value" done echoecho -e 打印特殊字符，如tab12345echo "a\tb"#a\tbecho -e "a\tb"#a b expr数学计算1+2字符串，1 + 2数学计算（注意空格） 1234bash-3.2 d$ expr 1+21+2bash-3.2$ expr 1 + 23 sed sed &#39;1d&#39; 删除第一行，更多介绍：https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2856901.html sed &#39;s/要替换的字符串/新的字符串/g&#39; 变量替换除了使用sed &#39;s/要替换的字符串/新的字符串/g&#39;，还可以使用：${变量/旧字符串/新字符串} 若变量内容符合“旧字符串”，则第一个旧字符串会被新字符串替换。${变量//旧字符串/新字符串} 若变量内容符合“旧字符串”，则全部的旧字符串会被新字符串替换。也可以在旧字符前加\，结果一致。如果需要替换转义符，需要加\例如：1234567bash-3.2$ header="theme_res_id\tdid\tc3_dist"bash-3.2$ echo $&#123;header//id/,&#125; # 将id替换为,theme_res_,\td,\tc3_distbash-3.2$ echo $&#123;header//\t/,&#125; # 将t替换为,,heme_res_id\,did\,c3_dis,bash-3.2$ echo $&#123;header//\\t/,&#125; # 将转义符\t替换为,theme_res_id,did,c3_dist 参考： Bash变量的删除、取代与替换https://andyyoung01.github.io/2017/02/21/Bash%E5%8F%98%E9%87%8F%E7%9A%84%E5%88%A0%E9%99%A4%E3%80%81%E5%8F%96%E4%BB%A3%E4%B8%8E%E6%9B%BF%E6%8D%A2/ string split shell脚本中string split功能：https://stackoverflow.com/questions/918886/how-do-i-split-a-string-on-a-delimiter-in-bash?page=1&amp;tab=votes#tab-top 。使用cut比较简洁： 1234$ echo "bla@some.com;john@home.com" | cut -d ";" -f 1bla@some.com$ echo "bla@some.com;john@home.com" | cut -d ";" -f 2john@home.com 函数返回值中文参考：shell 函数返回值接收问题Linux Shell函数返回值 函数可以有返回值，return，但是需要返回值是数字，而不能是字符串，字符串会提示：/data0/home/rec/chengsujun/test_ly/search_index_builder/DataHope/scripts/../utils.sh: line 33: return: index_data/sku_precise/2019-01-16: numeric argument required 虽然有这个提示，但是执行似乎成功了 How to return a string value from a Bash function 点赞最高：没有什么方法 12345678910function func_mk_hadoop_dir()&#123; local date=$&#123;1&#125; local index_type=$&#123;2&#125; local HADOOP_DATA_DIR=$&#123;HADOOP_DIR&#125;/$&#123;index_type&#125;/$&#123;date&#125; return "$&#123;HADOOP_DATA_DIR&#125;"&#125;#调用加``符号hadoop_data_dir=`func_mk_hadoop_dir $&#123;date&#125; $&#123;index_type&#125;`#这么执行报错：return: index_data/sku_precise/2019-01-16: numeric argument required 使用echo方法：123456function func_mk_hadoop_dir()&#123; local date=$&#123;1&#125; local index_type=$&#123;2&#125; local HADOOP_DATA_DIR=$&#123;HADOOP_DIR&#125;/$&#123;index_type&#125;/$&#123;date&#125; echo &quot;$&#123;HADOOP_DATA_DIR&#125;&quot;&#125; 报错：“integer expression expected”（需要的是整数)将字符串比较写为了整数比较的格式，就会出现这个报错。这是在比较两个日期时报的错，解决方案： https://unix.stackexchange.com/questions/84381/how-to-compare-two-dates-in-a-shell 123456789101112131415161718192021222324252627todate=2013-07-18cond=2013-07-15if [ $todate -ge $cond ];then echo "break"fi # 将变量用引号引起来，-ge修改为&gt;，改写为：（if中[[]]也可替换为[]）date_a=2013-07-18date_b=2013-07-15if [[ "$date_a" &gt; "$date_b" ]] ;then echo "break"fi# 备注：也有其他方案例如先将日期转为整数再比较：todate=$(date -d 2013-07-18 +%s)cond=$(date -d 2014-08-19 +%s)# 或者todate=$(date -d 2013-07-18 +"%Y%m%d") # = 20130718cond=$(date -d 2013-07-15 +"%Y%m%d") # = 20130715# 或者删除-$ echo "2013-07-15" | tr -d "-"20130715 报错：bad substitutionfor i in ${awk -F &quot;:&quot; &#39;{print $1}&#39; /etc/passwd | grep stu}报错${awk -F &quot;:&quot; &#39;{print $1}&#39; /etc/passwd | grep stu}: bad substitution 变量引用是$()，而不是${}，所以只需要把这行代码改为：for i in $(awk -F &quot;:&quot; &#39;{print $1}&#39; /etc/passwd | grep stu) 输出到文件需要加echo例如：12a=5$a&gt;t.txt 会报错：-bash: 5: command not found，文件t.txt中没有内容 正确方式是： 12a=5echo $a&gt;t.txt shell 脚本中set命令set -e-e 选项作用范围 :https://blog.csdn.net/fc34235/article/details/76598448 set -e就是当命令以非零状态退出时，则退出shell。主要作用是，当脚本执行出现意料之外的情况时，立即退出，避免错误被忽略，导致最终结果不正确。 set -e 命令用法总结如下： 1.当命令的返回值为非零状态时，则立即退出脚本的执行。 2.作用范围只限于脚本执行的当前进行，不作用于其创建的子进程。 3.另外，当想根据命令执行的返回值，输出对应的log时，最好不要采用set -e选项，而是通过配合exit 命令来达到输出log并退出执行的目的。 set -u参考：(http://man.linuxde.net/set) set -u：当执行时使用到未定义过的变量，则显示错误信息。 不要在公共机器上set -u，会导致自动补全功能失效，并报错： 123cd sear-bash: !ref: unbound variable-bash: !ref: unbound variable-bash: words[i]: unbound variable 关闭： set +u set -x同理，关闭:set +x 查看物理cpu与逻辑cpu概述https://blog.csdn.net/BeautifulGrils/article/details/79799634 物理cpu数：主板上实际插入的cpu数量，可以数不重复的 physical id 有几个（physical id） cpu核数：单块CPU上面能处理数据的芯片组的数量，如双核、四核等 （cpu cores） 逻辑cpu数：一般情况下，逻辑cpu=物理CPU个数×每颗核数，如果不相等的话，则表示服务器的CPU支持超线程技术（HT：简单来说，它可使处理器中的1 颗内核如2 颗内核那样在操作系统中发挥作用。这样一来，操作系统可使用的执行资源扩大了一倍，大幅提高了系统的整体性能，此时逻辑cpu=物理CPU个数×每颗核数x2）备注一下：Linux下top查看的CPU也是逻辑CPU个数123456789101112#查看物理cpu个数：cat /proc/cpuinfo |grep "physical id"| sort -u | wc -l2#查看逻辑cpu个数：（核数？=逻辑cpu个数）cat /proc/cpuinfo |grep processor| wc -l32#查看cpu核数：（单个cpu的核数?所有的核数需要*物理cpu个数，由于超线程技术，因此再*2）cat /proc/cpuinfo |grep cores|uniq8#查看CPU型号：cpu型号是 E5-2640cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c32 Intel(R) Xeon(R) CPU E5-2640 v2 @ 2.00GHz http://www.uuboku.com/137.html 查看内存可使用free，默认单位是kB，free -m单位是M，free -g单位是G）12345678910111213free -m total used free shared buff/cache availableMem: 31963 11688 1143 368 19131 19476Swap: 16383 1419 14964#总的物理内存为 32G，虚拟内存为16G（由于进制的关系，上面显示的是 31963 和 16383）。cat /proc/meminfoMemTotal: 32730616 kBMemFree: 1168892 kBMemAvailable: 19942200 kBBuffers: 0 kBCached: 18844272 kB#看第一行 32730616 kB，总的物理内存为32G 其他 ssh 默认从~/.ssh/中匹配，所以，如果这个目录下.ssh不可用（由于文件权限等原因），在个人目录中新生成.ssh文件，在执行时应该使用-i显示指定.ssh/id_rsa文件地址 hostname -i 获取本机ip select_dt=$(date -d &#39;&#39;${input_dt}&#39; day&#39; +%Y-%m-%d) 注意这里的参数${input_dt}必须用单引号引起来，否则会报错。shell：引号里面用需要加引号 if [ $# -ge 2 ] ; then 如果参数的数量&gt;2，$# 表示设置的参数个数 ${where_condition:=1=1}参考：http://www.cnblogs.com/fhefh/archive/2011/04/22/2024750.html: ${VAR:=”some default”}这些代码开始的冒号是一个正确执行非活动任务的shell命令。在这个句法中，它仅仅扩展了行中紧随其后的所有参数。本例中，只要是要在花括号内扩展参数值。本行ongoing冒号中的参数是最有趣的部分；它是用花括号起来的一些逻辑的参数扩展。:=句法表示VAR变量将会和“some defalut”字符串进行比较。在这个表达式中，如果变量VAR还没有被设置，那么“:=”之后表达式的值将被赋给它，这个值可能是一个数字，一个字符串，或者是另外一个变量。 sudo netstat -anp | grep TIME_WAIT | grep :22 查看22端口 kill -9 进程即刻结束 取出字符串中变量 ${!c} 参考： 鸟哥的Linux私房菜]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-1-栈、队列和链表]]></title>
    <url>%2F2019%2F04%2F08%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-1-%E6%A0%88%E3%80%81%E9%98%9F%E5%88%97%E5%92%8C%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[栈先进后出；push；pop 两种存储表示方式：顺序栈，链式栈 用数组实现一个顺序栈12345678910111213141516171819202122232425262728293031# coding:utf-8class Stack: def __init__(self): self.stack = [] def isempty(self): if (len(self.stack) == 0): return True return False def push(self, e): return self.stack.append(e) def pop(self): if not self.isempty(): self.stack.pop() def print_info(self): print(self.stack)stack = Stack()stack.push(1)stack.push(2)stack.push(3)stack.print_info() # [1, 2, 3]stack.pop()stack.print_info() # [1, 2]stack.push(4)stack.print_info() # [1, 2, 4] 用链表实现一个链式栈使用head表示栈顶 123456789101112131415161718192021222324class Node: def __init__(self, data): self.data = data self.next = None class Stack: def __init__(self): self.head = None def push(self, data): if self.head is None: self.head = Node(data) else: new_node = Node(data) new_node.next = self.head self.head = new_node def pop(self): if self.head is None: return None else: popped = self.head.data self.head = self.head.next return popped 编程模拟实现一个浏览器的前进、后退功能1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding:utf-8class Browser: def __init__(self): self.stack = [] self.index = -1 def isempty(self): if (len(self.stack) == 0): return True return False def access(self, e): self.stack.append(e) self.index += 1 return e def forward(self): self.index = min(self.index-1, len(self.stack)-1) return self.stack[self.index] def back(self): if not self.isempty(): self.index = max(self.index - 1, 0) return self.stack[self.index]bw = Browser()print(bw.access(1))print(bw.access(2))print(bw.access(3))print(bw.forward())print(bw.access(4))print(bw.back())print(bw.back())"""123before 2after 12421""" 对应的 LeetCode 练习题Valid Parentheses（有效的括号）英文版：https://leetcode.com/problems/valid-parentheses/ 中文版：https://leetcode-cn.com/problems/valid-parentheses/ 代码见：leetcode-20-有效的括号 123456789101112131415161718192021class Solution(object): def isValid(self, s): """ :type s: str :rtype: bool """ re_dict = &#123;"(": ")", "&#123;": "&#125;", "[": "]"&#125; stack = [] for t in s: if t not in re_dict: if len(stack) == 0: return False elif stack[-1] != t: return False else: stack.pop() else: stack.append(re_dict[t]) if (len(stack)): return False return True Longest Valid Parentheses（最长有效的括号）英文版：https://leetcode.com/problems/longest-valid-parentheses/ 中文版：https://leetcode-cn.com/problems/longest-valid-parentheses/ 参考：https://leetcode.com/problems/longest-valid-parentheses/solution/ 改方法使用栈，先在栈底放入-1，然后放各个括号索引 123456789101112131415161718class Solution(object): def longestValidParentheses(self, s): """ :type s: str :rtype: int """ stack = [-1] ans = 0 for i in range(len(s)): if s[i] == "(": stack.append(i) else: stack.pop() if len(stack) == 0: stack.append(i) else: ans = max(ans, i - stack[-1]) return ans 测试用例 12345s = Solution()print(s.longestValidParentheses("(()")) # 2print(s.longestValidParentheses(")()())")) # 4print(s.longestValidParentheses("(()())")) # 6print(s.longestValidParentheses("()(()")) # 2 Evaluate Reverse Polish Notatio（逆波兰表达式求值）英文版：https://leetcode.com/problems/evaluate-reverse-polish-notation/ 中文版：https://leetcode-cn.com/problems/evaluate-reverse-polish-notation/ 题中指明逆波兰式总是有效的，因此无需判定有效，直接使用栈解答 123456789101112131415161718192021222324class Solution: def evalRPN(self, tokens: List[str]) -&gt; int: stack = [] for s in tokens: if s == "+": b = stack.pop() a = stack.pop() stack.append(a + b) elif s == "-": b = stack.pop() a = stack.pop() stack.append(a - b) elif s == "*": b = stack.pop() a = stack.pop() stack.append(a * b) elif s == "/": b = stack.pop() a = stack.pop() stack.append(int(a / b)) # 负数除法：6//-132 = -1，而非0。因此采用先除，后取整方法 else: stack.append(int(s)) # 将字符转为int存入栈 # print(stack) return stack[0] python除法可参考：python – 整数除以负数 更简洁的写法(耗时更长)： 12345678910111213class Solution: def evalRPN(self, tokens: List[str]) -&gt; int: stack = [] symbol = ["+", "-", "*", "/"] for s in tokens: if s in symbol: b = stack.pop() a = stack.pop() stack.append(str(int(eval(a + s + b)))) else: stack.append(s) # 栈中存字符 # print(stack) return int(stack[0]) # 最后结果转为int 部分测试用例： 1234s = Solution()print(s.evalRPN(["2", "1", "+", "3", "*"])) # 9,((2 + 1) * 3) = 9print(s.evalRPN(["4", "13", "5", "/", "+"])) # 6, (4 + (13 / 5)) = 6print(s.evalRPN(["10", "6", "9", "3", "+", "-11", "*", "/", "*", "17", "+", "5", "+"])) # 22 队列用数组实现一个顺序队列12345678910111213141516# coding:utf-8class Queue: def __init__(self): self.items = [] def isEmpty(self): return self.items == [] def enqueue(self, item): self.items.insert(0,item) def dequeue(self): return self.items.pop() def size(self): return len(self.items) 用链表实现一个链式队列123456789101112131415161718192021222324252627282930313233# coding:utf-8class Node: def __init__(self, data): self.data = data self.next = Noneclass Queue: def __init__(self): self.front = self.rear = None def isEmpty(self): return self.front == None def EnQueue(self, item): temp = Node(item) if self.rear == None: self.front = self.rear = temp return self.rear.next = temp self.rear = temp def DeQueue(self): if self.isEmpty(): return temp = self.front self.front = temp.next if (self.front == None): self.rear = None return str(temp.data) 实现一个循环队列1234567891011121314151617181920212223242526272829303132333435class Queue: def __init__(self): front = None rear = Nonedef enQueue(q, value): temp = Node() temp.data = value if (q.front == None): q.front = temp else: q.rear.link = temp q.rear = temp q.rear.link = q.frontdef deQueue(q): if (q.front == None): print("Queue is empty") return -1 value = None if (q.front == q.rear): value = q.front.data q.front = None q.rear = None else: temp = q.front value = temp.data q.front = q.front.link q.rear.link = q.front return value 对应的 LeetCode 练习题Circular Deque（设计一个双端队列）英文版：https://leetcode.com/problems/design-circular-deque/ 中文版：https://leetcode-cn.com/problems/design-circular-deque/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687class MyCircularDeque(object): def __init__(self, k): """ Initialize your data structure here. Set the size of the deque to be k. :type k: int """ self.k = k self.queue = [] def insertFront(self, value): """ Adds an item at the front of Deque. Return true if the operation is successful. :type value: int :rtype: bool """ if self.isFull(): return False self.queue.insert(0, value) return True def insertLast(self, value): """ Adds an item at the rear of Deque. Return true if the operation is successful. :type value: int :rtype: bool """ if self.isFull(): return False self.queue.append(value) return True def deleteFront(self): """ Deletes an item from the front of Deque. Return true if the operation is successful. :rtype: bool """ if self.isEmpty(): return False self.queue.pop(0) return True def deleteLast(self): """ Deletes an item from the rear of Deque. Return true if the operation is successful. :rtype: bool """ if self.isEmpty(): return False self.queue.pop() return True def getFront(self): """ Get the front item from the deque. :rtype: int """ if len(self.queue) &gt; 0: return self.queue[0] # 注意不是pop(0) return -1 # 根据测试用例预期返回-1， 不写return None def getRear(self): """ Get the last item from the deque. :rtype: int """ if len(self.queue) &gt; 0: return self.queue[-1] # 注意不是pop() return -1 # 根据测试用例预期返回-1， 不写return None def isEmpty(self): """ Checks whether the circular deque is empty or not. :rtype: bool """ if len(self.queue) == 0: return True return False def isFull(self): """ Checks whether the circular deque is full or not. :rtype: bool """ if len(self.queue) == self.k: return True return False 部分测试用例 1234567891011121314151617181920212223circularDeque = MyCircularDeque(3) # 设置容量大小为3print(circularDeque.insertLast(1)) # 返回 trueprint(circularDeque.insertLast(2)) # 返回 trueprint(circularDeque.insertFront(3)) # 返回 trueprint(circularDeque.insertFront(4)) # 已经满了，返回 falseprint(circularDeque.getRear()) # 返回 2print(circularDeque.isFull()) # 返回 trueprint(circularDeque.deleteLast()) # 返回 trueprint(circularDeque.insertFront(4)) # 返回 trueprint(circularDeque.getFront()) # 返回 4print("=" * 30)obj = MyCircularDeque(4) # nullprint(obj.insertFront(9)) # trueprint(obj.deleteLast()) # trueprint(obj.getRear()) # -1"""["MyCircularDeque","insertFront","deleteLast","getRear","getFront","getFront","deleteFront","insertFront","insertLast","insertFront","getFront","insertFront"][[4],[9],[],[],[],[],[],[6],[5],[9],[],[6]][null,true,true,-1,-1,-1,false,true,true,true,9,true]""" Sliding Window Maximum（滑动窗口最大值）英文版：https://leetcode.com/problems/sliding-window-maximum/ 中文版：https://leetcode-cn.com/problems/sliding-window-maximum/ 链表实现单链表、循环链表、双向链表，支持增删操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667# coding: utf-8class Node(object): def __init__(self, data): self.data = data self.next = Noneclass LinkedList(object): def __init__(self): self.head = None def __len__(self): pre = self.head length = 0 while pre: length += 1 pre = pre.nex return length def is_empty(self): return False if len(self) &gt; 0 else True def append(self, data): node = Node(data) if self.head is None: self.head = node else: pre = self.head while pre.next: pre = pre.next pre.next = node def insert(self, index, data): node = Node(data) if abs(index + 1) &gt; len(self): return False index = index if index &gt;= 0 else len(self) + index + 1 if index == 0: node.next = self.head self.head = node else: pre = self.get(index - 1) if pre: nex = pre.nex pre.nex = node node.next = nex else: return False return node def delete(self, index): f = index if index &gt; 0 else abs(index + 1) if len(self) &lt;= f: return False pre = self.head index = index if index &gt;= 0 else len(self) + index prep = None while index: prep = pre pre = pre.nex index -= 1 if not prep: self.head = pre.nex else: prep.nex = pre.nex return pre.data 实现单链表反转123456789101112131415161718192021222324# coding: utf-8class Node(object): def __init__(self, data): self.data = data self.next = Noneclass LinkedList(object): def __init__(self): self.head = None def __reversed__(self): def reverse(pre_node, node): if pre_node is self.head: pre_node.nex = None if node: next_node = node.nex node.nex = pre_node return reverse(node, next_node) else: self.head = pre_node return reverse(self.head, self.head.nex) 实现两个有序的链表合并为一个有序链表12345678910111213def Merge(self, pHead1, pHead2): if pHead1 == None: return pHead2 elif pHead2 == None: return pHead1 pMergedHead = None if pHead1.val &lt; pHead2.val: pMergedHead = pHead1 pMergedHead.next = self.Merge(pHead1.next, pHead2) else: pMergedHead = pHead2 pMergedHead.next = self.Merge(pHead1, pHead2.next) return pMergedHead 实现求链表的中间结点123456789101112131415161718# coding: utf-8class Node: def __init__(self,data,next): self.data = data self.next = nextn1 = Node('n1',None)n2 = Node('n2',n1)n3 = Node('n3',n2)n4 = Node('n4',n3)n5 = Node('n5',n4)p1 = n5p2 = n5while p2.next is not None and p2.next.next is not None: p1 = p1.next p2 = p2.next.nextprint(p1.data) 对应的 LeetCode 练习题Linked List Cycle I（环形链表）英文版：https://leetcode.com/problems/linked-list-cycle/ 中文版：https://leetcode-cn.com/problems/linked-list-cycle/ Merge k Sorted Lists（合并 k 个排序链表）英文版：https://leetcode.com/problems/merge-k-sorted-lists/ 中文版：https://leetcode-cn.com/problems/merge-k-sorted-lists/]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive常用命令]]></title>
    <url>%2F2019%2F03%2F31%2Fhive%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[增建表 重要的数据建表最好为externel ，在drop表时，不会drop对应hadoop文件，在重新create table后能够快速恢复数据。 可以显示指定format为orc，注意最后3行顺序 location可以不写，但是建完后需要检测存储路径是否和预期一致 12345678910111213create [external] table if not exists app.test ( sku string, csku string ) partitioned by ( dt string ) stored as orc location 'xxxx/app.db/test' tblproperties ('orc.compress'='SNAPPY'); 增加字段(列) 添加字段(在所有存在的列后面，但是在分区列之前添加一个字段) 不添加说明：alter table 表名 add columns (字段名 字段数据类型, 字段名 字段数据类型) 添加说明：alter table 表名 add columns (字段名 字段数据类型 comment &#39;字段说明&#39;, 字段名 字段数据类型 comment &#39;字段说明&#39;) 增加表记录 添加一条记录：insert into 表名(字段名[，字段名]) values(&#39;值&#39;[,&#39;值&#39;]); 或使用select 12insert into 表名(字段名[，字段名]) select ‘...’ 使用insert into向表中追加数据，可能追加的数据与表中已有的数据相同，不会覆盖，因此会出现相同的两条记录。 添加记录（同记录覆盖）使用insert overwrite注意 insert overwrite table 表名 select…..table不能省略。会将之前的记录全部删除，即时与追加的记录不同 增加分区1234567ALTER TABLE table_name ADD PARTITION (partCol = 'value1') location 'loc1'; -- 一次添加一个分区ALTER TABLE table_name ADD IF NOT EXISTS PARTITION (dt='20130101') LOCATION '/user/hadoop/warehouse/table_name/dt=20130101'; -- 一次添加多个分区ALTER TABLE page_view ADD PARTITION (dt='2008-08-08', country='us') location '/path/to/us/part080808' PARTITION (dt='2008-08-09', country='us') location '/path/to/us/part080809'; 删删除表格 删除表格：drop table 表名; 删除所有记录（行），不删除表结构truncate table 表名; 删除分区123456ALTER TABLE login DROP IF EXISTS PARTITION (dt='2008-08-08');ALTER TABLE page_view DROP IF EXISTS PARTITION (dt='2008-08-08', country='us');-- 删除多个分区ALTER TABLE app.xxx DROP IF EXISTS PARTITION (dt&lt;'2019-04-01'); 删外部表数据外部表，直接rm -r hdfs数据，对表show partitions $table_name 分区依然存在只是没有数据。 使用alter table app.app_discovery_content_info_da_tag drop partition (dt=&#39;${drop_dt}&#39;)，show partitions $table_name分区不存在，但是hadoop fs -ls 路径，改分区数据依然存在。 方案一： 将表改为内部表external =false，删分区（hdfs数据会删掉），再改回为外部表external=True。(对外部表的其他操作（如rename）也可以使用这个模式) 12345ALTER TABLE db_name.test_1 SET TBLPROPERTIES('EXTERNAL'='FALSE'); ALTER TABLE app.xxx DROP IF EXISTS PARTITION (dt&lt;'2019-04-01');ALTER TABLE db_name.test_1 SET TBLPROPERTIES('EXTERNAL'='TRUE'); 方案二： 先删分区，再用rm -r删数据 12ALTER TABLE some.table DROP IF EXISTS PARTITION (part="some")hdfs dfs -rm -R /path/to/table/basedir 改修改表记录 update 修改表记录 UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值 例如 update tt set name=&#39;Joe&#39;, salary=70000, managerid=3 where id=1; 修改字段名(列名)123456789101112CREATE TABLE test_change (a int, b int, c int);-- 修改列名a为a1ALTER TABLE test_change CHANGE a a1 INT; -- 修改列名a为a1，将a1的数据类型置为string，并将a1放在b列后-- 表的新结构： b int, a1 string, c intALTER TABLE test_change CHANGE a a1 STRING AFTER b; -- 修改列名b为b1，并将其置为第一列-- 表的新结构： b1 int, a string, c int ALTER TABLE test_change CHANGE b b1 INT FIRST; 修改表属性12345-- 内部表转外部表 alter table table_name set TBLPROPERTIES ('EXTERNAL'='TRUE'); -- 外部表转内部表alter table table_name set TBLPROPERTIES ('EXTERNAL'='FALSE'); 表的重命名12-- 非外部表会同时修改locationALTER TABLE table_name RENAME TO new_table_name 外部表需要修改location(更简洁的方法是，先将外部表转为内部表，重命名后再转为外部表) mv 表数据存储的hdfs目录：例如：hdfs dfs -mv /user/xxx/xx.db/test_orc/* /user/xxx/xx.db/test（将test_orc下的数据全部移动到test目录下） hdfs dfs -rm -r /user/mart_mobile/dev.db/test_orc（删除空目录） 移动之后执行set hive.msck.path.validation=ignore;msck repair table dev.test;修复分区 修改分区123456ALTER TABLE table_name PARTITION (dt='2008-08-08') SET LOCATION "new location";ALTER TABLE table_name PARTITION (dt='2008-08-08') RENAME TO PARTITION (dt='20080808');-- 将19分区修改到18(外部表的location可能不会变，待验证)alter table app.xxxx partition(dt='2019-01-19') rename to partition(dt='2019-01-18'); 修改location一般location在create table if not exist后，不会被触发，而如果删除表则会删除location，因此如果新建表的location错误指向了已经存在的location，需要手动修改新表location 命令行新建location目录： hadoop fs -mkdir &#39;hdfs://ns9/user/xxxx/xxx/app.db/table_name_new&#39; hive alter table 表名 set location &#39;hdfs://ns9/user/xxxx/xxx/app.db/table_name_new&#39; 验证：show create table 表名查看LOCATION是否更新 查常用查询语句 查看表字段介绍： desc 表名 select列名:https://stackoverflow.com/questions/26181454/just-get-column-names-from-hive-tableshow columns in 表名 查某一列：select 列名 from 表名 order by 排序(string类型字典序，数值类型按大小排) order by colname 默认升序 order by colname desc 降序 limit 返回对应行 SELECT * FROM table LIMIT 3; 返回前3行 SELECT * FROM table LIMIT 0,3; 返回前3行 SELECT * FROM table LIMIT 5,10; // 从第6行开始，最多返回10行（可能后面的数据不到10行）。即检索记录行 6-15 SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last 空值数计算：select sum(if(a is null,1,0)) from ... 空值率计算：select avg(if(a is null,1,0)) from ... 查询某个字段按字符分割后长度：size(split(sim_recall,&#39;,&#39;)) 直接查看表信息 通过执行log：Table 表名 stats: [numFiles=4, numRows=623232, totalSize=234324, rawDataSize=32243] 通过explain (发现有时通过这种方式查看numRows和count(*)结果不一致) sql的模糊匹配 %：表示任意0个或多个字符。可匹配任意类型和长度的字符select distinct * from app.xxxxxx where tb_name like &#39;app.xxx%&#39;;中%不能少(匹配a等) _： 表示任意单个字符。匹配单个任意字符 查询重复的项 定位重复行可先group by，记录下count，再对count排序，选count&gt;1的 1234567891011selectskufrom(selectsku, count(*) as cntfromapp.xxxxgroup by sku)awhere a.cnt &gt; 1 order by cnt desc limit 100; 数据中有两列A和B，查看是否存在以下情况：A B1 22 1可以先将AB按大小拼起来，再查询 1234567891011select sku, csku, round(score, 10) score, if(sku&gt;csku,concat_ws(',',csku,sku),concat_ws(',',sku,csku)) sku_csku_pairfrom app.xxxwhere dt = '2018-12-25' and tab_name = 'B' and sku_sr_type = '0' tips 使用严格模式优点 禁止不指定分区查询 避免join产生笛卡尔积 通过时间可以定位hadoop中文件是否被修改，在同一个集市中，如果有其他表指定的location错误，则很可能被修改。 如果location指定错误，例如新表指定到旧表路径中，那么会影响旧表。如果直接drop新表，而新表不是external表，则会删除location中文件，无法恢复。所以，需要修改新表的location，在修改之前不要对新表做任何操作。 concat_ws 需要数据类型为 string null where col=NULL 不会返回结果 where col is null 会返回为空的列 join left join on 保留左边表关键字信息（即使右表中没有匹配，也从左表返回所有的行 ），可以使用where 右表.col is not null实现join效果 right join on 保留右边关键字信息(即使左表中没有匹配，也从右表返回所有的行) inner join 两边都有才保留，也可写为join full join 只要其中一个表中存在匹配，就返回行 这么写中间表(${subSql}) t只查了一遍 123456789101112from($&#123;subSql&#125;) t insert into table $&#123;num_rows_tb&#125; partition ( tb_name = '$&#123;tb_name&#125;' ) select ct, '$&#123;select_dt&#125;', sysdate() insert overwrite table $&#123;null_rate_tb&#125; partition ( tb_name = '$&#123;tb_name&#125;' ) select split(kv, ':') [0] as k, cast(split(kv, ':') [1] as double) as v, '$&#123;select_dt&#125;' as select_dt lateral view explode(split(kvs, ',')) kvs as kv;" 注意 lateral view explode要写在from的后面，上述如果不将from写在最上方，应该写为如下，而不能将from放在最后 123456 select split(kv, ':') [0] as k, cast(split(kv, ':') [1] as double) as v, '$&#123;select_dt&#125;' as select_dtfrom($&#123;subSql&#125;) t lateral view explode(split(kvs, ',')) kvs as kv; map数过大不一定运行快，过大的map数会被pending。 在join时，如果on的是double数据类型，需要注意小数的精度不同可能造成=判定失败。可以用round(score, 2) score 只保留2位小数后再对比。 hdfs文件操作命令常用 hadoop fs -mkdir path创建文件夹 hadoop fs -put local_path hdfs_path 上传本机的HDFS文件。local_path指非hdfs路径，例如/home/name hadoop fs -get hdfs_path local_path 把HDFS的文件下载到本机 hadoop fs -cat file_name 读取HDFS文件 hadoop fs 和hdfs dfs 作用一样。都可以在本机上查看HDFS文件。 HDFS下的文件可以压缩存储，这样能够减少表查询时对Hadoop集群的IO。 从文件导数据到表 使用put将test.txt文件放到hdfs中：hadoop fs -put &#39;/home/test/test.txt&#39; /usr/xxxx/rec/xxx_data/test 使用load hdfs地址将数据导入表中：load data inpath &#39;/user/xxxx/rec/xxx_data/test/test.txt&#39; into table app.test; 导入成功，可以在select limit表检查确认一下。 hadoop fs -ls [path]查看HDFS文件名后面不加目录参数的话，默认当前用户的目录。ls会显示文件详细信息，如果只想ls出文件名，可以这么写：（参考 https://stackoverflow.com/questions/21569172/how-to-list-only-the-file-names-in-hdfs ） 1hadoop fs -ls &lt;HDFS_DIR&gt;|cut -d &apos; &apos; -f17 或者先sed &#39;1d&#39; 删除第一行（第一行是总述信息），将多个空格替换为一个空格(sed &#39;s/要被取代的字串/新的字串/g&#39;)再cut： 获取文件名：hadoop fs -ls | sed &#39;1d;s/ */ /g&#39; | cut -d\ -f8 获取文件名最后一列（这里是dt=2018-10-27）：hadoop fs -ls | sed &#39;1d;s/ */ /g&#39; | cut -d\ -f8 | xargs -n 1 basename 更优解：hadoop fs -ls /tmp | sed 1d | perl -wlne&#39;print +(split &quot; &quot;,$_,8)[7]&#39; 最终采用：hadoop fs -ls | sed &#39;1d;s/ */ /g&#39; | cut -d\ -f8 获取文件名列表 12345# 遍历文件。hdfs dfs -ls $&#123;path&#125; | sed '1d;s/ */ /g' | cut -d\ -f8| while read line do echo $&#123;line&#125;done 对每个文件，$(echo ${line}|cut -d &quot;=&quot; -f 2) 取分区数据。以=分割取第2个元素 补充：sed介绍： https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2856901.html 常用设置 集市限制小文件个数，可在脚本中加以下参数合并小文件： 1234set hive.merge.mapfiles = trueset hive.merge.mapredfiles = trueset hive.merge.size.per.task = 256000000set hive.merge.smallfiles.avgsize = 104857600]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-238-除自身以外数组的乘积]]></title>
    <url>%2F2019%2F03%2F05%2Fleetcode-238-%E9%99%A4%E8%87%AA%E8%BA%AB%E4%BB%A5%E5%A4%96%E6%95%B0%E7%BB%84%E7%9A%84%E4%B9%98%E7%A7%AF%2F</url>
    <content type="text"><![CDATA[题目链接除自身以外数组的乘积 题目描述给定长度为 n 的整数数组 nums，其中 n &gt; 1，返回输出数组 output ，其中 output[i] 等于 nums 中除 nums[i] 之外其余各元素的乘积。 示例: 12输入: [1,2,3,4]输出: [24,12,8,6] 说明: 请不要使用除法，且在 O(n) 时间复杂度内完成此题。 进阶：你可以在常数空间复杂度内完成这个题目吗？（ 出于对空间复杂度分析的目的，输出数组不被视为额外空间。） 解答方法一使用除法，注意有0的情况 123456789101112131415161718192021222324252627class Solution(object): def productExceptSelf(self, nums): """ :type nums: List[int] :rtype: List[int] """ n = len(nums) mul = 1 zero_cnt = 0 for i in range(n): if nums[i] == 0: zero_cnt += 1 if zero_cnt &gt; 1: # 2个0的情况 return [0] * n continue mul *= nums[i] ans = [] if zero_cnt &gt; 0: # 1个0的情况 for i in range(n): if nums[i] == 0: ans.append(mul) else: ans.append(0) return ans for i in range(n): # 没有0的情况 ans.append(mul // nums[i]) return ans]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ML实战记录]]></title>
    <url>%2F2019%2F03%2F01%2FML%E5%AE%9E%E6%88%98%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[详细过程见达观杯文本智能处理 提交记录 使用LSTM（Long short-term memory, LSTM），lstm参数(https://keras.io/zh/layers/recurrent/) 1keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False) 参数 units: 正整数，输出空间的维度。 activation: 要使用的激活函数 (详见 activations)。 如果传入 None，则不使用激活函数 (即 线性激活：a(x) = x)。 recurrent_activation: 用于循环时间步的激活函数 (详见 activations)。 默认：分段线性近似 sigmoid (hard_sigmoid)。 如果传入 None，则不使用激活函数 (即 线性激活：a(x) = x)。 use_bias: 布尔值，该层是否使用偏置向量。 kernel_initializer: kernel 权值矩阵的初始化器， 用于输入的线性转换 (详见 initializers)。 recurrent_initializer: recurrent_kernel 权值矩阵 的初始化器，用于循环层状态的线性转换 (详见 initializers)。 bias_initializer:偏置向量的初始化器 (详见initializers). unit_forget_bias: 布尔值。 如果为 True，初始化时，将忘记门的偏置加 1。 将其设置为 True 同时还会强制 bias_initializer=&quot;zeros&quot;。 这个建议来自 Jozefowicz et al.。 kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数 (详见 regularizer)。 recurrent_regularizer: 运用到 recurrent_kernel 权值矩阵的正则化函数 (详见 regularizer)。 bias_regularizer: 运用到偏置向量的正则化函数 (详见 regularizer)。 activity_regularizer: 运用到层输出（它的激活值）的正则化函数 (详见 regularizer)。 kernel_constraint: 运用到 kernel 权值矩阵的约束函数 (详见 constraints)。 recurrent_constraint: 运用到 recurrent_kernel 权值矩阵的约束函数 (详见 constraints)。 bias_constraint: 运用到偏置向量的约束函数 (详见 constraints)。 dropout: 在 0 和 1 之间的浮点数。 单元的丢弃比例，用于输入的线性转换。 recurrent_dropout: 在 0 和 1 之间的浮点数。 单元的丢弃比例，用于循环层状态的线性转换。 implementation: 实现模式，1 或 2。 模式 1 将把它的操作结构化为更多的小的点积和加法操作， 而模式 2 将把它们分批到更少，更大的操作中。 这些模式在不同的硬件和不同的应用中具有不同的性能配置文件。 return_sequences: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。 return_state: 布尔值。除了输出之外是否返回最后一个状态。 go_backwards: 布尔值 (默认 False)。 如果为 True，则向后处理输入序列并返回相反的序列。 stateful: 布尔值 (默认 False)。 如果为 True，则批次中索引 i 处的每个样品的最后状态 将用作下一批次中索引 i 样品的初始状态。 unroll: 布尔值 (默认 False)。 如果为 True，则网络将展开，否则将使用符号循环。 展开可以加速 RNN，但它往往会占用更多的内存。 展开只适用于短序列。 代码参考：https://github.com/Heitao5200/DGB/blob/master/model/model_code/RCNN.py 数据处理，输入为中心词、左词和右词 12345678910111213141516171819202122232425X_train_word_ids = tokenizer.texts_to_sequences(X_train)X_test_word_ids = tokenizer.texts_to_sequences(X_test)X_train_padded_seqs = pad_sequences(X_train_word_ids, maxlen=doc_len)X_test_padded_seqs = pad_sequences(X_test_word_ids, maxlen=doc_len)left_train_word_ids = [[len(vocab)] + x[:-1] for x in X_train_word_ids]left_test_word_ids = [[len(vocab)] + x[:-1] for x in X_test_word_ids]right_train_word_ids = [x[1:] + [len(vocab)] for x in X_train_word_ids]right_test_word_ids = [x[1:] + [len(vocab)] for x in X_test_word_ids]left_train_padded_seqs = pad_sequences(left_train_word_ids, maxlen=doc_len)left_test_padded_seqs = pad_sequences(left_test_word_ids, maxlen=doc_len)right_train_padded_seqs = pad_sequences(right_train_word_ids, maxlen=doc_len)right_test_padded_seqs = pad_sequences(right_test_word_ids, maxlen=doc_len)document = Input(shape = (doc_len, ), dtype = "int32")left_context = Input(shape = (doc_len, ), dtype = "int32")right_context = Input(shape = (doc_len, ), dtype = "int32")# embeddingembedder = Embedding(len(vocab) + 1, embedding_dim, input_length = doc_len)doc_embedding = embedder(document)l_embedding = embedder(left_context)r_embedding = embedder(right_context) 构建模型 1234567891011121314151617forward = LSTM(256, return_sequences = True)(l_embedding)backward = LSTM(256, return_sequences = True, go_backwards = True)(r_embedding)together = concatenate([forward, doc_embedding, backward], axis = 2)semantic = TimeDistributed(Dense(128, activation = "tanh"))(together)pool_rnn = Lambda(lambda x: backend.max(x, axis = 1), output_shape = (128, ))(semantic)output = Dense(19, activation = "softmax")(pool_rnn) model = Model(inputs = [document, left_context, right_context], outputs = output)model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])model.fit([X_train_padded_seqs, left_train_padded_seqs, right_train_padded_seqs],y_train, batch_size=32, epochs=1, validation_data=([X_test_padded_seqs, left_test_padded_seqs, right_test_padded_seqs], y_test)) 评价及预测 1234567891011score = model.evaluate(X_test_padded_seqs, y_test, verbose=0)print('Test loss:', score[0])print('Test accuracy:', score[1])## 特征转换xx_test_word_ids = tokenizer.texts_to_sequences(df_test['word_seg'])xx_test_padded_seqs = pad_sequences(xx_test_word_ids, maxlen=doc_len)## 预测pred_prob = model.predict(xx_test_padded_seqs)pred = pred_prob.argmax(axis=1) 模型融合 123models = [KNeighborsClassifier(n_neighbors=5,n_jobs = -1),RandomForestClassifier(random_state=0, n_jobs=-1,n_estimators = 100, max_depth = 3),XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1,n_estimators = 100, max_depth = 3)]S_train, S_test = stacking(models, X_train, y_train, X_test, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None, metric=accuracy_score, n_folds=4, stratified=True, shuffle=True, random_state=0, verbose=2) 各参数含义如下 The stacking function takes several inputs: models: the first level models we defined earlier X_train, y_train, X_test: our data regression: Boolean indicating whether we want to use the function for regression. In our case set to False since this is a classification mode: using the earlier describe out-of-fold during cross-validation needs_proba: Boolean indicating whether you need the probabilities of class labels save_dir: save the result to directory Boolean metric: what evaluation metric to use (we imported the accuracy_score in the beginning) n_folds: how many folds to use for cross-validation stratified: whether to use stratified cross-validation shuffle: whether to shuffle the data random_state: setting a random state for reproducibility verbose: 2 here refers to printing all info 最终使用XGB预测 123model = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=100, max_depth=3) model = model.fit(S_train, y_train) y_pred = model.predict(S_test)]]></content>
      <categories>
        <category>MachineLearning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-43-字符串相乘]]></title>
    <url>%2F2019%2F03%2F01%2Fleetcode-43-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9B%B8%E4%B9%98%2F</url>
    <content type="text"><![CDATA[题目链接字符串相乘 题目描述给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。 示例 1: 12输入: num1 = &quot;2&quot;, num2 = &quot;3&quot;输出: &quot;6&quot; 示例 2: 12输入: num1 = &quot;123&quot;, num2 = &quot;456&quot;输出: &quot;56088&quot; 说明： num1 和 num2 的长度小于110。 num1 和 num2 只包含数字 0-9。 num1 和 num2 均不以零开头，除非是数字 0 本身。 不能使用任何标准库的大数类型（比如 BigInteger）或直接将输入转换为整数来处理。 解答方法一直接转为整数计算，理论上不符合题意，但是目前leetcode无法check。大致有以下2种方式 12return str(int(num1) * int(num2))return str(eval(num1)*eval(num2)) 方法二竖乘法，将手工运算方法转为代码。这种方式需要注意细节。 方法三这种方法来自：Easiest JAVA Solution with Graph Explanation a*b=c，则len(c)&lt;=len(a)+len(b)，如999*999 &lt; 999*1000，所以999*999的值不会超过6位，可以设置长度为len(a)+len(b)的列表来存最后的结果。 使用竖乘法，num1的第i位和num2的第j位，结果存在i+j和i+j+1位 1234567891011121314151617181920212223242526class Solution(object): def multiply(self, num1, num2): """ :type num1: str :type num2: str :rtype: str """ ans = [0 for i in range(len(num1) + len(num2))] for i in range(len(num1))[::-1]: for j in range(len(num2))[::-1]: mul = eval(num1[i]) * eval(num2[j]) ans[i + j + 1] += mul # 先加到ans[i+j+1]再处理进位；而不是分2位加到ans[i+j]和ans[i+j+1]再处理进位。 ans[i + j] += ans[i + j + 1] // 10 ans[i + j + 1] %= 10 # 处理高位的0 ans_str = "" for i in range(len(ans)): if not (len(ans_str) == 0 and ans[i] == 0): # 首位的0跳过 ans_str += str(ans[i]) if len(ans_str) == 0: return "0" return ans_str]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-11-盛最多水的容器]]></title>
    <url>%2F2019%2F02%2F28%2Fleetcode-11-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[题目链接盛最多水的容器 题目描述给定 n 个非负整数 a1，a2，…，an，每个数代表坐标中的一个点 (i, ai) 。在坐标内画 n 条垂直线，垂直线 i 的两个端点分别为 (i, ai) 和 (i, 0)。找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 说明：你不能倾斜容器，且 n 的值至少为 2。 图中垂直线代表输入数组 [1,8,6,2,5,4,8,3,7]。在此情况下，容器能够容纳水（表示为蓝色部分）的最大值为 49。 示例: 12输入: [1,8,6,2,5,4,8,3,7]输出: 49 解答方法一枚举法，提交超时，时间复杂度为O(n^2) 123456789101112class Solution(object): def maxArea(self, height): """ :type height: List[int] :rtype: int """ n = len(height) ans = 0 for i in range(n): for j in range(i + 1, n): ans = max(ans, (j - i) * min(height[i], height[j])) return ans 方法二双指针法。使用2个指针指向列表的首尾，向中间移动，使用ans记录最大面积，更新指向值更小的指针。这种方式只需遍历一遍，时间复杂度为O(n) 12345678910111213141516class Solution(object): def maxArea(self, height): """ :type height: List[int] :rtype: int """ l = 0 r = len(height) - 1 ans = 0 while l &lt; r: ans = max(ans, (r - l) * min(height[l], height[r])) if height[l] &lt; height[r]: l += 1 else: r -= 1 return ans]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-557-反转字符串中的单词III]]></title>
    <url>%2F2019%2F02%2F27%2Fleetcode-557-%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E5%8D%95%E8%AF%8DIII%2F</url>
    <content type="text"><![CDATA[题目链接反转字符串中的单词 III 题目描述给定一个字符串，你需要反转字符串中每个单词的字符顺序，同时仍保留空格和单词的初始顺序。 示例 1: 12输入: &quot;Let&apos;s take LeetCode contest&quot;输出: &quot;s&apos;teL ekat edoCteeL tsetnoc&quot; 注意：在字符串中，每个单词由单个空格分隔，并且字符串中不会有任何额外的空格。 解答方法一先split，然后每个单词反转，最后拼接 12345678910class Solution(object): def reverseWords(self, s): """ :type s: str :rtype: str """ ans = [] for w in s.split(): ans.append(w[::-1]) return " ".join(ans)]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-344-反转字符串]]></title>
    <url>%2F2019%2F02%2F27%2Fleetcode-344-%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[题目链接反转字符串 题目描述编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 char[] 的形式给出。 不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O(1) 的额外空间解决这一问题。 你可以假设数组中的所有字符都是 ASCII 码表中的可打印字符。 示例 1： 12输入：[&quot;h&quot;,&quot;e&quot;,&quot;l&quot;,&quot;l&quot;,&quot;o&quot;]输出：[&quot;o&quot;,&quot;l&quot;,&quot;l&quot;,&quot;e&quot;,&quot;h&quot;] 示例 2： 12输入：[&quot;H&quot;,&quot;a&quot;,&quot;n&quot;,&quot;n&quot;,&quot;a&quot;,&quot;h&quot;]输出：[&quot;h&quot;,&quot;a&quot;,&quot;n&quot;,&quot;n&quot;,&quot;a&quot;,&quot;H&quot;] 解答方法一从头尾两个方向遍历列表，交换元素 123456789101112131415class Solution(object): def reverseString(self, s): """ :type s: List[str] :rtype: None Do not return anything, modify s in-place instead. """ n = len(s) if n &lt;= 1: return start = 0 end = n - 1 while (start &lt; end): s[start], s[end] = s[end], s[start] start += 1 end -= 1]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-26-删除排序数组中的重复项]]></title>
    <url>%2F2019%2F02%2F27%2Fleetcode-26-%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[题目链接删除排序数组中的重复项 题目描述给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。 不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。 示例 1: 12345给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。 示例 2: 12345给定 nums = [0,0,1,1,1,2,2,3,3,4],函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4。你不需要考虑数组中超出新长度后面的元素。 说明: 为什么返回数值是整数，但输出的答案是数组呢? 请注意，输入数组是以“引用”方式传递的，这意味着在函数里修改输入数组对于调用者是可见的。 你可以想象内部操作如下: 12345678// nums 是以“引用”方式传递的。也就是说，不对实参做任何拷贝int len = removeDuplicates(nums);// 在函数里修改输入数组对于调用者是可见的。// 根据你的函数返回的长度, 它会打印出数组中该长度范围内的所有元素。for (int i = 0; i &lt; len; i++) &#123; print(nums[i]);&#125; 解答方法一如注释 1234567891011121314151617181920212223242526class Solution(object): def removeDuplicates(self, nums): """ :type nums: List[int] :rtype: int """ n = len(nums) if n &lt;= 1: return n p = 1 # 记录列表当前插入数据位置 q = 1 # 记录当前遍历位置 # 首先将p和q初始化到正确位置 while p &lt; n and nums[p - 1] != nums[p]: # 注意p&lt;n在前 p += 1 while q &lt; n and nums[q - 1] != nums[q]: q += 1 while p &lt; n and q &lt; n: if nums[q - 1] == nums[q]: q += 1 else: nums[p] = nums[q] p += 1 q += 1 return p 测试用例 12345print(removeDuplicates([1, 1, 2]))print(removeDuplicates([0, 0, 1, 1, 1, 2, 2, 3, 3, 4]))print(removeDuplicates([]))print(removeDuplicates([1, 2]))print(removeDuplicates([1, 2, 2]))]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-20-有效的括号]]></title>
    <url>%2F2019%2F02%2F27%2Fleetcode-20-%E6%9C%89%E6%95%88%E7%9A%84%E6%8B%AC%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[题目链接有效的括号 题目描述给定一个只包括 &#39;(&#39;，&#39;)&#39;，&#39;{&#39;，&#39;}&#39;，&#39;[&#39;，&#39;]&#39; 的字符串，判断字符串是否有效。 有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 注意空字符串可被认为是有效字符串。 示例 1: 12输入: &quot;()&quot;输出: true 示例 2: 12输入: &quot;()[]&#123;&#125;&quot;输出: true 示例 3: 12输入: &quot;(]&quot;输出: false 示例 4: 12输入: &quot;([)]&quot;输出: false 示例 5: 12输入: &quot;&#123;[]&#125;&quot;输出: true 解答方法一使用列表模拟栈，能匹配就pop，不能则返回false。最终栈空返回true，否则返回false。 123456789101112131415161718192021class Solution(object): def isValid(self, s): """ :type s: str :rtype: bool """ re_dict = &#123;"(": ")", "&#123;": "&#125;", "[": "]"&#125; stack = [] for t in s: if t not in re_dict: if len(stack) == 0: return False elif stack[-1] != t: return False else: stack.pop() else: stack.append(re_dict[t]) if (len(stack)): return False return True]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-16-最接近的三数之和]]></title>
    <url>%2F2019%2F02%2F02%2Fleetcode-16-%E6%9C%80%E6%8E%A5%E8%BF%91%E7%9A%84%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[题目链接最接近的三数之和 题目描述给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。 123例如，给定数组 nums = [-1，2，1，-4], 和 target = 1.与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2). 解答方法一注意这里只需要返回三个数的和，而不是返回这三个数。这里使用枚举法 1234567891011121314151617181920class Solution: def threeSumClosest(self, nums, target): """ :type nums: List[int] :type target: int :rtype: int """ n = len(nums) ans = 0 # 存3数之和 sub_min = float('inf') # 存abs(target - s)的最小值 for i in range(n): for j in range(i + 1, n): for k in range(j + 1, n): s = nums[i] + nums[j] + nums[k] if s == target: # 如果s==target直接返回 return s if abs(target - s) &lt; sub_min: sub_min = abs(target - s) ans = s return ans 一部分测试用例： 12print(threeSumClosest([-1, 2, 1, -4], 1))# 2]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-15-三数之和]]></title>
    <url>%2F2019%2F01%2F30%2Fleetcode-15-%E4%B8%89%E6%95%B0%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[题目链接三数之和 题目描述给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。 注意：答案中不可以包含重复的三元组。 1234567例如, 给定数组 nums = [-1, 0, 1, 2, -1, -4]，满足要求的三元组集合为：[ [-1, 0, 1], [-1, -1, 2]] 解答方法一 对列表中元素排序 遍历，对当前元素 nums[i]，相当于求 nums[i+1:] 的两数之和为target = 0-nums[i]。在位置 i 之前的元素不会再参与到计算中，因为假设在 nums[j] (j&lt;i) 和某元素nums[x]之和为target，那么在遍历位置j时已经将[nums[j],nums[i], nums[x]]加入结果列表 使用二分法求排序列表中两元素之和为 target 123456789101112131415161718192021222324252627class Solution: def threeSum(self, nums): """ :type nums: List[int] :rtype: List[List[int]] """ nums = sorted(nums) n = len(nums) ans = [] for i in range(n): if i &gt; 0 and i &lt; n and nums[i] == nums[i - 1]: continue target = 0 - nums[i] start = i + 1 end = n - 1 while start &lt; end: if nums[start] + nums[end] &lt; target: start += 1 elif nums[start] + nums[end] &gt; target: end -= 1 else: # 避免ans中有重复元素，这里应该能优化 if [nums[i], nums[start], nums[end]] not in ans: ans.append([nums[i], nums[start], nums[end]]) start += 1 end -= 1 return ans 一部分测试用例： 1234print(threeSum([1, -1, -1, 4, 2, 1, 0]))# [[-1, -1, 2], [-1, 0, 1]]print(threeSum([-2,0,0,2,2]))# [[-2, 0, 2]]]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-14-最长公共前缀]]></title>
    <url>%2F2019%2F01%2F30%2Fleetcode-14-%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80%2F</url>
    <content type="text"><![CDATA[题目链接最长公共前缀 题目描述编写一个函数来查找字符串数组中的最长公共前缀。 如果不存在公共前缀，返回空字符串 &quot;&quot;。 示例 1: 12输入: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]输出: &quot;fl&quot; 示例 2: 123输入: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]输出: &quot;&quot;解释: 输入不存在公共前缀。 说明: 所有输入只包含小写字母 a-z 。 解答方法一本题注意不要理解为公共子串。 12345678910111213141516171819202122class Solution: def longestCommonPrefix(self, strs): """ :type strs: List[str] :rtype: str """ ans = "" if len(strs) == 0: # 输入[]需返回，否则min报错 min() arg is an empty sequence return ans min_len = min(map(len, strs)) # 列表中元素最短len，避免后续 string index out of range flag = 1 for i in range(min_len): # 列表中元素最短len for j in range(1, len(strs)): # 列表中字符的个数 if strs[0][i] == strs[j][i]: continue else: flag = 0 break if flag == 0: break ans += strs[0][i] return ans 一部分测试用例： 1234567891011print(longestCommonPrefix([]))print(longestCommonPrefix([&quot;&quot;]))print(longestCommonPrefix([&quot;flower&quot;, &quot;flow&quot;, &quot;flight&quot;]))# flprint(longestCommonPrefix([&quot;dog&quot;, &quot;racecar&quot;, &quot;car&quot;]))print(longestCommonPrefix([&quot;aa&quot;, &quot;a&quot;]))# a]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-8-字符串转换整数(atoi)]]></title>
    <url>%2F2019%2F01%2F29%2Fleetcode-8-%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2%E6%95%B4%E6%95%B0-atoi%2F</url>
    <content type="text"><![CDATA[题目链接字符串转换整数 (atoi) 题目描述请你来实现一个 atoi 函数，使其能将字符串转换成整数。 首先，该函数会根据需要丢弃无用的开头空格字符，直到寻找到第一个非空格的字符为止。 当我们寻找到的第一个非空字符为正或者负号时，则将该符号与之后面尽可能多的连续数字组合起来，作为该整数的正负号；假如第一个非空字符是数字，则直接将其与之后连续的数字字符组合起来，形成整数。 该字符串除了有效的整数部分之后也可能会存在多余的字符，这些字符可以被忽略，它们对于函数不应该造成影响。 注意：假如该字符串中的第一个非空格字符不是一个有效整数字符、字符串为空或字符串仅包含空白字符时，则你的函数不需要进行转换。 在任何情况下，若函数不能进行有效的转换时，请返回 0。 说明： 假设我们的环境只能存储 32 位大小的有符号整数，那么其数值范围为 [−231, 231 − 1]。如果数值超过这个范围，qing返回 INT_MAX (231 − 1) 或 INT_MIN (−231) 。 示例 1: 12输入: &quot;42&quot;输出: 42 示例 2: 1234输入: &quot; -42&quot;输出: -42解释: 第一个非空白字符为 &apos;-&apos;, 它是一个负号。 我们尽可能将负号与后面所有连续出现的数字组合起来，最后得到 -42 。 示例 3: 123输入: &quot;4193 with words&quot;输出: 4193解释: 转换截止于数字 &apos;3&apos; ，因为它的下一个字符不为数字。 示例 4: 1234输入: &quot;words and 987&quot;输出: 0解释: 第一个非空字符是 &apos;w&apos;, 但它不是数字或正、负号。 因此无法执行有效的转换。 示例 5: 1234输入: &quot;-91283472332&quot;输出: -2147483648解释: 数字 &quot;-91283472332&quot; 超过 32 位有符号整数范围。 因此返回 INT_MIN (−231) 。 解答方法一难度在于理解题意，以及考虑各种到各种情况 1234567891011121314151617181920212223242526272829303132333435363738class Solution: def myAtoi(self, str): """ :type str: str :rtype: int """ str = str.strip() # 如果数字中间有非数字，直接终止。所以不能"".join(str.split())去掉所有空格 INT_MAX = pow(2, 31) - 1 INT_MIN = -pow(2, 31) ans_str = "" if len(str) == 0: return 0 if str[0] == '+' or str[0] == '-': ans_str += str[0] str = str[1:].lstrip('0') for i in range(len(str)): if str[i].isdigit(): ans_str += str[i] else: break if len(ans_str) == 1: return 0 elif str[0].isdigit(): str = str.lstrip('0') for i in range(len(str)): if str[i].isdigit(): ans_str += str[i] else: break if len(ans_str) == 0: return 0 else: return 0 ans = eval(ans_str) - eval('0') if ans &lt; 0: return max(INT_MIN, ans) else: return min(INT_MAX, ans) 一部分测试用例： 1234567891011121314151617181920212223242526272829303132&quot;4193 with words 234234&quot;4193&quot; 0000000000012345678&quot;12345678&quot;wcd 123&quot;0&quot; -42&quot;-42&quot;3.12&quot;3&quot;+a 124&quot;0&quot;+&quot;0&quot; 0000000&quot;0&quot; +0 123&quot;0&quot;-000000000000001&quot;-1&quot; +004500&quot;4500]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-5-最长回文子串]]></title>
    <url>%2F2019%2F01%2F28%2Fleetcode-5-%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[题目链接最长回文子串 题目描述给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。 示例 1： 123输入: &quot;babad&quot;输出: &quot;bab&quot;注意: &quot;aba&quot; 也是一个有效答案。 示例 2： 12输入: &quot;cbbd&quot;输出: &quot;bb&quot; 解答方法一遍历字符串s的所有子串，判断是否为回文串。找出长度最大的回文串。 1234567891011121314151617class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ r_s = s[::-1] n = len(s) max_len = 0 ans = "" for x in range(1, n + 1): # 子串长度 for i in range(n + 1 - x): # 偏移量 if s[i:i + x] == s[i:i + x][::-1]: if x &gt; max_len: max_len = x ans = s[i:i + x] return ans 方法二回文串是对称的，长度为奇数的回文串对称位置是中间的字符，偶数对称位置是中间2个字符间的空隙。可以遍历每个字符和中间位置，同时向左和右扩展，直到字符不同，或达到边界。为了不分奇偶情况讨论，在字符间填充符号#，遍历每个位置。 123456789101112131415161718192021class Solution: def longestPalindrome(self, s): """ :type s: str :rtype: str """ ss = '#' + '#'.join(s) + '#' n = len(ss) rem = [0] * n # 记录各个位置最长回文串半径 mid_index = 0 max_r = 0 for i in range(1, n): # 当前位置 for j in range(1, i + 1): # 半径长度 if (i + j) &lt; n and ss[i - j] == ss[i + j]: rem[i] += 1 if max_r &lt; rem[i]: max_r = rem[i] mid_index = i else: break return ss[(mid_index - max_r):(mid_index + max_r + 1)].replace("#","")]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-4-寻找两个有序数组的中位数]]></title>
    <url>%2F2019%2F01%2F28%2Fleetcode-4-%E5%AF%BB%E6%89%BE%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E7%9A%84%E4%B8%AD%E4%BD%8D%E6%95%B0%2F</url>
    <content type="text"><![CDATA[题目链接寻找两个有序数组的中位数 题目描述给定两个大小为 m 和 n 的有序数组 nums1 和 nums2。 请你找出这两个有序数组的中位数，并且要求算法的时间复杂度为 O(log(m + n))。 你可以假设 nums1 和 nums2 不会同时为空。 示例 1: 1234nums1 = [1, 3]nums2 = [2]则中位数是 2.0 示例 2: 1234nums1 = [1, 2]nums2 = [3, 4]则中位数是 (2 + 3)/2 = 2.5 解答思路是对两个数组排序后求中位数。 方法一使用sorted排序，取中位数 123456789101112131415def twoSum(nums, target): n=len(nums) for i in range(n):class Solution: def findMedianSortedArrays(self, nums1, nums2): """ :type nums1: List[int] :type nums2: List[int] :rtype: float """ nums = sorted(nums1 + nums2) l = len(nums) if l % 2 == 0: return (nums[l // 2 - 1] + nums[l // 2]) / 2 else: return nums[l // 2] 方法二自己实现排序，然后取中位数。 1234567891011121314151617181920212223242526272829303132class Solution(object): def findMedianSortedArrays(self, nums1, nums2): """ :type nums1: List[int] :type nums2: List[int] :rtype: float """ m = len(nums1) n = len(nums2) sort_nums = [] i = 0 j = 0 l = m + n now_index = 0 while i &lt; m and j &lt; n: if nums1[i] &lt; nums2[j]: sort_nums.append(nums1[i]) i += 1 now_index += 1 else: sort_nums.append(nums2[j]) j += 1 now_index += 1 if i &lt; m: sort_nums.extend(nums1[i:]) if j &lt; n: sort_nums.extend(nums2[j:]) if l % 2 == 0: print((sort_nums[l // 2 - 1] + sort_nums[l // 2]) / 2) else: print(sort_nums[l // 2])]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-功能完善-置顶-评论等]]></title>
    <url>%2F2019%2F01%2F28%2Fhexo-%E5%8A%9F%E8%83%BD%E5%AE%8C%E5%96%84-%E7%BD%AE%E9%A1%B6-%E8%AF%84%E8%AE%BA%E7%AD%89%2F</url>
    <content type="text"><![CDATA[置顶修改Hexo文件夹下node_modules/hexo-generator-index/lib/generator.js，添加如下代码 1234567891011posts.data = posts.data.sort(function(first, second) &#123; if (first.top &amp;&amp; second.top) &#123; // 两篇文章top都有定义 return first.top == second.top ? second.date - first.date : second.top - first.top //若top值一样则按照文章日期降序排, 否则按照top值降序排 &#125; else if (first.top &amp;&amp; !second.top) &#123; // 以下是只有一篇文章top有定义，将有top的排在前面 return -1; &#125; else if (!first.top &amp;&amp; second.top) &#123; return 1; &#125; else &#123; return second.date - first.date; // 都没定义top，按照文章日期降序排 &#125; &#125;); 添加后完整代码如下 123456789101112131415161718192021222324252627282930'use strict';var pagination = require('hexo-pagination');module.exports = function(locals) &#123; var config = this.config; var posts = locals.posts.sort(config.index_generator.order_by); posts.data = posts.data.sort(function(first, second) &#123; if (first.top &amp;&amp; second.top) &#123; // 两篇文章top都有定义 return first.top == second.top ? second.date - first.date : second.top - first.top //若top值一样则按照文章日期降序排, 否则按照top值降序排 &#125; else if (first.top &amp;&amp; !second.top) &#123; // 以下是只有一篇文章top有定义，将有top的排在前面 return -1; &#125; else if (!first.top &amp;&amp; second.top) &#123; return 1; &#125; else &#123; return second.date - first.date; // 都没定义top，按照文章日期降序排 &#125; &#125;); var paginationDir = config.pagination_dir || 'page'; var path = config.index_generator.path || ''; return pagination(path, posts, &#123; perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: &#123; __index: true &#125; &#125;);&#125;; 在需要置顶的文章front-matter中添加top值（top值越大文章越靠前） 12345title: hexo 功能完善(置顶 评论等)date: 2019-01-27 09:37:37tags: hexocategories: hexotop: 2 添加阅读量及访问量统计Next升级后添加访问量升级到v6后只需要修改next/_config.yml，则可以在底部显示访问量 12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye post_views: false # 由于已经使用leancloud_visitors进行了统计，这里置为false post_views_icon: eye 如果进入文章出现这种报错 阅读次数： Counter not initialized! More info at console err msg. 可参考：LearnCloud报错解决 如果加入的这行报错：- type: leancloud_counter_securi ...，是因为缩进不对，正确格式如下 12345deploy: - type: git repository: git@github.com:usrname/usrname.github.io.git branch: master - type: leancloud_counter_security_sync 旧版本添加访问量参考：Hexo博客Next主题添加文章阅读量及网站访问信息 写的很详细，需要注意的是最后“显示统计标签”，修改next/layout/_partials/footer.swig文件，在该文件开头需要加上 12&lt;script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt; 访问量无法显示之前如果配置过访问量但现在已无法显示的原因是不蒜子换域名了，导致之前配置的js文件不能正常调用，所以就无法显示。 修改上方文件，将https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js修改为https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js，就可以显示了。 另外，使用hexo s部署在本地预览效果的时候，uv数和pv数会过大，这是由于不蒜子用户使用一个存储空间，所以使用localhost:4000进行本地预览的时候会导致数字异常，这是正常现象，只需要将博客部署至云端即可恢复正常。 Next主题升级 将旧hexo/themes/next备份，然后删除 克隆新版本的nextgit clone https://github.com/theme-next/hexo-theme-next themes/next 参照旧版本设定相关配置，完毕后删除旧版本备份。 显示中文需修改 hexo/_config.yml：由language: zh-Hans修改为language: zh-CN 添加评论Next 6 已经集成这个功能了，可以使用和访问量同一个应用。 在云端的 leancloud 应用中创建一个名为 Comment 的类，使用默认的 ACL 权限设置。 在主题配置文件中设置 app_id 和 app_key 即可。 123456789101112valine: enable: true # When enable is set to be true, leancloud_visitors is recommended to be closed for the re-initialization problem within different leancloud adk version. appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier, See: https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 在此处输入评论 # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: false # leancloud-counter-security is not supported for now. When visitor is set to be true, appid and appkey are recommended to be the same as leancloud_visitors' for counter compatibility. Article reading statistic https://valine.js.org/visitor.html comment_count: true # if false, comment count will only be displayed in post page, not in home page 添加搜索安装插件：在hexo根目录下运行npm install hexo-generator-searchdb --save 修改next/_config.yml 1234567891011# Local search# Dependencies: https://github.com/theme-next/hexo-generator-searchdblocal_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 # unescape html strings to the readable one unescape: false 修改字体及高亮这部分可参考：Hexo Next博客优化 行间距及行内代码字体颜色调整由于使用的是Mist模式，所以需要修改：hexo/themes/next/source/css/_schemes/Mist/_base.styl 12345678910111213141516171819202122232425262728293031323334353637// Tags// --------------------------------------------------.posts-expand .post-body ul li &#123; list-style: disc;&#125;code &#123; padding: 2px 4px; word-wrap: break-word; color: rgba(244, 67, 54, 0.66); background: rgba(238, 238, 238, 0.5); border-radius: 3px; font-size: 14px;&#125;h1, h2, h3, h4, h5, h6 &#123; margin: 40px 0 10px; &#125;h2 &#123; font-size: 32px;&#125;h3 &#123; font-size: 24px;&#125;blockquote &#123; border-left: 4px solid #42b983;&#125;p &#123; margin: 0 0 25px 0; &#125;a &#123; border-bottom-color: $grey-light; &#125;hr &#123; margin: 20px 0; height: 2px;&#125; 修改链接颜色修改next/source/css/_common/components/post/post.styl，添加以下代码 12345678.post-body p a&#123; color: #0593d3; border-bottom: none; &amp;:hover &#123; color: #ea6753; &#125;&#125; 修改高亮颜色默认的高亮颜色有些暗，可以修改hexo/themes/next/source/css/_common/components/highlight/theme.styl 因为使用的高亮是”normal”，所以修改这一部分 1234567891011121314151617if $highlight_theme == "normal" $highlight-background = #f8f9fa $highlight-current-line = #efefef $highlight-selection = #d6d6d6 $highlight-foreground = #4d4d4c $highlight-comment = #8e908c $highlight-red = #c82829 $highlight-orange = #f5871f $highlight-yellow = #eab700 $highlight-green = #008000 $highlight-aqua = #3e999f $highlight-blue = #4271ae $highlight-purple = #AA22FF $highlight-gutter = &#123; color: #869194, bg-color: #eff2f3 &#125;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-1-两数之和]]></title>
    <url>%2F2019%2F01%2F26%2Fleetcode-1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[题目链接两数之和 题目描述给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例: 1234给定 nums = [2, 7, 11, 15], target = 9因为 nums[0] + nums[1] = 2 + 7 = 9所以返回 [0, 1] 解答方法一遍历两次，如果两个不同元素之和为target，返回下标。 123456def twoSum(nums, target): n=len(nums) for i in range(n): for j in range(i+1,n): if nums[i]+nums[j]==target: return [i,j] 方法二遍历一次，使用字典m_dict记录当前元素下标和匹配的值， 设当前元素为p，下标为i，那么应该寻找的元素q=target-p，使用字典m_dict记录{q:i} 遍历数组时，如果当前元素x在字典m_dict中，则返回m_dict[x]和当前下标 1234567891011def twoSum(self, nums, target): """ :type nums: List[int] :type target: int :rtype: List[int] """ m_dict=&#123;&#125; for i in range(len(nums)): if nums[i] in m_dict: return [m_dict[nums[i]],i] m_dict[target-nums[i]]=i 代码https://github.com/ywtail/leetcode/blob/master/1_1.py]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy使用记录]]></title>
    <url>%2F2018%2F03%2F22%2FScrapy%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[安装1pip install Scrapy 创建项目1scrapy startproject tutorial 该命令将会创建包含下列内容的 tutorial 目录: 12345678910tutorial/ scrapy.cfg tutorial/ __init__.py items.py pipelines.py settings.py spiders/ __init__.py ... 这些文件分别是: scrapy.cfg: 项目的配置文件 tutorial/: 该项目的python模块。之后您将在此加入代码。 tutorial/items.py: 项目中的item文件. tutorial/pipelines.py: 项目中的pipelines文件. tutorial/settings.py: 项目的设置文件. tutorial/spiders/: 放置spider代码的目录. 定义Item，Item用来保存爬去的数据，与python中的dict类似。 编写爬虫，保存在 tutorial/spiders 目录下的 dmoz_spider.py 文件中： 1234567891011121314import scrapyclass DmozSpider(scrapy.Spider): name = "dmoz" allowed_domains = ["dmoz.org"] start_urls = [ "http://www.dmoz.org/Computers/Programming/Languages/Python/Books/", "http://www.dmoz.org/Computers/Programming/Languages/Python/Resources/" ] def parse(self, response): filename = response.url.split("/")[-2] with open(filename, 'wb') as f: f.write(response.body) 运行进入项目的根目录，执行下列命令启动spider: 1scrapy crawl dmoz 其中，dmoz 为tutorial/spiders 目录下的 dmoz_spider.py 文件中为爬虫设置的name。就像 parse 方法指定的那样，有两个包含url所对应的内容的文件被创建了: Book , Resources 。 提取ItemSelectors选择器简介从网页中提取数据有很多方法。Scrapy使用了一种基于 XPath 和 CSS 表达式机制: Scrapy Selectors。 关于selector和其他提取机制的信息请参考 Selector文档 。 这里给出XPath表达式的例子及对应的含义: /html/head/title: 选择HTML文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素 /html/head/title/text(): 选择上面提到的 &lt;title&gt; 元素的文字 //td: 选择所有的 &lt;td&gt; 元素 //div[@class=&quot;mine&quot;]: 选择所有具有 class=&quot;mine&quot; 属性的 div 元素 上边仅仅是几个简单的XPath例子，XPath实际上要比这远远强大的多。 如果您想了解的更多，我们推荐 这篇XPath教程 。 在Shell中尝试Selector选择器为了介绍Selector的使用方法，接下来我们将要使用内置的 Scrapy shell 。Scrapy Shell需要您预装好IPython(一个扩展的Python终端)。 您需要进入项目的根目录，执行下列命令来启动shell: 1scrapy shell &quot;http://www.dmoz.org/Computers/Programming/Languages/Python/Books/&quot; 保存爬取到的数据最简单存储爬取的数据的方式是使用 Feed exports: 1scrapy crawl dmoz -o items.json 该命令将采用 JSON 格式对爬取的数据进行序列化，生成 items.json 文件。 其他 以为是机器人不允许爬取，更改 settings.py，将 ROBOTSTXT_OBEY 置为 False 获取的中文是Unicode，不方便阅读，可以使用BeautifulSoup，不仅可以提取网页结构中的文字，还可以显示为中文。 123@staticmethoddef get_plain_text(html): # 不仅可以解析html，还可以将unicode编码输出为汉字 return BeautifulSoup(html, "lxml").text 使用xpath定位兄弟结点的方法：//div[@id=&#39;D&#39;]/preceding-sibling::div[1]和//div[@id=&#39;D&#39;]/following-sibling::div[1]参考：Python selenium —— 父子、兄弟、相邻节点定位方式详解preceding-sibling，其能够获取当前节点的所有同级哥哥节点，注意括号里的标号，1 代表着离当前节点最近的一个哥哥节点，数字越大表示离当前节点越远，当然，xpath轴：preceding也可以，但是使用起来比较复杂，它获取到的是该节点之前的所有非祖先节点。following-sibling，跟preceding-sibling类似，它的作用是获取当前节点的所有同级弟弟节点，同样，1 代表离当前节点最近的一个弟弟节点，数字越大表示离当前节点越远 node()[not(self::div)]用法参考：https://stackoverflow.com/questions/4455684/xpath-get-only-node-content-without-other-elements表示不要它自己的孩子div结点。例如如下代码，只要“ This is some text”，而不要h1和div标签内的内容，可以使用/div/node()[not(self::h1|self::div)] 12345&lt;div&gt; This is some text &lt;h1&gt;This is a title&lt;/h1&gt; &lt;div&gt;Some other content&lt;/div&gt;&lt;/div&gt; 对于.py中有需要读写文件的部分，注意文件的路径！如果使用相对路径，程序会从执行scrapy scrawl所在目录的相对路径找。如果每次执行crawl命令所在的目录不同，那么就会报错IOError: [Errno 2] No such file or directory: &#39;t.txt&#39;。所以，最好使用绝对路径，或者每次执行的命令的目录都相同（例如每次都在根目录执行）。 参考 Scrapy 0.24.6 文档 Python selenium —— 父子、兄弟、相邻节点定位方式详解 https://stackoverflow.com/questions/4455684/xpath-get-only-node-content-without-other-elements]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Scrapy</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构(1): 基本数据结构]]></title>
    <url>%2F2018%2F03%2F05%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-1-%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[逻辑结构和物理结构逻辑结构 集合结构：同属一集合，之间没有关系 线性结构：一对一关系，有顺序 树形结构：一对多的层次关系 图形结构：多对多的关系 物理结构 顺序存储：地址连续，逻辑关系与物理一致 链接存储：任意存储单元，可连续，也可不连续 算法时间复杂度渐进增长在输入规模n没有限制的条件下，只要超过一个数值N，这个函数就总大于另一个函数，我们称函数是渐进增长的。 函数的渐进增长给定两个函数f(n)和g(n)，如果存在一个整数N，是的对所有的n&gt;N，f(n)总是比g(n)大，那么就说：f(n)的增长渐进快于g(n)。 时间复杂度时间复杂度考虑的是渐进增长。如：O(n^3)&gt;O(n^2+100) 常见时间复杂度： O(1) 常数 O(logn) 对数 O(n) 线性 O(nlogn) nlog(n) O(n^2) 平方 O(n^3) 立方 O(2^n) 指数 O(n!) 阶乘 O(n^n) 最后三个，除非n非常小，哪怕n=100，都是噩梦般的运行时间。这种不切实际的复杂度，一般不讨论。 线性表零个或多个元素的有限序列。是有顺序的，有前驱、后继元素。 有顺序存储结构和链式存储结构两种。 顺序存储用一段地址连续的存储单元依次存线性表的数据元素。 插入删除 最好（最后一位）：O(1) 最坏（第0位）：O(n) 平均：插到第i位，移n-i 存、读：O(1) 插、删：O(n) 优点： 无须为表中元素之间的逻辑关系增加额外存储空间。 可快速存取表中任意位置的元素。 缺点： 插、删需要移动大量元素 长度变化较大时，难以确定存储空间容量 易造成存储空间的碎片。 链式存储结构存储单元可以连续，也可以不连续。 单链表头指针是必须的，头结点不是。]]></content>
  </entry>
  <entry>
    <title><![CDATA[排序算法总结]]></title>
    <url>%2F2017%2F09%2F06%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[冒泡排序 BubbleSort基本思想基本思想：每次比较两个相邻的元素，如果它们的顺序不对，就交换。 实现从小到大排序：3, 1, 5, 7, 2, 4, 9, 6 代码： 123456789101112131415161718192021222324# coding:utf-8def bubbleSort(numbers): n = len(numbers) for j in range(n): for i in range(1, n - j): if numbers[i - 1] &gt; numbers[i]: numbers[i - 1], numbers[i] = numbers[i], numbers[i - 1] print j,numbers return numbersif __name__ == '__main__': a = [1, 2, 4, 3, 5] bubbleSort(a)'''运行结果：0 [1, 3, 5, 2, 4, 7, 6, 9]1 [1, 3, 2, 4, 5, 6, 7, 9]2 [1, 2, 3, 4, 5, 6, 7, 9]3 [1, 2, 3, 4, 5, 6, 7, 9]4 [1, 2, 3, 4, 5, 6, 7, 9]5 [1, 2, 3, 4, 5, 6, 7, 9]6 [1, 2, 3, 4, 5, 6, 7, 9]7 [1, 2, 3, 4, 5, 6, 7, 9]''' 优化注意到经过一次排序，数组就已经是有序的了。可以针对上述代码进行优化： 优化1：某一趟遍历如果没有数据交换，则说明已经排好序了，因此不用再进行迭代了。用一个标记记录这个状态即可。 12345678910111213141516171819def bubbleSort_2(numbers): n = len(numbers) for j in range(n): flag = 1 for i in range(1, n - j): if numbers[i - 1] &gt; numbers[i]: numbers[i - 1], numbers[i] = numbers[i], numbers[i - 1] flag = 0 print j, numbers if flag: break return numbers'''运行结果：0 [1, 3, 5, 2, 4, 7, 6, 9]1 [1, 3, 2, 4, 5, 6, 7, 9]2 [1, 2, 3, 4, 5, 6, 7, 9]3 [1, 2, 3, 4, 5, 6, 7, 9]''' 优化2：记录某次遍历时最后发生数据交换的位置，这个位置之后的数据显然已经有序，不用再排序了。因此通过记录最后发生数据交换的位置就可以确定下次循环的范围了。 123456789101112131415161718192021def bubbleSort_3(numbers): n = len(numbers) k = n for j in range(n): flag = 1 for i in range(1, k): if numbers[i - 1] &gt; numbers[i]: numbers[i - 1], numbers[i] = numbers[i], numbers[i - 1] k = i flag = 0 print j, numbers if flag: break return numbers'''运行结果：0 [1, 3, 5, 2, 4, 7, 6, 9]1 [1, 3, 2, 4, 5, 6, 7, 9]2 [1, 2, 3, 4, 5, 6, 7, 9]3 [1, 2, 3, 4, 5, 6, 7, 9]''' 选择排序 SelectionSort基本思想 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。 再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。 以此类推，直到所有元素均排序完毕。 实现在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。 123456789101112131415161718192021def selectSort(numbers): n = len(numbers) for j in range(n): min_index = j for i in range(j, n): if numbers[i] &lt; numbers[min_index]: min_index = i numbers[j], numbers[min_index] = numbers[min_index], numbers[j] print j, numbers return numbers'''运行结果：0 [1, 3, 5, 7, 2, 4, 9, 6]1 [1, 2, 5, 7, 3, 4, 9, 6]2 [1, 2, 3, 7, 5, 4, 9, 6]3 [1, 2, 3, 4, 5, 7, 9, 6]4 [1, 2, 3, 4, 5, 7, 9, 6]5 [1, 2, 3, 4, 5, 6, 9, 7]6 [1, 2, 3, 4, 5, 6, 7, 9]7 [1, 2, 3, 4, 5, 6, 7, 9]''' 插入排序 InsertionSort基本思想基本思想：对于每个未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 步骤： 认为第0个元素有序 从第1个元素开始，取出当前元素now，和有序的数组从后往前对比 如果now大于等于有序数组最后一个元素，则continue；否则，将有序数组元素逐个后移，找到元素now应该插入的位置，插入now 实现从小到大排序：3, 1, 5, 7, 2, 4, 9, 6 代码： 12345678910111213141516171819202122232425262728def insertionSort(numbers): n = len(numbers) print(0, numbers) for j in range(1, n): # 从1开始 if numbers[j - 1] &gt; numbers[j]: # 只处理这种情况。如果这2个元素本身有序，则continue now_element = numbers[j] index = j for i in range(j - 1, -1, -1): # 从后往前遍历[j-1, 0] if numbers[i] &gt; now_element: numbers[i + 1] = numbers[i] # 后移一位 index = i else: break numbers[index] = now_element print(j, numbers) return numbers '''运行结果：0 [3, 1, 5, 7, 2, 4, 9, 6]1 [1, 3, 5, 7, 2, 4, 9, 6]2 [1, 3, 5, 7, 2, 4, 9, 6]3 [1, 3, 5, 7, 2, 4, 9, 6]4 [1, 2, 3, 5, 7, 4, 9, 6]5 [1, 2, 3, 4, 5, 7, 9, 6]6 [1, 2, 3, 4, 5, 7, 9, 6]7 [1, 2, 3, 4, 5, 6, 7, 9]''' 快速排序 QuickSort基本思想采用分治思想 实现从小到大排序：3, 1, 5, 7, 2, 4, 9, 6 代码： 123456789101112131415161718192021222324252627282930313233def quickSort(numbers, start, end): print(numbers) if start &gt;= end: return numbers key = numbers[start] # 取最左边元素为基数 l = start r = end while l &lt; r: while numbers[r] &gt;= key and l &lt; r: # 必须先while r，再l r -= 1 while numbers[l] &lt;= key and l &lt; r: # 找到第一个比key大的元素索引 l += 1 numbers[l], numbers[r] = numbers[r], numbers[l] numbers[start], numbers[l] = numbers[l], numbers[start] quickSort(numbers, start, l - 1) quickSort(numbers, r + 1, end) return numbers'''运行结果：[3, 1, 5, 7, 2, 4, 9, 6][2, 1, 3, 7, 5, 4, 9, 6][1, 2, 3, 7, 5, 4, 9, 6][1, 2, 3, 7, 5, 4, 9, 6][1, 2, 3, 7, 5, 4, 9, 6][1, 2, 3, 6, 5, 4, 7, 9][1, 2, 3, 4, 5, 6, 7, 9][1, 2, 3, 4, 5, 6, 7, 9][1, 2, 3, 4, 5, 6, 7, 9][1, 2, 3, 4, 5, 6, 7, 9][1, 2, 3, 4, 5, 6, 7, 9][1, 2, 3, 4, 5, 6, 7, 9]''' 归并排序 MergeSort基本思想采用分治思想 实现从小到大排序：3, 1, 5, 7, 2, 4, 9, 6 代码： 12345678910111213141516171819202122232425262728293031323334353637def merge_sort(ary): if len(ary) &lt;= 1 : return ary num = int(len(ary)/2) #二分分解 left = merge_sort(ary[:num]) right = merge_sort(ary[num:]) return merge(left,right) #合并数组def merge(left,right): ''' 合并操作， 将两个有序数组left[]和right[]合并成一个大的有序数组 ''' l,r = 0,0 #left与right数组的下标指针 result = [] while l&lt;len(left) and r&lt;len(right) : if left[l] &lt; right[r]: result.append(left[l]) l += 1 else: result.append(right[r]) r += 1 result += left[l:] result += right[r:] print(left,right,"==&gt;",result) return result'''运行结果：[3] [1] ==&gt; [1, 3][5] [7] ==&gt; [5, 7][1, 3] [5, 7] ==&gt; [1, 3, 5, 7][2] [4] ==&gt; [2, 4][9] [6] ==&gt; [6, 9][2, 4] [6, 9] ==&gt; [2, 4, 6, 9][1, 3, 5, 7] [2, 4, 6, 9] ==&gt; [1, 2, 3, 4, 5, 6, 7, 9][1, 2, 3, 4, 5, 6, 7, 9]''' 堆排序 HeapSort基本思想堆排序在 top K 问题中使用比较频繁。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树 。 实现从小到大排序：3, 1, 5, 7, 2, 4, 9, 6 代码： 123456789101112131415161718192021222324252627282930313233343536373839404142def heap_sort(ary): n = len(ary) first = int(n / 2 - 1) # 最后一个非叶子节点 for start in range(first, -1, -1): # 构造大根堆 max_heapify(ary, start, n - 1) for end in range(n - 1, 0, -1): # 堆排，将大根堆转换成有序数组 ary[end], ary[0] = ary[0], ary[end] max_heapify(ary, 0, end - 1) return ary# 最大堆调整：将堆的末端子节点作调整，使得子节点永远小于父节点# start为当前需要调整最大堆的位置，end为调整边界def max_heapify(ary, start, end): root = start while True: child = root * 2 + 1 # 调整节点的子节点 if child &gt; end: break if child + 1 &lt;= end and ary[child] &lt; ary[child + 1]: child = child + 1 # 取较大的子节点 if ary[root] &lt; ary[child]: # 较大的子节点成为父节点 ary[root], ary[child] = ary[child], ary[root] # 交换 root = child else: break print(ary, "start: ", start, "end", end)'''运行结果：[3, 1, 5, 7, 2, 4, 9, 6] start: 3 end 7[3, 1, 9, 7, 2, 4, 5, 6] start: 2 end 7[3, 7, 9, 6, 2, 4, 5, 1] start: 1 end 7[9, 7, 5, 6, 2, 4, 3, 1] start: 0 end 7[7, 6, 5, 1, 2, 4, 3, 9] start: 0 end 6[6, 3, 5, 1, 2, 4, 7, 9] start: 0 end 5[5, 3, 4, 1, 2, 6, 7, 9] start: 0 end 4[4, 3, 2, 1, 5, 6, 7, 9] start: 0 end 3[3, 1, 2, 4, 5, 6, 7, 9] start: 0 end 2[2, 1, 3, 4, 5, 6, 7, 9] start: 0 end 1[1, 2, 3, 4, 5, 6, 7, 9] start: 0 end 0[1, 2, 3, 4, 5, 6, 7, 9]''' 参考 经典排序算法总结与实现 八大排序算法]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (2): Decision Tree]]></title>
    <url>%2F2017%2F09%2F06%2FMachine-Learning-2-Decision-Tree%2F</url>
    <content type="text"><![CDATA[决策树简介决策树是一种分类和回归的基本模型，可从三个角度来理解它，即： 树形结构 可看成是if-then规则的集合，该集合是决策树上的每一条从根节点到叶节点的路径的集合，决策树的路径或其对应的if-then规则集合互斥且完备 表示给定特征条件下类的条件概率分布。决策树实际上是将特征空间划分成了互不相交的单元，每个从根到叶的路径对应着一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。实际中，哪个类别有较高的条件概率，就把该单元中的实例划分为该类别 决策树的学习本质上就是从训练数据集中归纳出一组分类规则。与训练数据集不相矛盾的决策树可能有多个，也可能没有，我们需要的是一个与训练数据集矛盾较小的决策树，同时具有较好的泛化能力。从另一个角度看，决策树学习也是由训练数据集估计条件概率模型。 决策树的损失函数通常是正则化的极大似然函数，学习的策略是以损失函数为目标函数的最小化。当损失函数确定后，决策树学习的策略变为在损失函数意义下选择最优决策树的问题。由于从所有可能的决策树中选取最优决策树是NP完全问题，所以现实中，我们通常采用启发式算法来近似求解这一最优化问题，得到的决策树是次最优的。该启发式算法可分为三步： 特征选择 模型生成 决策树的剪枝 特征选择信息熵（information entropy） 在信息论与概率论中，熵(entropy)用于表示随机变量不确定性的度量。 熵越大，则随机变量的不确定性越大。 当p=0.5时，熵取值最大，随机变量不确定性最大。 表示 Ent(D) 范围 [0, log2|y|] （|y| 是样本的类数） Ent(D) 越小，D纯度越高 信息增益（information gain） 信息增益表示的是：得知特征X的信息而使得类Y的信息的不确定性减少的程度。 表示 Gain(D, a) 信息增益越大，意味着使用属性a来进行划分所获得的“纯度提升”越大。 增益率（gain ratio） 以信息增益作为特征选择准则，会存在偏向于选择取值较多的特征的问题。 可以采用信息增益比对这一问题进行校正。 特征A对训练数据集D的信息增益比定义为其信息增益与训练集D关于特征A的值的熵之比 表示 Gain_ratio(D, a) = Gain(D, a)/ IV(a) IV(a) 称为属性a的“固有值”（intrinsic value） 属性a的可能取值数目越多（即V越大），则IV(a) 的值通常会越大。 基尼指数（Gini index） Gini(D) CART决策树使用基尼指数来选择划分属性 Gini(D) 反映了从数据集D中随机抽取两个样本，其类别标志不一致的概率。 因此，Gini(D) 越小，数据集D的纯度越高。 信息增益准则对可取值数目较多的属性有所偏好（导致泛化能力较差），为了减少这种偏好带来的不利影响，C4.5 不直接使用信息增益，而是使用增益率来选择最优划分注意：增益率准则对可取值数目较少的属性有所偏好。(因此C4.5并不直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的。??) 决策树的生成ID3算法ID3算法的核心是在决策树的各个结点上应用信息增益准则进行特征选择。具体做法是： 从根节点开始，对结点计算所有可能特征的信息增益，选择信息增益最大的特征作为结点的特征，并由该特征的不同取值构建子节点； 对子节点递归地调用以上方法，构建决策树； 直到所有特征的信息增益均很小或者没有特征可选时为止。 C4.5算法C4.5算法与ID3算法的区别主要在于它在生产决策树的过程中，使用信息增益比来进行特征选择。 CART算法分类与回归树（classification and regression tree,CART）与C4.5算法一样，由ID3算法演化而来。CART假设决策树是一个二叉树，它通过递归地二分每个特征，将特征空间划分为有限个单元，并在这些单元上确定预测的概率分布。CART算法中，对于回归树，采用的是平方误差最小化准则；对于分类树，采用基尼指数最小化准则。 剪枝剪枝是决策树预防过拟合的主要手段。 预剪枝（prepruning） 决策树生成过程中，对每个结点在划分前先进行评估 若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点 预剪枝使得决策树的很多分支都没有“展开”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测试时间开销。 但另一方面，有些分支的当前划分虽不能提升泛化性能，甚至可能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显著提高 预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。 后剪枝（postpruning） 先从训练集中生成一棵完整的决策树 自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能的提升，则将该子树替换为叶结点。 后剪枝决策树通常比预剪枝决策树保留了更多的分支。 一般情况下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。 但后剪枝过程是在完全生成决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。 优缺点优点 易于理解和解释，甚至比线性回归更直观； 与人类做决策思考的思维习惯契合； 模型可以通过树的形式进行可视化展示； 可以直接处理非数值型数据，不需要进行哑变量的转化，甚至可以直接处理含缺失值的数据； 缺点 对于有大量数值型输入和输出的问题，决策树未必是一个好的选择； 特别是当数值型变量之间存在许多错综复杂的关系，如金融数据分析； 决定分类的因素取决于更多变量的复杂组合时； 模型不够稳健，某一个节点的小小变化可能导致整个树会有很大的不同。 其他连续值处理 最简单地策略是采用二分法（bi-partition）对连续值进行处理，这正是C4.5决策树算法中采用的机制 与离散属性不同，若当前结点划分属性为连续属性，该属性还可作为其后代结点的划分属性。（例如父结点使用了“密度&lt;=0.38”，不会禁止在子结点上使用“密度&lt;=0.29”） 缺失值处理 如果简单地放弃不完整样本，仅适用无缺失值的样本来进行学习，显然是对数据信息的极大的浪费。 缺失值同时进入各个分支中，但权重有所不同。即让同一个样本以不同的概率划分到不同的子结点中去。 参考 李航. 统计学习方法[M]. 清华大学出版社, 2012. 周志华. 机器学习 : = Machine learning[M]. 清华大学出版社, 2016. 简书：数据挖掘面试题之决策树必知必会 决策树算法的Python实现]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning (1): kNN]]></title>
    <url>%2F2017%2F09%2F03%2FMachine-Learning-1-kNN%2F</url>
    <content type="text"><![CDATA[kNN简介算法流程 基本分类和回归方法。大多用于分类。 分类时，根据k个最近邻实例的类别，通过多数表决等方式进行预测。 不具有显示的学习过程。（训练过程） KNN即最近邻算法，其主要过程为： 计算训练样本和测试样本中每个样本点的距离（常见的距离度量有欧式距离，马氏距离等）； 对上面所有的距离值进行排序； 选前k个最小距离的样本； 根据这k个样本的标签进行投票，得到最后的分类类别； 三个基本要素 这三个基本要素是： k值的选择 距离度量 分类决策规则 k值的选择 k=1时称 最近邻法 k值的选择（不具有显示学习过程，所以下方学习打引号） k不同，有可能导致分类不同 在应用中，k值一般取一个比较小的数值。通常采用交叉验证法来选取最优的k值 k过小 过拟合 相当于用较小的领域中的训练实例进行预测 “学习”的近似误差（approximation error）会减小（与训练集误差小） “学习”的估计误差（estimation error）会增大（与测试集误差大） 预测结果会对近邻实例点非常敏感，如果近邻的实例点恰好是噪声，预测就会出错 即，k值的减小意味着整体模型变得复杂，容易发生过拟合 k过大 欠拟合 相当于用较大的领域中的训练实例进行预测 “学习”的近似误差（approximation error）会增大（与训练集误差大） “学习”的估计误差（estimation error）会减小（与测试集误差小） 与输入实例较远的（不相似的）训练实例也会对预测起作用，使预测发生错误 即，k值得增大意味着整体的模型变得简单 如果k=N，则不论输入什么，都简单地预测它属于实例中最多的类。这时，模型过于简单，完全忽略了训练实例中的大量有用信息，是不可取的 距离度量 欧式距离 Euclidean distance（Lp距离，p=2的情况） p=1，曼哈顿距离 Manhattan distance p=无穷，各坐标距离的最大值（无求和过程） p越大，Lp距离越小 距离度量不同，x1与x2最近，可能变为x1与x3最近。 从图中直接观察的距离是欧式距离。 所以，并不是在图上看起来最近，使用Lp算出来的距离就最近，这完全要看p的取值。 分类决策规则 往往是多数表决。多数表决规则（majority voting rule） kNN实现 简单实现方法：线性扫描（linear scan） 计算输入实例与每一个训练实例的距离。 当训练集很大时，非常耗时，不可行 kd树（kd tree），这里k与k-NN的k意义不同 实现时，主要考虑如何对训练数据快速地进行k近邻搜索。在特征空间维数大及训练数据容量大时尤其必要。 为了提高搜索效率，考虑使用特殊的结构存储训练数据，以减少计算距离的次数 具体方法很多，介绍kd树 优缺点 KNN算法的优点 思想简单，理论成熟，既可以用来做分类也可以用来做回归； 可用于非线性分类； 训练时间复杂度为O(n)； 准确度高，对数据没有假设，对outlier不敏感； 缺点 计算量大； 样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）； 需要大量的内存； Python实现环境： Python 2.7.13numpy 1.12.0pandas 0.19.2skleran 0.18.1 为了验证效果，使用的数据集是kaggle上digit-recognizer给的数据集，取了前3000行来验证实现的kNN效果。 线性扫描法（Linear Scan）实现实现详细过程见：kNN线性扫描实现，其中包括各个函数的用法探索。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# coding:utf-8from __future__ import divisionimport numpy as npimport pandas as pdfrom sklearn.model_selection import train_test_splitdef knnClassify(newinput, datas, labels, k, p): # 计算距离 diff = abs(np.tile(newinput, (len(datas), 1)) - datas) distances = (np.sum(diff ** p, axis=1)) ** (1 / p) sort_distances = np.argsort(distances) #print distances # print sort_distances # 投票法决定分类 classCount = &#123;&#125; for i in range(k): label = labels[sort_distances[i]] classCount[label] = classCount.get(label, 0) + 1 maxCount = 0 maxIndex = -1 for key, value in classCount.items(): if value &gt; maxCount: maxCount = value maxIndex = key return maxIndexif __name__ == '__main__': ''' # example in book group = [[5, 1], [4, 4]] lables = ['a', 'b'] print knnClassify([1, 1], group, lables, 1, 1) print knnClassify([1, 1], group, lables, 1, 2) print knnClassify([1, 1], group, lables, 1, 3) print knnClassify([1, 1], group, lables, 1, 4) ''' # example for digit recognizer all_data = pd.read_csv('/Users/liuyue/workspace/pythonstudy/test/digit_datas.csv') y = all_data['label'].values x = all_data.drop(['label'], axis=1).values x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) print 'Data Infomation:' print 'Train Data Information: ',x_train.shape, len(y_train) print 'Test Data Information: ',x_test.shape, len(y_test) matchCount = 0 accuracy = 0 print '识别错误的数如下：' for i in range(len(x_test)): predict = knnClassify(x_test[i], x_train, y_train, 3, 2) # print predict,y_test[i] if predict == y_test[i]: matchCount += 1 else: # 打印识别错误的数 print predict, y_test[i] accuracy = float(matchCount) / len(x_test) print 'accuracy:',accuracy 运行结果123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384Data Infomation:Train Data Information: (2100, 784) 2100Test Data Information: (900, 784) 900识别错误的数如下：6 09 54 96 80 85 88 21 78 37 91 31 41 78 53 81 80 60 51 89 87 39 45 93 21 78 28 51 77 86 08 25 39 41 20 59 49 47 29 47 97 88 34 99 49 89 34 89 75 85 81 71 81 29 51 70 56 08 53 82 81 49 49 40 99 45 97 28 59 59 38 32 39 84 25 89 05 81 89 8accuracy: 0.912222222222 参考 李航. 统计学习方法[M]. 清华大学出版社, 2012. 机器学习&amp;数据挖掘笔记_16（常见面试之机器学习算法思想简单梳理） 机器学习算法与Python实践之（一）k近邻（KNN）]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python实现全排列]]></title>
    <url>%2F2017%2F08%2F10%2Fpython%E5%AE%9E%E7%8E%B0%E5%85%A8%E6%8E%92%E5%88%97%2F</url>
    <content type="text"><![CDATA[使用permutations12itertools.permutations(iterable[, r])#创建一个迭代器，返回iterable中所有长度为r的项目序列，如果省略了r，那么序列的长度与iterable中的项目数量相同： 返回p中任意取r个元素做排列的元组的迭代器 例如： 12345678910111213# coding:utf-8from itertools import permutationss = raw_input()print permutations(s)# &lt;itertools.permutations object at 0x10b9a5410&gt;print list(permutations(s))# [('a', 'b', 'c'), ('a', 'c', 'b'), ('b', 'a', 'c'), ('b', 'c', 'a'), ('c', 'a', 'b'), ('c', 'b', 'a')]print list(permutations(s, 2))# [('a', 'b'), ('a', 'c'), ('b', 'a'), ('b', 'c'), ('c', 'a'), ('c', 'b')]print [''.join(x) for x in list(permutations(s))]# ['abc', 'acb', 'bac', 'bca', 'cab', 'cba'] 所以利用permutations实现的全排列的代码为：]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql使用记录]]></title>
    <url>%2F2017%2F07%2F19%2Fmysql%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[在mac中使用mysql的记录。 安装使用homebrew安装mysql1brew install mysql 下载 sequel pro，使用 sequel-pro 来对数据库进行管理。以下介绍引用自 segmentfalt: Mac 上的 MySQL 管理工具 — Sequel Pro Sequel Pro 是 Mac 用户常用的 MySQL 管理软件，属于开源项目 CocoaMySQL 的一个分支。它支持包括索引在内的所有表管理功能，支持MySQL视图，可以同时使用多个窗口来操作多个数据库/表。完全可以媲美大家熟悉的 phpMyadmin。 Sequel Pro 的部分特性如下： 操作快速，简单。通过简单的几个参数设定即可连接本地或远程MySQL。 支持多窗口操作。在不同的个窗口中，对多数据库实施操作。 SQL语句的语法彩色、加亮显示。 SQL语句的关键字、表名、字段名的自动完成。 支持30多种不同的字符编码。 快速导入/恢复、导出/备份SQL及CSV格式的数据。 兼容MySQL3、4、5。 支持在MAMP/XAMP架构上连接数据库，支持SSH连接模式； 免费使用，当然，如果你觉得不错，可以 Donate 支持一下作者。 使用命令行启动 MySQL 服务，运行 mysql.server，在命令行输入： 1( ⌁ ) mysql.server start 登录 MySQL，运行: 1( ⌁ ) mysql -uroot Note: 默认情况下，MySQL 用户 root 没有密码，这对本地开发没有关系，但如果你希望修改密码，你可以运行: 1$ mysqladmin -u root password &apos;new-password&apos; 关闭 MySQL，运行：（注意运行位置） 123( ⌁ ) mysql.server stop Shutting down MySQL.... SUCCESS! 你可以了解更多 mysql.server 的命令，运行： 12( ⌁ ) mysql.server --help Usage: mysql.server &#123;start|stop|restart|reload|force-reload|status&#125; [ MySQL server options ] sequel pro在运行（mysql.server start）后可以在图形界面使用mysql： 打开之前安装的sequel-pro，点击左下方＋新建一个 FAVORITES，在右侧进行配置。 Name： 随便写 Host：因为是在本地，所以填127.0.0.1 Username：与自己的用户名相同，如果按照上面的写法，用户是root Password：如果设置了就写，没设置就空着 Database：要连接的数据库名 Port：端口号默认 3306，可以不写 设置好后点connect，就可以利用图形界面来操作了。 更多的操作方法可以参考 segmentfalt: Mac 上的 MySQL 管理工具 — Sequel Pro 常用 sql使用sql语句来操作数据库，需要注意的是： SQL 对大小写不敏感 某些数据库系统要求在每条 SQL 命令的末端使用分号。分号是在数据库系统中分隔每条 SQL 语句的标准方法，这样就可以在对服务器的相同请求中执行一条以上的语句。 对数据库的操作show databases; 查看现在有哪些数据库（注意分号） 1234567891011mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test |+--------------------+5 rows in set (0.00 sec) create database 数据库名; 新建一个数据库 12mysql&gt; create database test;Query OK, 1 row affected (0.00 sec) use 数据库名; 选择要操作的 Mysql 数据库，使用该命令后所有 Mysql 命令都只针对该数据库 12345mysql&gt; use test;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed drop database 数据库名; 删除数据库 123mysql&gt; drop database chou;Query OK, 1 row affected (0.01 sec) 对表的操作show tables; 显示指定数据库的所有表，使用该命令前需要使用 use 命令来选择要操作的数据库。 1234567mysql&gt; show tables;+----------------+| Tables_in_test |+----------------+| test_table1 |+----------------+1 row in set (0.00 sec) show columns from 数据表 显示数据表的属性，属性类型，主键信息 ，是否为 NULL，默认值等其他信息。 12345678910mysql&gt; show columns from t;+-------------+------------------+------+-----+---------+----------------+| Field | Type | Null | Key | Default | Extra |+-------------+------------------+------+-----+---------+----------------+| id | int(11) unsigned | NO | PRI | NULL | auto_increment || word | varchar(30) | YES | | NULL | || explanation | varchar(5000) | YES | | NULL | || tag | varchar(100) | YES | | NULL | |+-------------+------------------+------+-----+---------+----------------+4 rows in set (0.00 sec) delete from 数据表 删除表中所有内容，删除后可以查询表中还有多少条记录 12345678910mysql&gt; delete from test;Query OK, 6 rows affected (0.00 sec)mysql&gt; select count(*) from test;+----------+| count(*) |+----------+| 0 |+----------+1 row in set (0.00 sec) insert into 表名 (列名1,列名2) values (&#39;值1&#39;,&#39;值2&#39;); 将数据插入表。 Tipssource通过 Mysql Source 命令能够将 SQL 文件导入 Mysql 数据库中。 在日常工作中，可以通过脚本生成 sql 语句，存入 .sql 文件中，然后使用 source filename.sql 就可以执行这些 sql 语句。 char、varchar和text此部分引用 MySQL之char、varchar和text的设计- billy鹏- 博客园 1、char（n）和varchar（n）中括号中n代表字符的个数，并不代表字节个数，所以当使用了中文的时候(UTF8)意味着可以插入m个中文，但是实际会占用m*3个字节。 2、同时char和varchar最大的区别就在于char不管实际value都会占用n个字符的空间，而varchar只会占用实际字符应该占用的空间+1，并且实际空间+1&lt;=n。 3、超过char和varchar的n设置后，字符串会被截断。 4、char的上限为255字节，varchar的上限65535字节，text的上限为65535。 5、char在存储的时候会截断尾部的空格，varchar和text不会。 6、varchar会使用1-3个字节来存储长度，text不会。 总体来说： 1、char，存定长，速度快，存在空间浪费的可能，会处理尾部空格，上限255。 2、varchar，存变长，速度慢，不存在空间浪费，不处理尾部空格，上限65535，但是有存储长度实际65532最大可用。 3、text，存变长大数据，速度慢，不存在空间浪费，不处理尾部空格，上限65535，会用额外空间存放数据长度，顾可以全部使用65535。 从官方文档中我们可以得知当varchar大于某些数值的时候，其会自动转换为text，大概规则如下： 大于varchar（255）变为 tinytext 大于varchar（500）变为 text 大于varchar（20000）变为 mediumtext 所以对于过大的内容使用varchar和text没有太多区别。 所以我们认为当超过255的长度之后，使用varchar和text没有本质区别，只需要考虑一下两个类型的特性即可。（主要考虑text没有默认值的问题） 从上面的简单测试看，基本上是没有什么区别的，但是个人推荐使用varchar（10000），毕竟这个还有截断，可以保证字段的最大值可控，如果使用text那么如果code有漏洞很有可能就写入数据库一个很大的内容，会造成风险。所以，本着short is better原则，还是使用varchar根据需求来限制最大上限最好。 问题及解决方法ERROR! The server quit without updating PID file启动时报错：ERROR! The server quit without updating PID file (/usr/local/var/mysql/bogon.pid). 解决：首先查看有没有运行的mysql实例：ps -ef | grep mysql，如果有，就根据PID杀掉进程：kill -9 [PID]，这里将PID替换为查询到的PID（数字），再mysql.server start就成功了。 参考：stackoverflow:MySql server startup error ‘The server quit without updating PID file ‘ 参考 segmentfalt: Mac 上的 MySQL 管理工具 — Sequel Pro MySql | Mac 开发配置手册 - GitBook MySQL 教程| 菜鸟教程 stackoverflow:MySql server startup error ‘The server quit without updating PID file ‘]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[word使用记录]]></title>
    <url>%2F2017%2F07%2F18%2Fword%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[作为一种工具，有些功能每次使用时去搜索靠谱的用法实在太费劲了，所以记录一下实践过的tips，在下次使用时方便查阅。 目录不是从1开始把光标停在正文这一页的文字前面,然后 页面布局--&gt;分隔符--&gt;分节符--&gt;下一页 。在页脚的位置 双击--&gt;页码--&gt;页面底端--&gt;普通数字2，点击 页码--&gt;设置页码格式--&gt;起始页，设置为 “1”此时更新目录就是以 1 开始的了。但是封面和目录下面还有页码，如果删除那么所有的页码都被删除。在正文页脚的位置双击，取消 “连接到前一条页眉”，再删除目录的页码，在目录和封面的页面就都删除了。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>office</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[excel使用记录]]></title>
    <url>%2F2017%2F07%2F18%2Fexcel%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[作为一种工具，有些功能每次使用时去搜索靠谱的用法实在太费劲了，所以记录一下实践过的tips，在下次使用时方便查阅。 快捷键 ctrl+d 使用【向下填充】命令将选定范围内最顶层单元格的内容和格式复制到下面的单元格中。 ctrl+r 使用【向右填充】命令将选定范围最左边单元格的内容和格式复制到右边的单元格中。 ctrl+h 显示【查找和替换】对话框。 F4 【重复上一个命令或操作】（如有可能）。例如有多个合并单元格操作，可以在合并一个后，使用 F4 重复合并。 ctrl+# 或 ctrl+i 【斜体】 ctrl+w 关闭选定的工作簿窗口。 ctrl+箭头 可移动到工作表中当前数据区域 （数据区域：包含数据的单元格区域，该区域周围为空白单元格或数据表边框。）的边缘。 shift+箭头 可将单元格的选定范围扩大一个单元格。 ctrl+shift+箭头 可将单元格的选定范围扩展到与活动单元格同一列或同一行中的最后一个非空白单元格。 其他数字前面的0不显示输入 “01”，显示 “1”。对着单元格 右键--&gt;设置单元格格式--&gt;在“数字”栏选定“文本”选项--&gt;确定再输入 “01” 就能够显示了，并且将鼠标移到单元格右下角，当鼠标变为黑色“十”时，像下或像右移动光标能够给单元格填充递增的数字（使用 ctrl+d 或 ctrl+r 填充不递增）。 设置固定表头如果表头只有一行，那么直接选择 视图--&gt;冻结窗格--&gt;冻结首行 就可以了。如果表头是多行的，那么首先要选中表头的下方一行（如果想将前两行作为表头那就选择第三行），然后选择视图选项下的 冻结窗格--&gt;冻结拆分窗格。]]></content>
      <categories>
        <category>tools</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>office</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-docx使用记录]]></title>
    <url>%2F2017%2F06%2F30%2Fpython-docx%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[因为要处理中文，所以在这里使用 python3（相对 python2 编码问题较少）。 安装 docx：使用 pip3 install python-docx如果安装失败可以尝试：pip3 easy-install python-docx docx文档结构分为3层： Document对象表示整个文档 Document包含了Paragraph对象的列表，Paragraph对象用来表示段落 一个Paragraph对象包含了Run对象的列表，Run：word里不只有字符串，还有字号、颜色、字体等属性，都包含在style中。一个Run对象就是style相同的一段文本。新建一个Run就有新的style。 基本操作参考：http://python-docx.readthedocs.io/en/latest/ 基本操作包括打开文档、在文档中写入内容、存储文档，简洁示例如下。12345from docx import Documentdoc=Document() #不填文件名默认新建空白文档。填文件名（必须是已存在的doc文件）将打开这一文档进行操作doc.add_heading('Hello') #添加标题doc.add_paragraph('word') #添加段落doc.save('test.docx') #保存，必须有1个参数 python-docx包含的对象集合如下 12345doc.paragraphs #段落集合doc.tables #表格集合doc.sections #节 集合doc.styles #样式集合doc.inline_shapes #内置图形 等等... http://python-docx.readthedocs.io/en/latest/ 中的示例如下： 1234567891011121314151617181920212223242526272829303132333435363738from docx import Documentfrom docx.shared import Inchesdocument = Document()document.add_heading('Document Title', 0)p = document.add_paragraph('A plain paragraph having some ')p.add_run('bold').bold = Truep.add_run(' and some ')p.add_run('italic.').italic = Truedocument.add_heading('Heading, level 1', level=1)document.add_paragraph('Intense quote', style='IntenseQuote')document.add_paragraph( 'first item in unordered list', style='ListBullet')document.add_paragraph( 'first item in ordered list', style='ListNumber')document.add_picture('monty-truth.png', width=Inches(1.25))table = document.add_table(rows=1, cols=3)hdr_cells = table.rows[0].cellshdr_cells[0].text = 'Qty'hdr_cells[1].text = 'Id'hdr_cells[2].text = 'Desc'for item in recordset: row_cells = table.add_row().cells row_cells[0].text = str(item.qty) row_cells[1].text = str(item.id) row_cells[2].text = item.descdocument.add_page_break()document.save('demo.docx') 读写标题背景：需要将某个文档中的标题拷贝到另一个文档中，但是标题太过分散，手动拷贝太费劲，所以考虑使用 docx 来处理。 打开 doc 文档，获取所有的 paragraphs（里面包含了Heading），查看这些 paragraphs 的 style（查看需要获取的标题是几级的） 123456import docxdoc=docx.Document('filename.docx') #打开文档ps=doc.paragraphsfor p in ps: print(p.style) 通过上面执行结果知道在这个文档（filename.docx）中，标题的 style 包括 Heading 1、Heading 2、Heading 3（其他文档的标题也许不是这些 style），我们通过 p.style.name来匹配这些标题，将标题及其 level 存到 re 中备用。 12345678re=[]for p in ps: if p.style.name=='Heading 1': re.append((p.text,1)) if p.style.name=='Heading 2': re.append((p.text,2)) if p.style.name=='Heading 3': re.append((p.text,3)) 现在已经获取了标题内容以及标题的 level，将 re 列表“解压”：titles,titledes=zip(*re)，标题存在 titles 列表中，level 存在 titledes 列表中，接下来将标题写到新文档中 1234newdoc=docx.Document()for i in range(len(titles)): newdoc.add_heading(titles[i],level=titledes[i])newdoc.save('newfile.docx') 获取表格内容背景：需要获取某个文档中所有表格的第二列和第三列内容。 打开doc文档 12import docxdoc=docx.Document('filename.docx') #打开文档 doc.tables返回的是文档中的表格，rows，columns和 cell 对象在遍历表格的时候很有用。 Table 对象有两个属性 rows 和 columns，等同于 Row 的列表以及 Column 的列表。因此迭代、求长度等对list的操作同样适用于 Rows 和 Columns。 cell 也是表格中常用的对象，可以利用以下五种方法得到Cell对象： 使用 Table 对象的 cell(row,col) 方法。左上角的坐标为0,0 使用 Table 对象的 row_cells(row_index) 方法得到一个 list，它包含了某一行的按列排序的所有 Cell 得到一个 Row 对象后，使用 Row.cells 属性得到该 Row 的按列排序的所有 Cell 使用 Table 对象的 column_cells(column_index) 方法得到一个 list，它包含了某一列的按行排序的所有 Cell 得到一个 Column 对象后，使用 Column.cells 属性得到该 Column 的按行排序的所有 Cell 如果想遍历所有 Cell，可以先遍历所有行（table.rows），再遍历每一行所有的 Cell； 也可以先遍历所有列（table.columns），再遍历每一列所有的 Cell。 一个Cell对象最常用的属性是 text。设置这个属性可以设定单元格的内容，读取这个属性可以获取单元格的内容。 为了便于理解，举例如下 1234for table in doc.tables: #列举文档中的表格 for row in table.rows: #表格中的每一行 t1=row.cells[1].text #每一行中第2列（从0开始计数）的内容 t2=row.cells[2].text #每一行中第3列的内容 获取表格中的数据后用 DataFrame 存，最后保存为csv文件。如果有中文乱码问题，最后加上encoding=&#39;gb2312&#39; 1df.to_csv('filename.csv',index=False,encoding='gb2312') 创建表格 Document.add_table 的前两个参数设置表格行数和列数，第三个参数设定表格样式，也可以用 table 的 style 属性获取和设置样式。如果设置样式，可以直接用样式的英文名称，例如『Table Grid』；如果对样式进行了读取，那么会得到一个 Style对象。这个对象是可以跨文档使用的。除此之外，也可以使用 Style.name 方法得到它的名称。 下面创建一个 6 行 2 列的表格，可以通过 table.cell(i,j).text 来对表格进行填充。 1234doc=docx.Document()tabel=doc.add_table(rows=6,cols=2,style = 'Table Grid') #实线tabel.cell(0,0).text='编号'tabel.cell(1,0).text='位置' 上面创建的表格每一列等宽，可以设置表格的列宽使其更美观。 12345from docx.shared import Inchesfor t in doc.tables: for row in t.rows: row.cells[0].width=Inches(1) row.cells[1].width=Inches(5) 参考 http://python-docx.readthedocs.io/en/latest/ Python读取word文档——python-docx Python读写docx文件 使用表格—— 使用Python读写Office文档之三]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>docx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kaggle记录]]></title>
    <url>%2F2017%2F06%2F19%2FKaggle%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[Titanic代码地址：https://github.com/ywtail/kaggle/tree/master/1_Titanic 2017.4.7：Titanic-1score：0.76555使用模型：RandomForestClassifier运行过程展示地址：https://ywtail.github.io/kaggle/1_Titanic/Titanic-1.html说明：titanic 初探，只简单对缺失数据进行了填充。使用 GridSearchCV 对参数进行了调整。 2017.6.22：Titanic-2score：0.76555 (后来提交分数越来越低)使用模型：RandomForestClassifier运行过程展示地址：https://ywtail.github.io/kaggle/1_Titanic/Titanic-2.html说明：简单特征工程，从 Name 得到 Title、从 Parch、SibSp 得到家庭人数，从 Age 等信息得到是不是 Child，是不是有 Child（预测时使用分数反而降低了），随机（[average - std, average + std]）生成了缺失的年龄。参考：https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic 2017.6.23：Titanic-3score: 0.77033运行过程展示地址：https://ywtail.github.io/kaggle/1_Titanic/Titanic-3.html大体流程如下： 删除不需要的项：PassengerId(训练数据中的)，Name，Ticket 处理缺失数据：Embarked，Fare，Age，Cabin（缺失太多直接删除） 特征工程：Family，Person，Pclass 使用模型及提交后得分： LogisticRegression：0.76077 SVC：0.61722 RandomForestClassifier：0.73206 KNeighborsClassifier：0.62201 GaussianNB：0.73206 GradientBoostingClassifier：0.77033 参考：https://www.kaggle.com/omarelgabry/a-journey-through-titanic 2017.7.10：Titanic-4score: 0.79426 (排名1841/7167(26%))运行过程展示地址：https://ywtail.github.io/kaggle/1_Titanic/Titanic-4.htmlAge的缺失值填充参考了 Pclass 和 Sex；Age 和 Fare 分段。使用模型及提交后得分： LogisticRegression：0.76555 SVC：0.77990 LinearSVC：0.76555 KNeighborsClassifier：0.77033 GaussianNB：0.74163 Perceptron：0.75598 SGDClassifier：0.79426 DecisionTreeClassifier：0.78469 RandomForestClassifier：0.77990 GradientBoostingClassifier：0.79426 参考：https://www.kaggle.com/startupsci/titanic-data-science-solutions Digit RecognizerKaggle地址：https://www.kaggle.com/c/digit-recognizer代码地址：https://github.com/ywtail/kaggle/tree/master/2_Digit_Recognizer 2017.7.26：1-SVC【0.90929】.ipynb运行过程展示：点击这里 探索数据，流程如下： 取5000个样本进行训练。 特征缩放：大于1的特征取1。 使用SVC，提交得分 0.90929 2017.8.3：2-softmax【0.90971】.ipynb运行过程展示：点击这里 y=softmax(xW+b)（特征缩放：特征/255） 代价函数：交叉熵 最小化代价函数：梯度下降 GradientDescentOptimizer，学习率0.01 详细分析见：TensorFlow (2): Softmax Regression识别手写数字 2017.8.3：3-多层感知机 【0.96486】.ipynb运行过程展示：点击这里 Softmax Regression 和传统意义上的神经网络的最大区别是没有隐含层。这里实现的多层感知机实际上是在 Softmax Regression 的基础上加上一个隐含层。结构如下： x=tf.placeholder(tf.float32,[None,784]) hidden1=tf.nn.relu(tf.matmul(x,W1)+b1) hidden1_drop=tf.nn.dropout(hidden1,keep_prob) y=tf.nn.softmax(tf.matmul(hidden1_drop,W2)+b2) 代价函数：交叉熵 最小化代价函数：AdagradOptimizer，学习率0.01 详细分析见：TensorFlow (3): 多层感知机识别手写数字 2017.8.5：4-CNN-Tensorflow【0.98957】.ipynb运行过程展示：点击这里 结构如下： x_image=tf.reshape(x,[-1,28,28,1]) h_conv1=tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1) h_pool1=max_pool_2x2(h_conv1) h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2) h_pool2=max_pool_2x2(h_conv2) h_pool2_flat=tf.reshape(h_pool2,[-1,7764]) h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1) h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob) y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2) 代价函数：交叉熵 最小化代价函数：AdamOptimizer，学习率1e-4 详细分析见：TensorFlow (4): 卷积神经网络识别手写数字 2017.8.6：5-CNN-Keras【0.99514】.ipynb运行过程展示：点击这里 Top: 12%，198/1789 参考：https://www.kaggle.com/toregil/welcome-to-deep-learning-cnn-99 结构如下：1234567891011121314151617181920212223model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', input_shape = (28, 28, 1)))model.add(BatchNormalization())model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))model.add(BatchNormalization())model.add(MaxPool2D(strides=(2,2)))model.add(Dropout(0.25))model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))model.add(BatchNormalization())model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))model.add(BatchNormalization())model.add(MaxPool2D(strides=(2,2)))model.add(Dropout(0.25))model.add(Flatten())model.add(Dense(512, activation='relu'))model.add(Dropout(0.25))model.add(Dense(1024, activation='relu'))model.add(Dropout(0.5))model.add(Dense(10, activation='softmax'))model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=["accuracy"])]]></content>
      <categories>
        <category>Kaggle</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Kaggle</tag>
        <tag>MachineLearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow (6): 实现Word2Vec]]></title>
    <url>%2F2017%2F06%2F09%2FTensorFlow-6-%E5%AE%9E%E7%8E%B0Word2Vec%2F</url>
    <content type="text"><![CDATA[本文首先对 Word2Vec 进行简单介绍，然后使用 python 构造训练样本，最后实现 Word2Vec，并产生可视化结果。 本文中涉及的所有代码均在 github.com/ywtail。查看运行过程可点击 这个链接 。 Word2Vec 简介Word2Vec 也称 Word Embeddings，中文比较普遍的叫法是“词向量”或“词嵌入”。Word2Vec 是一个可以将中文词转为向量形式表达（Vector Representations）的模型。 为什么要把字词转为向量图像、音频等数据天然可以编码并存储为稠密向量的形式，比如图片是像素点的稠密矩阵，音频可以转为声音信号的频谱数据。自然语言在 Word2Vec 出现之前，通常将字词转成离散的单独的符号，例如 “cat” 一词或可表示为 Id537 ，而 “dog” 一词或可表示为 Id143。 这些符号编码毫无规律，无法提供不同词汇之间可能存在的关联信息。换句话说，在处理关于 “dogs” 一词的信息时，模型将无法利用已知的关于 “cats” 的信息（例如，它们都是动物，有四条腿，可作为宠物等等）。可见，将词汇表达为上述的独立离散符号将进一步导致数据稀疏，使我们在训练统计模型时不得不寻求更多的数据。而词汇的向量表示将克服上述的难题。 向量空间模型 (Vector Space Models，VSMs)将词汇表达（嵌套）于一个连续的向量空间中，语义近似的词汇被映射为相邻的数据点。向量空间模型在自然语言处理领域中有着漫长且丰富的历史，不过几乎所有利用这一模型的方法都依赖于 分布式假设，其核心思想为出现于上下文情景中的词汇都有相类似的语义。采用这一假设的研究方法大致分为以下两类：基于计数的方法 (e.g. 潜在语义分析)， 和 预测方法 (e.g. 神经概率化语言模型). 其中它们的区别在如下论文中又详细阐述 Baroni et al.，不过简而言之：基于计数的方法计算某词汇与其邻近词汇在一个大型语料库中共同出现的频率及其他统计量，然后将这些统计量映射到一个小型且稠密的向量中。预测方法则试图直接从某词汇的邻近词汇对其进行预测，在此过程中利用已经学习到的小型且稠密的嵌套向量。 Word2vec 是一种可以进行高效率词嵌套学习的预测模型。其两种变体分别为：连续词袋模型（Continuous Bag of Words，CBOW）及 Skip-Gram 模型。从算法角度看，这两种方法非常相似，其区别为 CBOW 根据源词上下文词汇（’the cat sits on the’）来预测目标词汇（例如，‘mat’），而 Skip-Gram 模型做法相反，它通过目标词汇来预测源词汇。CBOW 对小型数据比较合适，而 Skip-Gram 在大型语料中表现得更好。 预测模型通常使用最大似然的方法，在给定前面的语句 h 的情况下，最大化目标词汇 w 的概率。但它存在的一个比较严重的问题是计算量非常大，需要计算词汇表中所有单词出现的可能性。在 Word2Vec 的 CBOW 模型中，不需要计算完整的概率模型，只需要训练一个二元的分类模型，用来区分真实的目标词汇和编造的词汇（噪声）这两类。用这种少量噪声词汇来估计的方法，类似于蒙特卡洛模拟。 当模型预测真实的目标词汇为高概率，同时预测其他噪声词汇为低概率时，我们训练的学习目标就被最优化了。用编造的噪声词汇训练的方法被称为 负采样（ Negative Sampling），用这种方法计算 loss function 的效率非常高，我们只需要计算随机选择的 k 个词汇而非词汇表中的全部词汇，因此训练速度非常快。在实际中，我们使用 Noise-Contrastive Estimation(NCE) Loss，同时在 TensorFlow 中也有 tf.nn.nce_loss() 直接实现了这个 loss。在本节中我们将主要实现 Skip-Gram 模式的 Word2Vec。 更具体的信息参见：TensorFow 中国社区：Vector Representations of Words Skip-gram 模型下面来看一下这个数据集：the quick brown fox jumped over the lazy dog 我们首先对一些单词以及它们的上下文环境建立一个数据集。我们可以以任何合理的方式定义‘上下文’，而通常上这个方式是根据文字的句法语境的（使用语法原理的方式处理当前目标单词可以看一下这篇文献 Levy et al.，比如说把目标单词左边的内容当做一个‘上下文’，或者以目标单词右边的内容，等等。现在我们把目标单词的左右单词视作一个上下文， 使用大小为1的窗口，这样就得到这样一个由(上下文, 目标单词) 组成的数据集：([the, brown], quick), ([quick, fox], brown), ([brown, jumped], fox), ... 前文提到Skip-Gram模型是把目标单词和上下文颠倒过来，所以在这个问题中，举个例子，就是用’quick’来预测 ‘the’ 和 ‘brown’ ，用 ‘brown’ 预测 ‘quick’ 和 ‘brown’ 。因此这个数据集就变成由(输入, 输出)组成的：(quick, the), (quick, brown), (brown, quick), (brown, fox), ... 目标函数通常是对整个数据集建立的，但是本问题中要对每一个样本（或者是一个batch_size 很小的样本集，通常设置为16 &lt;= batch_size &lt;= 512）在同一时间执行特别的操作，称之为随机梯度下降 (SGD)。 构造训练样本实现 Word2Vec 首先需要构造训练样本。以 the quick brown fox jumped over the lazy dog 为例，我们需要构造一个语境与目标词汇的映射关系，假设我们的滑动窗口尺寸为 1，则语境包括一个单词左边和右边的词汇，可以制造的映射关系包括 [the, brown] -&gt; quick, [quick, fox] -&gt; brown, [brown, jumped] -&gt; fox 等。 因为 Skip-Gram 模型是从目标词汇预测语境，所以训练样本不再是 [the, brown] -&gt; quick，而是 quick -&gt; the 和 quick -&gt; brown。我们的数据集就变为了 (quick, the)、(quick, brown)、(brown, quick)、(brown, fox) 等。 我们训练时，希望模型能从目标词汇 quick 预测出语境 the，同时也需要制造随机的词汇作为负样本（噪声），我们希望预测的概率分布在正样本 the 上尽可能大，而在随机产生的负样本上尽可能小。这里的做法就是通过优化算法（例如 SGC）来更新模型中的 Word Embedding 的参数，让概率分布的损失函数（NCE Loss）尽可能小。这样每个单词的 Embedded Vector 就会随着就训练过程不断调整，直到出于一个最合适语料的空间位置。这样我们的损失函数最小，最符合语料，同时预测出正确单词的概率也最高。 下载数据集数据集获取有两种方法 在浏览器地址栏输入 http://mattmahoney.net/dc/text8.zip 下载数据的压缩文件。 使用 urllib.urlretrieve 下载数据的压缩文件，并核对尺寸，如果已经下载了文件则跳过。代码如下，下载成功提示 (&#39;Found and verified&#39;, &#39;text8.zip&#39;) 123456789101112def maybe_download(filename, expected_bytes): if not os.path.exists(filename): filename, _ = urllib.urlretrieve(url + filename, filename) statinfo = os.stat(filename) if statinfo.st_size == expected_bytes: print('Found and verified', filename) else: print(statinfo.st_size) raise Exception('Failed to verify ' + filename + '. Can you get to it with a browser?') return filenamefilename = maybe_download('text8.zip', 31344016) 解压并转为列表接下来解压（使用 zipfile.ZipFile 函数）下载的压缩文件，并使用 tf.compat.as_str 将数据转成单词的列表。 1234567def read_data(filename): with zipfile.ZipFile(filename) as f: data = tf.compat.as_str(f.read(f.namelist()[0])).split() return datawords = read_data(filename)print 'Data size', len(words) 通过输出知道数据最后被转为了一个包含 17005207 个单词的列表。 创建词汇表使用 collections.Counter 统计单词的频数，然后使用 most_common 方法获取词频数最高的 50000 个单词加入词汇表。因为 python 中字典查询复杂度为 O(1)，性能非常好，所以将词汇表 dictionary 设置为字典 ，将词频最高的50000 个词汇放入 dictionary 中，以便快速查询。接下来将全部单词转为编号（以频数排序的编号），top 50000 之外的词，认定其为 Unkown（未知），将其编号为0。最后返回： data：转换后的编码 count：每个单词的频数统计 dictionary：词汇表（词：编码） reverse_dictionary：词汇表的反转形式（编码：词） 12345678910111213141516171819202122232425vocabulary_size = 50000def build_dataset(words): count = [['UNK', -1]] # 前面是词汇，后面是出现的次数 count.extend(collections.Counter(words).most_common(vocabulary_size - 1)) dictionary = dict() for word, _ in count: dictionary[word] = len(dictionary) data = list() # 转换后的编码：如果出现在 dictionary 中，数量作为编号，不出现 0 作为编号 unk_count = 0 for word in words: if word in dictionary: index = dictionary[word] else: index = 0 unk_count += 1 data.append(index) count[0][1] = unk_count reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) return data, count, dictionary, reverse_dictionarydata, count, dictionary, reverse_dictionary = build_dataset(words) 生成 Word2Vec 训练样本根据前面提到的 Skip-Gram 模式（从目标单词反推语境），定义 generate_batch 函数来生成训练用的 batch 数据，将原始数据 the quick brown fox jumped over the lazy dog 转为形如 (quick, the)、(quick, brown)、(brown, quick)、(brown, fox) 的样本。 在 generate_batch(batch_size, num_skips, skip_window) 函数中，变量含义如下： batch_size： batch 的大小； skip_window ：单词间最远可以联系到的距离，设为 1 代表只能跟紧相邻的一个单词生成样本，例如 quick 只能生成 (quick, the) 和 (quick, brown)； num_skips：对每个目标单词提取的样本数，它不能大于 skip_window 的两倍，并且 batch_size 必须是它的整数倍（为了确保每个 batch 包含了一个词汇对应的所有样本）； data_index：单词序号，初始化为0，是global 变量，因为会反复调用 generate_batch，所以要确保 data_index 可以在函数 generate_batch 中被修改； 在函数 generate_batch 中，使用 assert 断言确保 skip_window 和 num_skips 满足前面提到的条件：batch_size % num_skips == 0，num_skips &lt;= 2 * skip_window。 断言 batch_size % num_skips == 0 是为了确保每个 batch 包含了一个词汇对应的所有样本。 断言 num_skips &lt;= 2 * skip_window 是因为：假设词汇表words中的词是 a, b, c, d, e, f，skip_window=2 （单词间最远可以联系到的距离），那么显然，num_skips 最大是 4。假设 c 是目标词汇 c -&gt; a, b、c -&gt; d, e、b -&gt; c, d、d -&gt; b, c，对目标单词 c 提取的样本最多为 4 个。如果目标单词是 a，则不足 4 个。但是在下方的代码中，目标词汇取的是 buffer[skip_window]，并不是从 buffer[0] 开始的。如果目标单词是 e，因为 data_index = (data_index + 1) % len(data)，所以此时 buffer 中是[c, d, e, f, a]，取的样本依然是 4 个。所以 num_skips &lt;= 2 * skip_window。 12345data_index = 0def generate_batch(batch_size, num_skips, skip_window): global data_index assert batch_size % num_skips == 0 assert num_skips &lt;= 2 * skip_window 定义输入特征和输出： batch：输入特征 features，用 np.ndarray 将 batch 初始化为数组； labels：输出 labels，用 np.ndarray 将 labels 初始化为数组； 12batch = np.ndarray(shape=(batch_size), dtype=np.int32)labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32) 定义双向队列 buffer，用于存储长度为 span 的单词编号： span：对某个单词创建相关样本时会使用到的单词数量，包括目标单词本身和它前后的单词，因此 span=2*skip_window+1； buffer：容量为 span 的 deque（双向队列），在用 append 对 deque 添加变量时，只会保留最后插入的 span 个变量，其中存的是词的编号； 在函数 generate_batch 中，创建最大容量为 span 的 deque，从 data_index 开始，把 span 个单词顺序读入 buffer 作为初始值，buffer 中存的是词的编号。因为 buffer 是容量为 span 的 deque，所以此时 buffer 已经充满，后续数据将替换掉前面的数据。 123456span = 2 * skip_window + 1buffer = collections.deque(maxlen=span)for _ in range(span): buffer.append(data[data_index]) data_index = (data_index + 1) % len(data) 然后我们进入第一层循环（次数为 batch_size // num_skips），每次循环内对一个目标单词生成样本。现在 buffer 中是目标单词和所有相关单词，我们定义 target=skip_window，即 buffer 中第 skip_window 个单词为目标单词。然后定义生成样本时需要避免的单词列表 targets_to_avoid，这个列表开始包括第 skip_window 个单词（即目标单词），因为我们要预测的是语境单词，不包括目标单词本身。 接下来进入第二层循环（次数为 num_skips），每次循环对一个语境单词生成样本， 先产生一个随机数，直到随机数不在 targets_to_avoid 中，就可以将之作为语境单词。feature 是目标词汇 buffer[skip_window]，label 是 buffer[target]。同时，因为这个语境单词被使用了，所以再把它添加到 targets_to_avoid 中过滤。在对一个目标单词生生成完所有样本后（num_skips 个样本），我们再读入下一个单词（同时会抛掉 buffer 中第一个单词），即把滑窗向后移动一位，这样我们的目标单词也向后移动了一个，语境单词也整体后移了，便可以开始生成下一个目标单词的训练样本。 两层循环完成后，我们已经获得了 batch_size 个训练样本，将 batch 和 labels 作为函数结果返回。 123456789101112for i in range(batch_size // num_skips): target = skip_window targets_to_avoid = [skip_window] for j in range(num_skips): while target in targets_to_avoid: target = random.randint(0, span - 1) targets_to_avoid.append(target) batch[i * num_skips + j] = buffer[skip_window] labels[i * num_skips + j, 0] = buffer[target] buffer.append(data[data_index]) data_index = (data_index + 1) % len(data)return batch, labels 到目前为止，我们对训练数据的生成完成，接下来实现 Word2Vec。 实现 Word2Vec定义训练时需要的参数12345678910batch_size = 128embedding_size = 128 # 将单词转为稠密向量的维度，一般是500~1000这个范围内的值，这里设为128skip_window = 1 # 单词间最远可以联系到的距离num_skips = 2 # 对每个目标单词提取的样本数# 生成验证数据，随机抽取一些频数最高的单词，看向量空间上跟它们距离最近的单词是否相关性比较高valid_size = 16 # 抽取的验证单词数valid_window = 100 # 验证单词只从频数最高的 100 个单词中抽取valid_examples = np.random.choice(valid_window, valid_size, replace=False) # 随机抽取num_sampled = 64 # 训练时用来做负样本的噪声单词的数量 定义 Skip-Gram Word2Vec 模型网络结构Skip-Gram 模型有两个输入。一个是一组用整型表示的上下文单词，另一个是目标单词。给这些输入建立占位符节点，之后就可以填入数据了。 1234# 建立输入占位符train_inputs = tf.placeholder(tf.int32, shape=[batch_size])train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])valid_dataset = tf.constant(valid_examples, dtype=tf.int32) # 将前面随机产生的 valid_examples 转为 TensorFlow 中的 constant 这里谈得都是嵌套，那么需要定义一个嵌套参数矩阵。我们用唯一的随机值来初始化这个大矩阵。 12# 随机生成所有单词的词向量 embeddings，单词表大小 5000，向量维度 128embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)) 对噪声-比对的损失计算就使用一个逻辑回归模型。对此，我们需要对语料库中的每个单词定义一个权重值和偏差值。(也可称之为输出权重 与之对应的 输入嵌套值)。定义如下。 123nce_weights = tf.Variable( tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))nce_bias = tf.Variable(tf.zeros([vocabulary_size])) 然后我们需要对批数据中的单词建立嵌套向量，TensorFlow 提供了方便的工具函数。 12# 查找 train_inputs 对应的向量 embedembed = tf.nn.embedding_lookup(embeddings, train_inputs) 现在我们有了每个单词的嵌套向量，接下来就是使用噪声-比对的训练方式来预测目标单词。 123loss = tf.reduce_mean( tf.nn.nce_loss(weights=nce_weights, biases=nce_bias, labels=train_labels, inputs=embed, num_sampled=num_sampled, num_classes=vocabulary_size)) 我们对损失函数建立了图形节点，然后我们需要计算相应梯度和更新参数的节点，比如说在这里我们会使用随机梯度下降法，TensorFlow 也已经封装好了该过程。 1optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss) 训练模型定义最大的迭代次数为 10 万次，然后创建并设置默认的 session，并执行参数和初始化。在每一步迭代中，先使用 generate_batch 生成一个 batch 的 inputs 和 labels 数据，并用他们创建 feed_dict。然后使用 session.run() 执行一次优化器运算（即一次参数更新）和损失计算，并将这一步训练的 loss 积累到 average_loss。 为了观察运行过程，之后每2000 次循环，计算一个平均 loss 并显示出来。每 10000 次循环，计算一次验证单词与全部单词的相似度，并将每个验证单词最相近的 8 个单词显示出来。 12345678910111213141516171819202122232425262728293031with tf.Session(graph=graph) as session: init.run() print 'Initialized' average_loss = 0 for step in range(num_steps): batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window) feed_dict = &#123;train_inputs: batch_inputs, train_labels: batch_labels&#125; _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict) average_loss += loss_val if step % 2000 == 0: if step &gt; 0: average_loss /= 2000 print 'Average loss at step &#123;&#125; : &#123;&#125;'.format(step, average_loss) average_loss = 0 if step % 10000 == 0: sim = similarity.eval() for i in range(valid_size): valid_word = reverse_dictionary[valid_examples[i]] top_k = 8 nearest = (-sim[i, :]).argsort()[1:top_k + 1] log_str = 'Nearest to &#123;&#125; :'.format(valid_word) for k in range(top_k): close_word = reverse_dictionary[nearest[k]] log_str = '&#123;&#125; &#123;&#125;,'.format(log_str, close_word) print log_str final_embeddings = normalized_embeddings.eval()s 运行的一部分结果如下： 12345678910111213141516171819202122232425InitializedAverage loss at step 0 : 302.263977051Nearest to that : slime, armament, mtsho, reliever, apocrypha, vocalic, allosteric, usda,Nearest to in : oint, alvarado, centres, beavers, miura, processes, laud, lyricist,Nearest to history : howling, amalgamated, nupedia, wiener, tomahawk, quakers, profil, lactate,Nearest to used : foals, ueshiba, yazoo, frustrated, esters, deploy, vanity, affine,Nearest to than : travelled, inclination, occupational, kets, smoothing, pathways, solutions, zolt,Nearest to during : empiricists, png, worst, atman, ortelius, swayed, heaps, racks,Nearest to it : blockading, lyell, adjectives, karelian, fredericksburg, scatter, behe, ewes,Nearest to will : topple, lv, abram, challenged, osip, hst, corrupting, slammed,Nearest to which : prometheus, tropic, erosive, dai, haliotis, visualize, paradoxically, minors,Nearest to new : trajan, evacuate, melanogaster, eagerness, pam, flee, ferrol, strengthen,Nearest to one : heckel, pleadings, jam, washing, earnings, distinguishes, congratulate, lettering,Nearest to nine : cva, pictish, unruly, mysql, zinn, evangelists, vacancies, schedel,Nearest to more : dysrhythmias, nucleus, persistently, prophesies, samarkand, mojave, recreate, attempting,Nearest to its : pq, dreamed, robin, homesick, offensive, apostol, gur, companionship,Nearest to with : agm, cru, eos, nasal, litchfield, ccny, macross, exhorted,Nearest to after : bremen, ddrmax, lutherans, ward, deum, bracelets, crevasses, pv,Average loss at step 2000 : 114.135557295Average loss at step 4000 : 52.9445186524Average loss at step 6000 : 33.5687308327Average loss at step 8000 : 23.5443917145Average loss at step 10000 : 17.309888566Nearest to that : analogue, shoes, slime, motivating, austin, and, have, to,Nearest to in : and, of, with, by, from, nine, UNK, for, 结果可视化下面定义一个用来可视化 Word2Vec 效果的函数。这里 low_dim_embs 是降维到 2 维 的单词的空间向量，我们将在图表中展示每个单词的位置。我么使用 plt.scatter 显示散点图（单词的位置），并用 plt.annotate 展示单词本身，同时，使用 plt.savefig 保存图片到本地文件。 12345678def plot_with_labels(low_dim_embs, labels, filename='tsne.png'): assert low_dim_embs.shape[0] &gt;= len(labels), 'More labels then embeddings' plt.figure(figsize=(18, 18)) for i, label in enumerate(labels): x, y = low_dim_embs[i, :] plt.scatter(x, y) plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom') plt.savefig(filename) 我们使用 sklearn.manifold.TSNE 实现降维，这里直接将原始的 128 维的嵌入向量降到 2 维，再用前面的 plot_with_labels 函数进行展示。这里只展示词频最高的 100 个单词的可视化结果。 12345678from sklearn.manifold import TSNEimport matplotlib.pyplot as plttsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)plot_only = 100low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])labels = [reverse_dictionary[i] for i in range(plot_only)]plot_with_labels(low_dim_embs, labels) 从可视化结果可以看出，距离相近的单词在语义上具有很高的相似性。在训练 Word2Vec 模型时，为了获得比较好的结构，我们可以使用大规模的语料库，同时需要对参数进行调试，选取最合适的值。 完整代码及运行结果本文相关内容在 github.com/ywtail中，完整代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226# coding: utf-8from __future__ import divisionimport collectionsimport mathimport osimport randomimport zipfileimport numpy as npimport tensorflow as tfimport urllibfrom sklearn.manifold import TSNEimport matplotlib.pyplot as plt# 下载数据集def maybe_download(filename, expected_bytes): if not os.path.exists(filename): filename, _ = urllib.urlretrieve(url + filename, filename) statinfo = os.stat(filename) if statinfo.st_size == expected_bytes: print('Found and verified', filename) else: print(statinfo.st_size) raise Exception('Failed to verify ' + filename + '. Can you get to it with a browser?') return filenamefilename = maybe_download('text8.zip', 31344016)# 将词存入 word 列表中def read_data(filename): with zipfile.ZipFile(filename) as f: data = tf.compat.as_str(f.read(f.namelist()[0])).split() return datawords = read_data(filename)print 'Data size', len(words)vocabulary_size = 50000 # 将出现频率最高的 50000 个单词放入 count 列表中，然后放入 dicionary 中def build_dataset(words): count = [['UNK', -1]] # 前面是词汇，后面是出现的次数，这里的 -1 在下面会填上 UNK 出现的频数 # 将出现频次最高的 50000 个词存入count count.extend(collections.Counter(words).most_common(vocabulary_size - 1)) # -1 因为 UNK 已经占了一个了 dictionary = dict() for word, _ in count: dictionary[word] = len(dictionary) ''' 等价于，就是按 count 中词出现的顺序，分别给他们编号：0 1 2 ... for i in vocabulary_size: dictionary[count[i][0]]=i ''' # 编码：如果不出现在 dictionary 中，就以 0 作为编号，否则以 dictionary 中的编号编号 # 也就是将 words 中的所有词的编号存在 data 中，顺带查一下 UNK 有多少个，以便替换 count 中的 -1 data = list() unk_count = 0 for word in words: if word in dictionary: index = dictionary[word] else: index = 0 unk_count += 1 data.append(index) count[0][1] = unk_count # 编号：词 reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) return data, count, dictionary, reverse_dictionarydata, count, dictionary, reverse_dictionary = build_dataset(words)del words # 删除原始单词表，节约内存# 生成 Word2Vec 训练样本data_index = 0def generate_batch(batch_size, num_skips, skip_window): global data_index # 设为global 因为会反复 generate assert batch_size % num_skips == 0 assert num_skips &lt;= 2 * skip_window # 将 batch 和 labels 初始化为数组 batch = np.ndarray(shape=(batch_size), dtype=np.int32) labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32) # 对某个单词创建相关样本时会使用到的单词数量，包括目标单词本身和它前后的单词 span = 2 * skip_window + 1 # 创建最大容量为 span 的 deque（双向队列） # 在用 append 对 deque 添加变量时，只会保留最后插入的 span 个变量 buffer = collections.deque(maxlen=span) # 从 data_index 开始，把 span 个单词顺序读入 buffer 作为初始值，buffer 中存的是词的编号 for _ in range(span): buffer.append(data[data_index]) data_index = (data_index + 1) % len(data) # buffer 容量是 span，所以此时 buffer 已经填满，后续的数据将替换掉前面的数据 # 每次循环内对一个目标单词生成样本，前方已经断言能整除，这里使用 // 是为了保证结果是 int for i in range(batch_size // num_skips): # //除法只保留结果整数部分（python3中），python2中直接 / # 现在 buffer 中是目标单词和所有相关单词 target = skip_window # buffer 中第 skip_window 个单词为目标单词（注意第一个目标单词是 buffer[skip_window]，并不是 buffer[0]） targets_to_avoid = [skip_window] # 接下来生成相关（上下文语境）单词，应将目标单词拒绝 # 每次循环对一个语境单词生成样本 for j in range(num_skips): # 先产生一个随机数，直到随机数不在 targets_to_avoid 中，就可以将之作为语境单词 while target in targets_to_avoid: target = random.randint(0, span - 1) targets_to_avoid.append(target) # 因为这个语境单词被使用了，所以要加入到 targets_to_avoid batch[i * num_skips + j] = buffer[skip_window] # feature 是目标词汇 labels[i * num_skips + j, 0] = buffer[target] # label 是 buffer[target] buffer.append(data[data_index]) data_index = (data_index + 1) % len(data) return batch, labels# 训练需要的参数batch_size = 128embedding_size = 128 # 将单词转为稠密向量的维度，一般是500~1000这个范围内的值，这里设为128skip_window = 1 # 单词间最远可以联系到的距离num_skips = 2 # 对每个目标单词提取的样本数# 生成验证数据，随机抽取一些频数最高的单词，看向量空间上跟它们距离最近的单词是否相关性比较高valid_size = 16 # 抽取的验证单词数valid_window = 100 # 验证单词只从频数最高的 100 个单词中抽取valid_examples = np.random.choice(valid_window, valid_size, replace=False) # 随机抽取num_sampled = 64 # 训练时用来做负样本的噪声单词的数量graph = tf.Graph()with graph.as_default(): # 建立输入占位符 train_inputs = tf.placeholder(tf.int32, shape=[batch_size]) train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1]) valid_dataset = tf.constant(valid_examples, dtype=tf.int32) # 将前面随机产生的 valid_examples 转为 TensorFlow 中的 constant with tf.device('/cpu:0'): # 限定所有计算在 CPU 上执行 # 随机生成所有单词的词向量 embeddings，单词表大小 5000，向量维度 128 embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0)) # 查找 train_inputs 对应的向量 embed embed = tf.nn.embedding_lookup(embeddings, train_inputs) # 使用 NCE Loss 作为训练的优化目标 nce_weights = tf.Variable( tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size))) nce_bias = tf.Variable(tf.zeros([vocabulary_size])) # 使用 tf.nn.nce_loss 计算学习出的词向量 embed 在训练数据上的 loss，并使用 tf.reduce_mean 进行汇总 loss = tf.reduce_mean( tf.nn.nce_loss(weights=nce_weights, biases=nce_bias, labels=train_labels, inputs=embed, num_sampled=num_sampled, num_classes=vocabulary_size)) # 定义优化器为 SGD，且学习速率为 1.0 optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss) # 计算嵌入向量 embeddings 的 L2 范数 norm norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True)) # 标准化 normalized_embeddings = embeddings / norm # 查询验证单词的嵌入向量，并计算验证单词的嵌入向量与词汇表中所有单词的相似性 valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset) similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True) # 初始化所有模型参数 init = tf.global_variables_initializer()num_steps = 100001with tf.Session(graph=graph) as session: init.run() print 'Initialized' average_loss = 0 for step in range(num_steps): batch_inputs, batch_labels = generate_batch(batch_size, num_skips, skip_window) feed_dict = &#123;train_inputs: batch_inputs, train_labels: batch_labels&#125; _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict) average_loss += loss_val if step % 2000 == 0: if step &gt; 0: average_loss /= 2000 print 'Average loss at step &#123;&#125; : &#123;&#125;'.format(step, average_loss) average_loss = 0 if step % 10000 == 0: sim = similarity.eval() for i in range(valid_size): valid_word = reverse_dictionary[valid_examples[i]] top_k = 8 nearest = (-sim[i, :]).argsort()[1:top_k + 1] log_str = 'Nearest to &#123;&#125; :'.format(valid_word) for k in range(top_k): close_word = reverse_dictionary[nearest[k]] log_str = '&#123;&#125; &#123;&#125;,'.format(log_str, close_word) print log_str final_embeddings = normalized_embeddings.eval()# 可视化def plot_with_labels(low_dim_embs, labels, filename='tsne.png'): assert low_dim_embs.shape[0] &gt;= len(labels), 'More labels then embeddings' plt.figure(figsize=(18, 18)) for i, label in enumerate(labels): x, y = low_dim_embs[i, :] plt.scatter(x, y) plt.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom') plt.savefig(filename)tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)plot_only = 100low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])labels = [reverse_dictionary[i] for i in range(plot_only)]plot_with_labels(low_dim_embs, labels) 生成的可视化文件如下： 参考 图书：TensorFlow实战 / 黄文坚，唐源著 TensorFlow 中文社区：Vector Representations of Words]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sklearn决策树可视化]]></title>
    <url>%2F2017%2F06%2F08%2Fsklearn%E5%86%B3%E7%AD%96%E6%A0%91%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[scikit-learn 中决策树的可视化一般需要安装 graphviz：主要包括 graphviz 的安装和 python 的 graphviz 插件的安装。 brew install graphviz 安装graphviz pip install graphviz 安装python中的graphviz pip install pydotplus 安装python中的pydotplus 以下示例来自 scikit learn 官方文档 1.10. Decision Trees 代码的运行效果见 这个链接。 方法一：export_graphviz 将树导出为 Graphviz 格式123456789101112from sklearn import treefrom sklearn.datasets import load_iris# 载入sklearn中自带的数据Iris，构造决策树iris = load_iris()clf = tree.DecisionTreeClassifier()clf = clf.fit(iris.data, iris.target)# 训练完成后，我们可以用 export_graphviz 将树导出为 Graphviz 格式，存到文件iris.dot中with open("iris.dot", 'w') as f: f = tree.export_graphviz(clf, out_file=f) 此时已经在本地生成了 iris.dot 文件，在命令行输入dot -Tpdf iris.dot -o iris.pdf生成决策树的PDF可视化文件，打开 iris.pdf （open iris.pdf）就能够看到生成的图片了。 官网还提供了删除 iris.dot 文件的方法：（如果想要删除，也可以直接在命令行rm iris.dot） 12import osos.unlink('iris.dot') #os.unlink() 方法用于删除文件 方法二：使用 pydotplus 直接生成 iris.pdf按如下代码生成 iris_2.pdf，open iris_2.pdf 就能够看到决策树。12345import pydotplusdot_data = tree.export_graphviz(clf, out_file=None)graph = pydotplus.graph_from_dot_data(dot_data)graph.write_pdf('iris.pdf') 方法三：直接在 jupyter notebook 中生成代码的运行效果见 这个链接。 12345678from IPython.display import Image dot_data = tree.export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names=iris.target_names, filled=True, rounded=True, special_characters=True) graph = pydotplus.graph_from_dot_data(dot_data) Image(graph.create_png()) 参考 博客园：scikit-learn决策树算法类库使用小结 scikit learn官方文档 1.10. Decision Trees]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git常见问题及解决方案]]></title>
    <url>%2F2017%2F06%2F07%2FGit%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[git 重复上次失败的提交在git push时失败了，提示有单个文件超过 100M，所以不能 push。在本地删除了这个文件，再 git add、git commit -a -m、git push 依然失败，因为依然会进行上一次失败的 push，超过 100M 的文件依然尝试上传，即使此时在本地已经删除了。 此时git commit 或 git status 提示如下1Your branch is ahead of 'origin/master' by 3 commits. 解决方案参考：https://stackoverflow.com/questions/16288176/your-branch-is-ahead-of-origin-master-by-3-commits 因为不想再提交这个超过 100M 的文件，所以使用 git reset --hard origin/master 将本地重置为远程 git。再提交就成功了。 删除本地 git init 过的文件 override r—r—r—使用 rm -r filename 删除本地git init过的文件时，提示如下1override r--r--r-- XXXXXXX? 解决方案参考：https://unix.stackexchange.com/questions/104330/how-do-i-override-rw-r-r-root-wheel-for-a-all-files-in-a-directory 最终使用 sudo rm -r filename 删除成功。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow (5): CNN对CIFAR-10进行分类]]></title>
    <url>%2F2017%2F06%2F06%2FTensorFlow-5-CNN%E5%AF%B9CIFAR-10%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[本文将逐步实现一个稍微复杂一些的卷积网络，简单的 MNIST 数据集已经不适合用来评测其性能，在这里我们将使用 CIFAR-10 数据集来进行训练。本文的结构安排如下 介绍 CIFAR-10 数据集 实现 CNN 在网络中加入 LRN 对权重进行 L2 正则化 总结和对比 给出完整代码和运行结果 列出参考资料 本文中涉及的所有代码均在 github.com/ywtail 中。 CIFAR-10本文使用的数据集是 CIFAR-10。这是一个经典的数据集，包含 60000 张 32x32 的彩色图像，其中训练集是 50000 张，测试集 10000 张。CIFAR-10 如同其名，一共标注为 10 类，每一类图片 6000 张，这 10 类分别是 飞机， 汽车， 鸟， 猫， 鹿， 狗， 青蛙， 马， 船， 卡车，其中没有任何重叠的情况，也不会在一张图片中同时出现两类物体。它还有一个兄弟版本 CIFAR-100，其中标注了 100 类。 CIFAR-10 数据集非常通用，对 CIFAR-10 数据集的分类是机器学习中一个公开的基准测试问题，其任务是对一组 32x32 RGB 的图像进行分类。许多论文中都在这个数据集上进行了测试，目前 state-of-the-art 的工作已经可以达到 3.5% 的错误率了，但是需要训练很久，即使在 GPU 上也需要十几个小时。据深度学习三巨头之一 LeCun 说，现有的卷积神经网络已经可以对 CIFAR-10 进行很好的学习，这个数据集的问题已经解决了。 实现 CNN在这里我们要实现的 CNN 网络结构如下表 Layer 名称 描述 conv1 卷积层，ReLU激活函数 pool1 最大池化 conv2 卷积层，ReLU激活函数 pool2 最大池化 local3 全连接层，ReLU激活函数 local4 全连接层，ReLU激活函数 logits 模型的输出 下载 TesorFlow Models 库首先下载 TesorFlow Models 库，以便使用其中提供的 CIFAR-10 数据的类。在本文中构建模型的过程中，实际上只使用了 cifar10_input.py 和 cifar10.py 这两个文件。1git clone https://github.com/tensorflow/models.git 下载完后是一个名为 models 的文件夹，代码位于 models/image/cifar10/，文件组织结构如下 文件 作用 cifar10_input.py 读取本地CIFAR-10的二进制文件格式的内容。 cifar10.py 建立CIFAR-10的模型。 cifar10_train.py 在CPU或GPU上训练CIFAR-10的模型。 cifar10_multi_gpu_train.py 在多GPU上训练CIFAR-10的模型。 cifar10_eval.py 评估CIFAR-10模型的预测性能。 可以通过 cd models/tutorials/image/cifar10/ 在cifar10 文件夹下编写代码，也可以只将 cifar10 中的 cifar10_input.py 和 cifar10.py 拷贝出来。 加载数据这里需要调用下载的 cifar10 和 cifar10_input 类来对数据进行下载和处理，得到训练数据和测试数据。123456789# 载入需要用的库import cifar10, cifar10_inputimport tensorflow as tfimport numpy as npimport mathimport timedata_dir = 'cifar10_data/cifar-10-batches-bin' # 下载 CIFAR-10 的默认路径cifar10.maybe_download_and_extract() # 下载数据集，并解压、展开到其默认位置 接下来使用 cifar10_input 类中的 distorted_inputs 函数产生训练需要使用的数据，包括特征及其对应的 label，这里返回的是已经封装好的 tensor，每次执行都会生成一个 batch_size 的数量的样本。 batch_size 需要作为参数输入，所以先设定 batch_size，并使用 distorted_inputs 产生训练需要使用的数据。 distorted_inputs 对数据进行了 Data Augmentation（数据增强），即采取了一系列随机变换的方法来人为的增加数据集的大小： 对图像进行随机的左右翻转； 随机变换图像的亮度； 随机变换图像的对比度； 通过这些操作可以获取更多的样本（带噪声的），原来的一张图片可以变为多张图片，相当于扩大样本量，对提高准确率非常有帮助。从磁盘上加载图像并进行变换需要花费不少的处理时间。为了避免这些操作减慢训练过程，我们在 16 个独立的线程中并行进行这些操作，这16个线程被连续的安排在一个 TensorFlow 队列中（在训练过程中会启动线程队列）。 12batch_size=128images_train,labels_train=cifar10_input.distorted_inputs(data_dir=data_dir,batch_size=batch_size) 再使用 cifar10_input.inputs 生成测试数据，这里不需要进行太多处理，不需要对图片进行翻转或者修改亮度、对比度，不过需要剪裁图片正中间的 24x24 大小的区块，并进行数据标准化操作。1images_test,labels_test=cifar10_input.inputs(eval_data=True,data_dir=data_dir,batch_size=batch_size) 到此为止数据加载完毕，下面进行参数设置。 参数设置有些数据需要多次使用，所以写成函数。12345678910111213def weight_variable(shape, stddev): initial = tf.truncated_normal(shape, stddev=stddev) # stddev=stddev！！！ return tf.Variable(initial)def bias_variable(cons, shape): initial = tf.constant(cons, shape=shape) # 必须是 shape=shape return tf.Variable(initial)def conv(x, W): return tf.nn.conv2d(x, W, [1, 1, 1, 1], padding='SAME')def max_pool_3x3(x): return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME') 模型实现首先创建输入数据的 placeholder，在设定时需要注意，因为 batch_size 在之后定义的网络结构时被用到了，所以数据尺寸中的第一个值（样本条数）需要被预先设定，而不是像之前那样设定为 None。而数据尺寸中的图片尺寸为剪裁后的 24x24，因为图片是彩色 RGB 图片，所以通道数为 3。123456789101112131415161718192021222324252627282930313233343536image_holder = tf.placeholder(tf.float32, [batch_size, 24, 24, 3])label_holder = tf.placeholder(tf.int32, [batch_size])# 第一层weight1 = weight_variable([5, 5, 3, 64], 5e-2)bias1 = bias_variable(0.0, [64])conv1 = tf.nn.relu(conv(image_holder, weight1) + bias1)pool1 = max_pool_3x3(conv1)# 第二层weight2 = weight_variable([5, 5, 64, 64], 5e-2)bias2 = bias_variable(0.1, [64])conv2 = tf.nn.relu(conv(pool1, weight2) + bias2)pool2 = max_pool_3x3(conv2)reshape = tf.reshape(pool2, [batch_size, -1])dim = reshape.get_shape()[1].value# 全连接层weight3 = weight_variable([dim, 384], 0.04)bias3 = bias_variable(0.1, [384])local3 = tf.nn.relu(tf.matmul(reshape, weight3) + bias3)# 全连接层weight4 = weight_variable([384, 192], 0.04)bias4 = bias_variable(0.1, [192])local4 = tf.nn.relu(tf.matmul(local3, weight4) + bias4)# 输出weight5 = weight_variable([192, 10], 1 / 192.0)bias5 = bias_variable(0.0, [10])logits = tf.matmul(local4, weight5) + bias5 损失函数依然使用 cross_entropy 作为损失函数，不同的是在这里将 cross_entropy 的计算和 softmax 的计算混合在了一起，使用 tf.nn.sparse_softmax_cross_entropy_with_logits。然后将 cross_entropy 的均值添加到 total_loss 的 collection 中（后面会加入 L2 正则，所以计算 total_loss）。最后，使用 tf.add_n 将 collection 中的 loss 全部求和，得到最终的 loss。 优化器使用 Adam Optimizer。 使用 tf.nn.in_top_k 函数输出结果中 top k 的准确率，默认使用 top 1，也就是输出分数最高的那一类的准确率。12345678910111213# 损失函数def loss(logits, labels): labels = tf.cast(labels, tf.int64) cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy_per_example') cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy') tf.add_to_collection('losses', cross_entropy_mean) return tf.add_n(tf.get_collection('losses'), name='total_loss')loss = loss(logits, label_holder)train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)top_k_op = tf.nn.in_top_k(logits, label_holder, 1) 训练如下代码中的第三行启动前面提到的图片数据增强的线程队列，这里一共使用了 16 个线程来进行加速。注意，如果这里不启动线程，那么后续的 inference 及训练的操作都是无法开启的。12345678910111213141516sess = tf.InteractiveSession()tf.global_variables_initializer().run()tf.train.start_queue_runners()max_steps = 3000for step in range(max_steps): start_time = time.time() image_batch, label_batch = sess.run([images_train, labels_train]) _, loss_value = sess.run([train_op, loss], feed_dict=&#123;image_holder: image_batch, label_holder: label_batch&#125;) duration = time.time() - start_time if step % 10 == 0: examples_per_sec = batch_size / duration sec_per_batch = float(duration) print 'step &#123;&#125;,loss=&#123;&#125;,(&#123;&#125; examples/sec; &#123;&#125; sec/batch)'.format(step, loss_value, examples_per_sec, sec_per_batch) 评测准确率测试集一共有 10000 个样本，但是需要注意的是，我们依然要像训练时哪样使用固定的 batch_size，然后一个 batch 一个batch 地输入测试数据。 计算一共要多少个 batch 才能将全部样本测试完 在每一个 step 中使用 session 的 run 方法获取 images_test、labels_test 的 batch，再执行 top_k_op 计算模型在这个 batch 的 top 1 上预测正确的样本数。 汇总所有预测正确的结果，求得全部测试样本中预测正确的数量 求准确率的评测结果并打印 12345678910111213num_examples = 10000num_iter = int(math.ceil(num_examples / batch_size)) # 计算一共有多少组true_count = 0total_sample_count = num_iter * batch_sizestep = 0while step &lt; num_iter: image_batch, label_batch = sess.run([images_test, labels_test]) predictions = sess.run([top_k_op], feed_dict=&#123;image_holder: image_batch, label_holder: label_batch&#125;) true_count += np.sum(predictions) step += 1precision = true_count / total_sample_countprint 'precision = ', precision 运行结果为准确率 74.56%。实现的代码见 github.com/ywtail 中的 cnn.py 文件。 加入 LRNLRN 最早见于 Alex 那篇用 CNN 参加 ImageNet 比赛的论文，Alex 在论文中解释 LRN 层模仿了生物神经系统的“侧抑制”机制，对局部神经元的活动创建竞争环境，使得其中相应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。Alex 在 ImageNet 数据集上的实验表明，使用 LRN 后 CNN 在 Top1 的错误率可以降低 1.4%，因此在其经典的 AlexNet 中使用 LRN 层。LRN 对 ReLU 这种没有上限边界的激活函数会比较有用，因为它会从附近的多个卷积核的相应（Response）中挑选比较大的反馈，但不适合 Sigmoid 这种有固定边界并且能抑制过大值的激活函数。尝试加入 LRN，增强模型泛化能力。现在网络结构如下表 Layer 名称 描述 conv1 卷积层，ReLU激活函数 pool1 最大池化 norm1 LRN conv2 卷积层，ReLU激活函数 norm2 LRN pool2 最大池化 local3 全连接层，ReLU激活函数 local4 全连接层，ReLU激活函数 logits 模型的输出 在上述 CNN 中加入 LRN，准确率 73.90%。实现的代码见 github.com/ywtail 中的 cnn_lrn.py 文件。 对权重进行 L2 正则化为了避免过拟合，在神经网络中使用 L2 正则化。 在机器学习中，不管是分类还是回归任务，都可能因特征过多而导致过拟合，一般可以通过减少特征或者惩罚不重要特征的权重来缓解这个问题。但是通常我们并不知道该惩罚哪些特征的权重，而正则化就是帮助我们惩罚特征权重的，即 特征的权重也会成为模型损失函数的一部分。这样我们就可以筛选出最有效的特征，减少特征权重防止过拟合。 一般来说，L1 正则会制造稀疏的特征，大部分无用特征的权重会被置为 0，而L2 正则会让特征的权重不过大，使得特征的权重比较平均。 在定义初始化 weight 的函数时，像之前一样使用 tf.truncated_normal 截断的正态分布来处理初始化权重。与之前不同的是，给权重设置函数加一个参数 w1，如果 w1 不等于 0，就给 weight 加上一个 L2 的 loss，相当于做了一个 L2 的正则化处理。 123456def weight_variable(shape, stddev, w1): var = tf.Variable(tf.truncated_normal(shape, stddev=stddev)) # stddev=stddev！！！ if w1: weight_loss = tf.multiply(tf.nn.l2_loss(var), w1, name='weight_loss') tf.add_to_collection('losses', weight_loss) return var 修改好这个函数后，将两个全连接层 weight 设置的第三个参数改为不为 0 的数。例如：weight3 = weight_variable([dim, 384], 0.04, 0.004)实现的代码见 github.com/ywtail 中的 cnn_l2.py 文件。 总结本文中实现的卷积神经网络没有那么复杂，在只使用 3000 个batch（每个batch 包含 128 个样本）时，设计的 CNN 模型在 CIFAR-10 数据集中分类的准确率为 74.56%；在 CNN 的基础上增加了 LRN，准确率 73.90%；如果对全连接层的权重进行 L2 正则化，准确率 70.30%；同时增加了 LRN，并对全连接层的权重进行了 L2 正则化，准确率 71.90%。具体见下表 网络结构 说明 准确率 CNN 只有卷积层、池化层、全连接层 74.56% CNN+L2 对全连接层的 weights 进行了 L2 的正则化 70.30% CNN+LRN 在每个卷积-最大池化层中使用了 LRN 层 73.90% CNN+LRN+L2 同时使用 LRN 层和 L2 的正则化 71.90% 在这个卷积神经网络中，我们使用了一些新的技巧。 对 weights 进行了 L2 的正则化 对图片进行了翻转、随机剪切等数据增强，制造了更多样本（下载的 TesorFlow Models 库中的 cifar10_input.distorted_inputs 函数） 在每个卷积-最大池化层中使用了 LRN 层，增强了模型的泛化能力 卷积层一般需要和一个池化层连接，卷积加池化的组合目前已经是做图像处理时的一个标准组件了。卷积网络最后的几个全连接层的作用是输出分类结果，前面的卷积层主要做特征提取的工作，直到最后的全连接层才开始对特征进行组合匹配，并进行分类。 可以观察到，其实设计 CNN 主要就是安排卷积层、池化层、全连接层的分布和顺序，以及其中超参数的设置、Trick 的使用等。设计性能良好的 CNN 是有一定规律可循的，但是想要针对某个问题设计最合适的网络结构，是需要大量实践摸索的。 完整代码以下是在 CNN 中同时增加了 LRN，并对全连接层的权重进行了 L2 正则化的代码，其他相关代码参见 github.com/ywtail123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124# coding=utf-8# cnn_l2_lrnfrom __future__ import divisionimport cifar10, cifar10_inputimport tensorflow as tfimport numpy as npimport mathimport timedata_dir = 'cifar10_data/cifar-10-batches-bin' # 下载 CIFAR-10 的默认路径cifar10.maybe_download_and_extract() # 下载数据集，并解压、展开到其默认位置batch_size = 128images_train, labels_train = cifar10_input.distorted_inputs(data_dir=data_dir, batch_size=batch_size)images_test, labels_test = cifar10_input.inputs(eval_data=True, data_dir=data_dir, batch_size=batch_size)def weight_variable(shape, stddev, w1): var = tf.Variable(tf.truncated_normal(shape, stddev=stddev)) # stddev=stddev！！！ if w1: weight_loss = tf.multiply(tf.nn.l2_loss(var), w1, name='weight_loss') tf.add_to_collection('losses', weight_loss) return vardef bias_variable(cons, shape): initial = tf.constant(cons, shape=shape) # 必须是 shape=shape return tf.Variable(initial)def conv(x, W): return tf.nn.conv2d(x, W, [1, 1, 1, 1], padding='SAME')def max_pool_3x3(x): return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')image_holder = tf.placeholder(tf.float32, [batch_size, 24, 24, 3])label_holder = tf.placeholder(tf.int32, [batch_size])# 第一层weight1 = weight_variable([5, 5, 3, 64], 5e-2, 0.0)bias1 = bias_variable(0.0, [64])conv1 = tf.nn.relu(conv(image_holder, weight1) + bias1)pool1 = max_pool_3x3(conv1)norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)# 第二层weight2 = weight_variable([5, 5, 64, 64], 5e-2, 0.0)bias2 = bias_variable(0.1, [64])conv2 = tf.nn.relu(conv(norm1, weight2) + bias2)norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)pool2 = max_pool_3x3(norm2)reshape = tf.reshape(pool2, [batch_size, -1])dim = reshape.get_shape()[1].value# 全连接层weight3 = weight_variable([dim, 384], 0.04, 0.004)bias3 = bias_variable(0.1, [384])local3 = tf.nn.relu(tf.matmul(reshape, weight3) + bias3)# 全连接层weight4 = weight_variable([384, 192], 0.04, 0.004)bias4 = bias_variable(0.1, [192])local4 = tf.nn.relu(tf.matmul(local3, weight4) + bias4)# 输出weight5 = weight_variable([192, 10], 1 / 192.0, 0.0)bias5 = bias_variable(0.0, [10])logits = tf.matmul(local4, weight5) + bias5# 损失函数def loss(logits, labels): labels = tf.cast(labels, tf.int64) cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='cross_entropy_per_example') cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy') tf.add_to_collection('losses', cross_entropy_mean) return tf.add_n(tf.get_collection('losses'), name='total_loss')loss = loss(logits, label_holder)train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)top_k_op = tf.nn.in_top_k(logits, label_holder, 1)sess = tf.InteractiveSession()tf.global_variables_initializer().run()tf.train.start_queue_runners()max_steps = 3000for step in range(max_steps): start_time = time.time() image_batch, label_batch = sess.run([images_train, labels_train]) _, loss_value = sess.run([train_op, loss], feed_dict=&#123;image_holder: image_batch, label_holder: label_batch&#125;) duration = time.time() - start_time if step % 10 == 0: examples_per_sec = batch_size / duration sec_per_batch = float(duration) print 'step &#123;&#125;,loss=&#123;&#125;,(&#123;&#125; examples/sec; &#123;&#125; sec/batch)'.format(step, loss_value, examples_per_sec, sec_per_batch)num_examples = 10000num_iter = int(math.ceil(num_examples / batch_size)) # 计算一共有多少组true_count = 0total_sample_count = num_iter * batch_sizestep = 0while step &lt; num_iter: image_batch, label_batch = sess.run([images_test, labels_test]) predictions = sess.run([top_k_op], feed_dict=&#123;image_holder: image_batch, label_holder: label_batch&#125;) true_count += np.sum(predictions) step += 1precision = true_count / total_sample_countprint 'precision = ', precision 参考 图书：TensorFlow实战 / 黄文坚，唐源著 TensorFlow 中文社区：卷积神经网络]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow (4): 卷积神经网络识别手写数字]]></title>
    <url>%2F2017%2F06%2F05%2FTensorFlow-4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[使用全连接神经网络（Fully Connected Netword,FCN,MLP 的另一种说法）也是有局限的，即使我们使用很深的网络，很多的隐藏节点，很大的迭代轮数，也很难在 MNIST 数据集上达到 99% 以上的准确率。 因此接下来我们介绍卷积神经网络，以及如何在 MNIST 数据及上使用 CNN 达到 99% 以上的准确率。 卷积神经网络简介卷积神经网络（Convolutional Neural Network，CNN）最初是为解决图像识别等问题设计的，当然现在的应用不仅限于图像和视频，也可以用于时间序列信号，例如音频信号、文本数据等。 在早期的图像识别研究中，最大的挑战是如何组织特征，因为图像数据不像其他类型的数据那样可以通过人工理解来提取特征。在深度学习出现之前，必须借助SIFT 、HoG 等算法提取具有良好区分性的特征，再集合 SVM 等机器学习算法进行图像识别。然而 SIFT 这类算法提取的特征还是有局限性的，在 ImageNet ILSVRC 比赛的最好结果错误率也有 26% 以上，而且常年难以产生突破。卷积神经网络提取的特征则可以达到更好地效果，同时它不需要将特征提取和分类训练两个过程分开，它在训练时就自动提取了最有效的特征。 CNN 作为一个深度学习架构被提出的最初诉求，是降低对图像预处理的要求，以避免复杂的特征工程。CNN 可以直接使用图像的原始像素作为输入，而不必先使用 SIFT 等算法提取特征，减轻了使用传统算法如 SVM 时必须要做的大量重复、繁琐的数据预处理。和 SIFT 算法类似，CNN 训练的模型同样对缩放、平移、旋转等畸变具有不变形，有着很强的泛化性。 CNN 的最大特点在于卷积的权值共享结构，可以大幅度减少神经网络的参数量，防止过拟合的同时又降低了神经网络模型的复杂度。 总的来说，全连接神经网络之所以不太适合图像识别任务，主要有以下几个方面的问题： 参数数量太多 考虑一个输入1000*1000像素的图片(一百万像素，现在已经不能算大图了)，输入层有1000*1000=100 万节点。假设第一个隐藏层有 100 个节点(这个数量并不多)，那么仅这一层就有(1000*1000+1)*100=1 亿参数，这实在是太多了！我们看到图像只扩大一点，参数数量就会多很多，因此它的扩展性很差。 没有利用像素之间的位置信息 对于图像识别任务来说，每个像素和其周围像素的联系是比较紧密的，和离得很远的像素的联系可能就很小了。如果一个神经元和上一层所有神经元相连，那么就相当于对于一个像素来说，把图像的所有像素都等同看待，这不符合前面的假设。当我们完成每个连接权重的学习之后，最终可能会发现，有大量的权重，它们的值都是很小的(也就是这些连接其实无关紧要)。努力学习大量并不重要的权重，这样的学习必将是非常低效的。 网络层数限制 我们知道网络层数越多其表达能力越强，但是通过梯度下降方法训练深度全连接神经网络很困难，因为全连接神经网络的梯度很难传递超过 3 层。因此，我们不可能得到一个很深的全连接神经网络，也就限制了它的能力。 卷积神经网络解决这个问题主要有三个思路： 局部连接 这个是最容易想到的，每个神经元不再和上一层的所有神经元相连，而只和一小部分神经元相连。这样就减少了很多参数。 权值共享 一组连接可以共享同一个权重，而不是每个连接有一个不同的权重，这样又减少了很多参数。 下采样 可以使用 Pooling 来减少每层的样本数，进一步减少参数数量，同时还可以提升模型的鲁棒性。 对于图像识别任务来说，卷积神经网络通过尽可能保留重要的参数，去掉大量不重要的参数，来达到更好的学习效果。 关于卷积神经网络更详细的解读参见博客 零基础入门深度学习(4) - 卷积神经网络，作者总结的非常详细。 实现卷积神经网络加载数据首先加载 MNIST 数据集，并创建一个 TensorFlow 默认的 InteractiveSession，这样在后续的各项操作中就无需指定 Session 了。12345import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist=input_data.read_data_sets('MNIST_data/',one_hot=True)sess=tf.InteractiveSession() 权重初始化为了创建这个模型，我们需要创建大量的权重和偏置项，为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。 权重：这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免 0 梯度，因此标准差设为 0.1。 偏置：由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为 0 的问题（dead neurons）。 1234567def weight_variable(shape): initial=tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial=tf.constant(0.1,shape=shape) return tf.Variable(initial) 卷积和池化TensorFlow 在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？在这个实例里，我们会一直使用 vanilla 版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。我们的池化用简单传统的2x2大小的模板做 max pooling。为了代码更简洁，我们把这部分抽象成一个函数。 tf.nn.conv2d 是 TensorFlow 中的 2 维卷积函数，其中 x 是输入，W 是卷积的参数，Strides 代表卷积模板移动的步长，Padding 代表边界的处理方式，padding=&#39;SAME&#39; 表明不再给输入元素的周围补充元素，让卷积的输入和输出保持同样的尺寸。具体示例参见零基础入门深度学习(4) - 卷积神经网络。 tf.nn.max_pool 是 TensorFlow 中的最大池化函数，在这里使用 2x2 的最大池化，即将一个 2x2 的像素块降为 1x1 的像素。最大池化会保留原始像素块中灰度值最高的那一个像素，即保留最显著特征。池化层的 strides 设为横竖两个方向以 2 为步长。 12345def conv2d(x,W): return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME') 第一层卷积首先定义输入的 placeholder，x 是特征，y_ 是真实的 label。因为卷积神经网络会利用到空间结构信息，因此需要将 1D 的输入向量转为 2D 的图片结构，即从 1x784 的形式转为原始的 28x28 的结构。同时因为只有一个颜色通道，故最终尺寸为[-1,28,28,1]，前面的 -1 代表样本数量不固定，最后的 1 代表颜色通道数为 1（因为是灰度图所以这里的通道数为 1，如果是 rgb 彩色图，则为 3）。这里我们使用的 tensor 变形函数是 tf.reshape。 123x=tf.placeholder(tf.float32,[None,784])y_=tf.placeholder(tf.float32,[None,10])x_image=tf.reshape(x,[-1,28,28,1]) 现在我们可以开始实现第一层了。首先使用前面写好的函数进行参数初始化，包括 weights 和 bias。 weights：卷积的权重张量形状是 [5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目，即卷积核尺寸是 5x5，颜色通道是 1，有 32 个不同的卷积核。 bias：卷积在每个 5x5 的 patch 中算出 32 个特征，而对于每一个输出通道都有一个对应的偏置量。 第一层卷积由一个卷积接一个 max pooling 完成： 首先使用 conv2d 函数进行卷及操作，并加上偏置，接着再使用 ReLU 激活函数进行非线性处理。 然后使用最大池化函数 max_pool_2x2 对卷积的输出结果进行池化操作。 12345W_conv1=weight_variable([5,5,1,32])b_conv1=bias_variable([32])h_conv1=tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)h_pool1=max_pool_2x2(h_conv1) 第二层卷积这个卷积层基本和第一个卷积层一样，唯一不同的是，卷积核的数量变成了 64，也就是说每个 5x5 的patch 会得到 64 个特征。 12345W_conv2=weight_variable([5,5,32,64])b_conv2=bias_variable([64])h_conv2=tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)h_pool2=max_pool_2x2(h_conv2) 密集连接层因为前面经历了两次步长为 2x2 的最大池化，所以边长只有 1/4 了，即图片尺寸由 28x28 变为 7x7。并且由于第二个卷积层的卷积核数量为 64，所以输出的 tensor 尺寸是 7x7x64。 我们加入一个有 1024 个神经元的全连接层，用于处理整个图片。我们把池化层输出的张量 reshape 成一些向量，乘上权重矩阵，加上偏置，然后对其使用 ReLU。 12345W_fc1=weight_variable([7*7*64,1024])b_fc1=bias_variable([1024])h_pool2_flat=tf.reshape(h_pool2,[-1,7*7*64])h_fc1=tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1) Dropout为了减少过拟合，我们在输出层之前加入 Dropout。 我们用一个 placeholder 来代表一个神经元的输出在 dropout 中保持不变的概率。这样我们可以在训练过程中启用 dropout，在测试过程中关闭 dropout。TensorFlow 的 tf.nn.dropout 操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的 scale。所以用 dropout 的时候可以不用考虑 scale。 12keep_prob=tf.placeholder(tf.float32)h_fc1_drop=tf.nn.dropout(h_fc1,keep_prob) 输出层我们添加一个 softmax 层，就像前面的单层 softmax regression 一样，得到最后的概率输出。 1234W_fc2=weight_variable([1024,10])b_fc2=bias_variable([10])y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2) 这里的损失函数依然使用交叉信息熵，优化器使用 Adam，并把学习速率设为较小的 1e-4。 12cross_entropy=-tf.reduce_sum(y_*tf.log(y_conv))train_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) 再继续定义评测准确率的操作，这里和之前一样。 12correct_prediction=tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32)) 下面开始训练过程，首先依然是初始化所有参数。 keep_prob 在训练时设置为 0.5。这里采用 5000 个 batch，每个 batch 包含 50 条的样本，参与训练的样本量共 25 万。其中每 500 次训练，会对准确率进行一次测评（测评时 keep_prob 设为 1），用以检测模型的性能。 1234567tf.global_variables_initializer().run()for i in range(5000): # 20000次训练需要耗时30min，为了节省时间这次运行改为5000次 batch = mnist.train.next_batch(50) if i % 500 == 0: train_accuracy = accuracy.eval(&#123;x: batch[0], y_: batch[1], keep_prob: 1.0&#125;) print 'step &#123;&#125;,training accuracy &#123;&#125;'.format(i, train_accuracy) train_step.run(&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;) 全部训练完成后，在测试集上进行全面的测试，得到分类的准确率。 12test_accuracy=accuracy.eval(&#123;x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0&#125;)print 'test accuracy',test_accuracy 总结当进行 5000 次训练时，这个 CNN 模型可以得到 98.7% 的准确率，当进行 20000 次训练时，这个模型可以达到 99.18% 的准确率，基本可以满足对手写数字识别准确率的要求。 CNN 主要的性能提升都来自于更优秀的网络设计，即卷积网络对图像特征的提取和抽象能力。依靠卷积核的权值共享，CNN 的参数量并没有爆炸，减低计算量的同时也减轻了过拟合，因此整个模型的性能有较大的提升。 完整的代码及运行结果在 github 可以下载完整代码和数据集。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293# coding: utf-8# 卷积神经网络识别手写数字import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# 加载数据mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)sess = tf.InteractiveSession()# 权重初始化def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)# 卷积和池化def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')# 第一层卷积x = tf.placeholder(tf.float32, [None, 784])y_ = tf.placeholder(tf.float32, [None, 10])x_image = tf.reshape(x, [-1, 28, 28, 1])W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1)# 第二层卷积W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2)# 密集连接层W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)# Dropoutkeep_prob = tf.placeholder(tf.float32)h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)# 输出层W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)# 损失函数cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)# 定义准确率correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))# 训练tf.global_variables_initializer().run()for i in range(5000): # 20000次训练需要耗时30min，为了节省时间这次运行改为5000次 batch = mnist.train.next_batch(50) if i % 500 == 0: train_accuracy = accuracy.eval(&#123;x: batch[0], y_: batch[1], keep_prob: 1.0&#125;) print 'step &#123;&#125;,training accuracy &#123;&#125;'.format(i, train_accuracy) train_step.run(&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)# 测试准确率test_accuracy = accuracy.eval(&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;)print 'test accuracy', test_accuracy 输出：12345678910111213141516171819Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.Extracting MNIST_data/train-images-idx3-ubyte.gzSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.Extracting MNIST_data/train-labels-idx1-ubyte.gzSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.Extracting MNIST_data/t10k-images-idx3-ubyte.gzSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.Extracting MNIST_data/t10k-labels-idx1-ubyte.gzstep 0,training accuracy 0.20000000298step 500,training accuracy 0.899999976158step 1000,training accuracy 0.959999978542step 1500,training accuracy 0.939999997616step 2000,training accuracy 1.0step 2500,training accuracy 0.939999997616step 3000,training accuracy 0.980000019073step 3500,training accuracy 0.980000019073step 4000,training accuracy 1.0step 4500,training accuracy 0.980000019073test accuracy 0.987 参考 图书：TensorFlow实战 / 黄文坚，唐源著 TensorFlow 中文社区：MNIST 进阶 博客：零基础入门深度学习(4) - 卷积神经网络]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绘图可视化 (1): matplotlib绘图基础]]></title>
    <url>%2F2017%2F06%2F04%2F%E7%BB%98%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96-1-matplotlib%E7%BB%98%E5%9B%BE%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[本文主要参考 十分钟入门Matplotlib 文中绘制的图形在 这个链接 中显示。 Matplotlib 是 Python 的一个绘图库。它包含了大量的工具，你可以使用这些工具创建各种图形，包括简单的散点图，正弦曲线，甚至是三维图形。Python 科学计算社区经常使用它完成数据可视化的工作。 绘图过程中常用样式如下 颜色： 蓝色 - b 绿色 - g 红色 - r 青色 - c 品红 - m 黄色 - y 黑色 - k（b代表蓝色，所以这里用黑色的最后一个字母） 白色 - w线： 直线 - - 虚线 - -- 点线 - : 点划线 - -. 常用点标记 点 - . 像素 - , 圆 - o 方形 - s 三角形 - ^ 本文主要是在 jupyter notebook 中绘图，首先需要 import matplotlib，通常的引入约定如下 1234567import matplotlib.pyplot as plt%matplotlib inline # 加这行不需要再写plt.show()``` - 画折线，红色```pythonplt.plot([1,2,4,8,16],'r') 画 y=sin(x) 1234import numpy as npx=np.linspace(0,2*np.pi) plt.plot(x,np.sin(x)) 在一张图中绘制多个数据集 12x=np.linspace(0,2*np.pi)plt.plot(x,np.sin(x),x,np.sin(2*x)) 自定义图形的外观代码展示了两种不同的曲线样式：r-o 和 g--。字母 r 和 g 代表线条的颜色，后面的符号代表线和点标记的类型。例如 -o 代表包含实心点标记的实线，-- 代表虚线。 123x=np.linspace(0,2*np.pi)plt.plot(x,np.sin(x),'r-o', x,np.cos(x),'g--') 使用子图在一个窗口绘制多张图 12345x=np.linspace(0,2*np.pi)plt.subplot(2,1,1) #行，列，活跃区plt.plot(x,np.sin(x),'r') # 红色plt.subplot(2,1,2)plt.plot(x,np.cos(x),'g') # 绿色 绘制简单的散点图 12x=np.linspace(0,2*np.pi)plt.plot(x,np.sin(x),'go') # 绿色圆点 彩色映射散点图同前面一样我们用到了 scatter() 函数，但是这次我们传入了另外的两个参数，分别为所绘点的大小和颜色。通过这种方式使得图上点的大小和颜色根据数据的大小产生变化。然后我们用 colorbar() 函数添加了一个颜色栏。 123456x=np.random.rand(100)y=np.random.rand(100)size=np.random.rand(100)*50colour=np.random.rand(100)plt.scatter(x,y,size,colour)plt.colorbar() 直方图 12x=np.random.randn(100)*10plt.hist(x,50) 添加标题，坐标轴标记和图例为了给图形添加图例，我们需要在 plot() 函数中添加命名参数 label 并赋予该参数相应的标签。然后调用 legend() 函数就会在我们的图形中添加图例。接下来我们只需要调用函数 title()，xlabel() 和 ylabel() 就可以为图形添加标题和标签。 1234567x=np.linspace(0,2*np.pi)plt.plot(x,np.sin(x),'r-x',label='Sin(x)')plt.plot(x,np.cos(x),'g-^',label='Cos(x)')plt.legend() #展示图例，必须调用这个上面的label才会显示plt.xlabel('Reds') #给x轴添加标签plt.ylabel('Amplitude') #给y轴添加标签plt.title('Sin and Cos Waves') #添加图形标题]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>可视化</tag>
        <tag>matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow (3): 多层感知机识别手写数字]]></title>
    <url>%2F2017%2F06%2F03%2FTensorFlow-3-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[本文内容主要来自图书：TensorFlow实战 / 黄文坚，唐源著在 TensorFlow (2): Softmax Regression识别手写数字 中使用 TensorFlow 实现了Softmax Regression (无隐含层)，并在 MNIST 数据集上取得了 92% 的正确率。在这里将给神经网络加上隐含层，使用 TensorFlow 实现多层感知机，并对 MNIST 数据集中的手写数字进行识别。实现多层感知机中使用了 Dropout、Adagrad、ReLU 等辅助性组件。 多层感知机Softmax Regression 和传统意义上的神经网络的最大区别是没有隐含层。本文实现的多层感知机实际上是在 Softmax Regression 的基础上加上一个隐含层。隐含层是神经网络的一个重要概念，它是指除输入、输出层外，中间的那些层。输入层和输出层是对外可见的，通常也被称作可视层，而中间层不直接暴露出来，是模型的黑箱部分，通常也比较难具有可解释性，所以一般被称作隐含层。理论上只要隐含层节点足够多，即使只有一个隐含层的神经网络也可以拟合任意函数。同时，隐含层越多，越容易拟合复杂函数。有理论研究表明，拟合复杂函数需要的隐含节点的数目，基本上随着隐含层的数量增多而呈指数下降趋势。即层数越多，神经网络需要的隐含节点可以越少。这也是深度学习的特点之一，层数越深，概念越抽象，神经网络隐含节点就越少。不过在实际应用中，使用层数较深的神经网络会遇到许多困难，例如：过拟合、参数难以调试、帝都弥散等。这些问题需要很多策略来解决，在最近几年的研究中，越来越多的方法来帮助我们解决问题，例如：Dropout、Adagrad、ReLU等。 Dropout过拟合是机器学习中一个常见的问题，尤其是在神经网络中，由于参数众多，非常容易出现过拟合。为了解决这个问题，Hinton 教授团队提出了一个思路非常简单但是非常有效的方法 —— Dropout。它的大致思路是 在训练时，将神经网络某一层的输出节点数据随机丢弃一部分。可以理解为随机把一张图片的 50% 的点删掉，此时人依然很可能识别这张图片，机器也一样。这种做法实质上相当于随机创造了很多新的样本，通过增大样本量、减少特征数来防止过拟合。Dropout 其实也相当于是一种 Bagging 方法，可以理解成每次丢弃节点数据是对特征的一种采样。相当于我们训练了一个 ensemble 的神经网络模型，对每个样本都做特征采样，只不过没有训练多个神经网络模型，只有一个融合的神经网络。 Adagrad参数难以调试是神经网络的另一大难点，尤其是随机梯度下降（Stochastic Gradient Descent，SGD）的参数，对 SGD 设置不同的学习速率，最后得到的结果可能差异巨大。神经网络通常不是一个凸优化的问题，它处处充满了局部最优。SGD 本身不是一个比较稳定的算法，结果可能会在最优解附近波动，而不同的学习速率可能导致神经网络落入截然不同的局部最优之中。对 SGD，一开始我们希望学习速率大一些，可以加速收敛，但训练的后期又希望学习速率可以小一点，这样可以比较稳定地落入一个局部最优解。不同的机器学习所需要的学习速率也不太好设置，需要反复调试，因此就有像 Adagrad、Adam、Adadelta 等自适应的方法可以减轻调试参数的负担。对于这些优化算法，通常我们使用它默认的参数设置就可以取得一个比较好的效果。 ReLU梯度弥散（Gradient Vanishment）是另一个影响神经网络训练的问题，在 ReLU 激活函数出现之前，神经网络的训练全部是用 Sigmoid 作为激活函数。这可能是因为 Sigmoid 函数具有限制性，输出数值在 0~1，最符合概率输出的定义。非线性的 Sigmoid 函数在信号的特征空间映射上，对中央区的信号增益较大，对两侧区的信号增益小。因而在神经网络训练时，可以将重要特征置于中央区，而非重要的特征置于两侧区。但是当神经网络层数较多时，Sigmoid 函数在反向传播中梯度值会逐渐减小，经过多层的传递后会呈指数级急剧减小，因此梯度值在传递到前面几层时就会变得非常小了。在这种情况下，根据训练数据的反馈来更新神经网络参数将会非常缓慢，基本起不到训练的作用。直到 ReLU 出现，才比较完美地解决了梯度弥散的问题。ReLU 是一个简单的非线性函数 y=max(0,x) ，它在坐标轴上是一条折线，当 x &lt;= 0 时， y=0；当 x &gt; 0 时，y = x。ReLU 非常类似于人脑的阈值响应机制，信号在超过某个阈值时，神经元才会进入兴奋和激活的状态，平时则出于抑制状态。ReLU 可以很好地传递梯度，经过多层的反向传播，梯度依旧不会大幅缩小，因此非常适合训练很深的神经网络。ReLU 从正面解决了梯度弥散的问题，而不需要通过无监督的逐层训练初始化权重。ReLU 对比 Sigmoid 的主要变化有如下三点： 单侧抑制 相对宽阔的兴奋边界 稀疏激活性 目前，ReLU 及其变种（EIU，PReLU，RReLU）已经成为了最主流的激活函数。实践中大部分情况下（包括 MLP 和 CNN，RNN 内部主要还是使用 Sigmoid、Tanh、Hard Sigmoid）将隐含层的激活函数从 Sigmoid 替换为 ReLU都可以代练训练速度及模型准确率的提升。当然神经网络的输出层一般还是 Sigmoid 函数，因为它最接近概率输出分布。 TensorFlow 实现机器学习算法通用步骤使用 TensorFlow 实现了简单的机器学习算法整个流程可以分为4个部分： 定义算法公式，也就是神经网络的 forward 时的计算 定义 loss，选定优化器（这里选的是梯度下降），并指定优化器优化 loss 迭代地对数据进行训练 在测试集或验证集上对准确率进行测评 以上几个步骤是使用 TensorFlow 进行算法设计、训练的核心步骤。TensorFlow 和 Spark 类似，我们定义的各个公式其实只是 Computation Graph，在执行这行代码时，计算还没有实际发生，只有等调用 run 方法，并 feed 数据时计算才真正执行。比如 cross_entropy、train_step、accuracy 等都是计算图中的节点，而不是数据结果，我们可以通过调用 run 方法执行这些结点或者说运算操作来获取结果。 实现多层感知机加载数据首先加载 MNIST 数据集，并创建一个 TensorFlow 默认的 InteractiveSession，这样在后续的各项操作中就无需指定 Session 了。12345import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist=input_data.read_data_sets('MNIST_data/',one_hot=True)sess=tf.InteractiveSession() 定义各个参数 这里 in_units 是输入节点数，h1_units 是隐含层的输出节点数，在这里设置为 300。 W1、b1 是隐含层的权重和偏置，这里将偏置赋值为 0，并将权重初始化为截断的正态分布，其标准差为 0.1。因为模型使用的激活函数是 ReLU，所以需要使用正态分布给参数加一点噪声来打破完全对称并且避免 0 梯度。在其他的一些模型中，有时还需要给偏置赋上一些小的非零值来避免 dead neuron（死亡神经元）。 对于输出层的 Softmax，直接将权重 W2 和偏置 b2 全部初始化为 0 即可（对于 Sigmoid，在 0 附近最敏感、梯度最大） 123456in_units=784h1_units=300W1=tf.Variable(tf.truncated_normal([in_units,h1_units],stddev=0.1))b1=tf.Variable(tf.zeros([h1_units]))W2=tf.Variable(tf.zeros([h1_units,10]))b2=tf.Variable(tf.zeros([10])) 定义输入 x，由于 Dropout 的比率 keep_prob 是变化的（训练时小于1，预测时等于1），所以也定义成一个 placeholder。12x=tf.placeholder(tf.float32,[None,in_units])keep_prob=tf.placeholder(tf.float32) 定义模型结构 隐含层命名为 hidden1，激活函数为 ReLU，所以这个隐含层的计算公式就是 $y=relu(W1x+b1)$ 接下来调用 tf.nn.dropout 实现 Dropout 功能，这里的 keep_prob 是保留数据的比例，在训练时应小于 1，用以制造随机性，防止过拟合；在预测时应等于 1，即使用全部特征来预测样本的类别。 最后是输出层，这一层依旧使用 softmax 作激活函数。 123hidden1=tf.nn.relu(tf.matmul(x,W1)+b1)hidden1_drop=tf.nn.dropout(hidden1,keep_prob)y=tf.nn.softmax(tf.matmul(hidden1_drop,W2)+b2) 定义损失函数和选择优化器目前已经完成第一步：定义计算公式，即神经网络的 forward 计算。接下来进行第 2 步：定义损失函数和选择优化器来优化loss，这里的损失函数使用交叉信息熵，优化器选择自适应的优化器 Adagrad，并把学习速率设为 0.01. 123y_=tf.placeholder(tf.float32,[None,10])cross_entropy=-tf.reduce_sum(y_*tf.log(y))train_step=tf.train.AdagradOptimizer(0.01).minimize(cross_entropy) 训练模型这里加入了 keep_prob，在训练时设置为 0.75。一般来说，对越复杂越大规模的神经网络，Dropout 的效果越显著。为了达到一个比较好的效果，一共采用 5000 个 batch，每个 batch 包含 100 条的样本，一共 50 万的样本，相当于对全数据及进行了 9 轮（epoch）迭代。 1234tf.global_variables_initializer().run()for i in range(5000): batch_xs,batch_ys=mnist.train.next_batch(100) train_step.run(&#123;x:batch_xs,y_:batch_ys,keep_prob:0.75&#125;) 对模型进行准确率测评在这一步 keep_prob 设置为 1，这样可以达到模型最好的预测效果。 123correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))print accuracy.eval(&#123;x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0&#125;) 总结最终达到了 97% 的准确度，相比之前的 Softmax， 误差率由最初的 8% 下降到 3%，这个提升仅靠增加一个隐含层就实现了，可见多层神经网络的效果是十分显著的。当前，其中也使用了一些 Trick 进行辅助，例如 Dropout、Adagrad、ReLU等，但起决定性作用的还是隐含层本身，它能对特征进行抽象和转化。 完整的代码及运行结果123456789101112131415161718192021222324252627282930313233343536373839404142434445# coding: utf-8# 多层感知机识别手写数字import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# 加载 MNIST 数据集mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)sess = tf.InteractiveSession()# 定义各个参数in_units = 784h1_units = 300W1 = tf.Variable(tf.truncated_normal([in_units, h1_units], stddev=0.1))b1 = tf.Variable(tf.zeros([h1_units]))W2 = tf.Variable(tf.zeros([h1_units, 10]))b2 = tf.Variable(tf.zeros([10]))x = tf.placeholder(tf.float32, [None, in_units])keep_prob = tf.placeholder(tf.float32)# 定义模型结构hidden1 = tf.nn.relu(tf.matmul(x, W1) + b1)hidden1_drop = tf.nn.dropout(hidden1, keep_prob)y = tf.nn.softmax(tf.matmul(hidden1_drop, W2) + b2)# 定义损失函数和选择优化器来优化lossy_ = tf.placeholder(tf.float32, [None, 10])cross_entropy = -tf.reduce_sum(y_ * tf.log(y))train_step = tf.train.AdagradOptimizer(0.01).minimize(cross_entropy)# 训练模型tf.global_variables_initializer().run()for i in range(5000): batch_xs, batch_ys = mnist.train.next_batch(100) train_step.run(&#123;x: batch_xs, y_: batch_ys, keep_prob: 0.75&#125;)# 对模型进行准确率测评correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))print accuracy.eval(&#123;x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;) 输出：123456789Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.Extracting MNIST_data/train-images-idx3-ubyte.gzSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.Extracting MNIST_data/train-labels-idx1-ubyte.gzSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.Extracting MNIST_data/t10k-images-idx3-ubyte.gzSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.Extracting MNIST_data/t10k-labels-idx1-ubyte.gz0.97]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow (2): Softmax Regression识别手写数字]]></title>
    <url>%2F2017%2F06%2F02%2FTensorFlow-2-Softmax-Regression%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[MNIST手写数字识别是机器学习领域的Hello World任务。MNIST(Mixed National Institute of Standards and Techenology database)是一个非常简单的机器视觉数据集。由几万张28像素 x 28像素的手写数字组成，这些图片只包含灰度值信息。MNIST也包含每一张图片对应的标签，告诉我们这个是数字几。 数据集下载TensorFlow为我们提供了一个方便的封装，可以直接将MNIST数据集加载成我们期望的格式。只需要使用以下两行代码12from tensorflow.examples.tutorials.mnist import input_datamnist=input_data.read_data_sets('MNIST_data/',one_hot=True) 注意如果运行这两行代码报错：IOError: [Errno socket error] [Errno 60] Operation timed out可以尝试以下解决方法： 自行从极客学院下载数据集 新建MNIST_data文件夹，并将下载的4个.gz文件放入MNIST_data 将MNIST_data放入代码所在目录，运行上面的代码，成功输出提示信息，表示已经将MNIST数据集加载成我们期望的格式 MNIST数据集一共包含三个部分，打印一下数据的信息123print 'train:',mnist.train.images.shape,mnist.train.labels.shapeprint 'test:',mnist.test.images.shape,mnist.test.labels.shapeprint 'validation:',mnist.validation.images.shape,mnist.validation.labels.shape 输出是： train: (55000, 784) (55000, 10)test: (10000, 784) (10000, 10)validation: (5000, 784) (5000, 10) 这个结果表明： 训练数据集(55,000份，mnist.train)，测试数据集(10,000份，mnist.test)，验证数据集(5,000份，mnist.validation)。 mnist.train.images （训练集的图片）是一个形状为 [55000, 784]的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。每一张图片包含28像素X28像素。我们可以用一个数字数组来表示这张图片：把这个数组展开成一个向量，长度是 28x28 = 784。如何展开这个数组（数字间的顺序）不重要，只要保持各个图片采用相同的方式展开。 mnist.train.labels （训练集的标签）是一个 [55000, 10] 的数字矩阵，使用one-hot vectors，将数字n表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。 实现Softmax Regression模型这里使用一个很简单的数学模型Softmax Regression(更详细的信息参见TensorFlow 中文社区：MNIST机器学习入门)： y=softmax(Wx+b)使用TensorFlow实现实现Softmax Regression：12345import tensorflow as tfx=tf.placeholder(tf.float32,[None,784])W=tf.Variable(tf.zeros([784,10]))b=tf.Variable(tf.zeros([10]))y=tf.nn.softmax(tf.matmul(x,W)+b) #tf.matmul实现了 x 和 W 的乘积 这里的输入 x 是一个占位符 Placeholder，在需要时指定。Placeholder 的第一个参数是数据类型，第二个参数[None,784]代表 tensor 的 shape，也就是数据的尺寸，这里 None 代表不限条数的输入，784 代表每条输入是一个 784 维的向量。 为模型中的 W 和 b 创建 Variable 对象，Variable 对象是用来存储模型参数的，在模型训练迭代中是持久化的（比如一直放在显存中），它可以长期存在并且在每轮迭代中被更新。 这里将 W 和 b 全部初始化为 0，因为模型训练时会自动学习合适的值，所以对这个简单模型来说初始值不太重要。不过对于复杂的卷积网络、循环网络或者比较深的全连接网络，初始化的方法就比较重要，甚至至关重要。 这里 W 的 shape 是[784,10]，784 是特征的维数，10 代表有 10 类（Label 在 one-hot 编码后是 10 维的向量） 模型训练及评测为了训练模型，我们需要定义一个 loss function 损失函数来描述模型对问题的分类精度。loss function 越小代表模型的分类结果与真实值偏差越小，即模型越精确。这里，我们使用交叉熵函数（cross-entropy）作为代价函数，交叉熵是一个源于信息论中信息压缩领域的概念，但是现在已经应用在多个领域。它的定义如下： H_{y′}(y)=−\sum_{i}y_i'log(y_i)这里 y 是所预测的概率分布，而 y′ 是真实的分布(one-hot vector表示的图片label)。直观上，交叉熵函数的输出值表示了预测的概率分布与真实的分布的符合程度。交叉熵函数的实现如下（reduce_sum表示 ∑ 求和）12y_=tf.placeholder(tf.float32,[None,10]) # y_存储实际lablecross_entropy=-tf.reduce_sum(y_*tf.log(y)) 接下来以损失函数最小化为目标，来训练模型以得到参数 W 和 b 的值。这里使用梯度下降算法来最小化代价函数。123456789train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)init=tf.global_variables_initializer() # 对所有的参数进行初始化sess=tf.Session() # 在一个Session里运行模型sess.run(init) # 执行初始化for i in range(1000): batch_xs,batch_ys=mnist.train.next_batch(100) # 每次随机取100个样本进行训练 sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;) 现在已经完成了训练，接下来对模型的准确率进行验证。123correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))accuracy=tf.reduce_mean(tf.cast(correct_prediction,'float'))print(sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y_:mnist.test.labels&#125;)) # 输出模型在测试及上的准确率 tf.argmax是从一个 tensor 中寻找最大值的序号，tf.argmax(y,1)就是求各个预测的数字中概率最大的那一个，而tf.argmax(y_,1)是找样本的真实数字的类别。 tf.equal方法用来判断预测值与真实值是否相等，返回的correct_prediction是一个布尔值的列表，例如 [True, False, True, True]。 tf.cast将correct_prediction输出的 bool 值转换为 float，再求平均。 最后输出模型在测试集上的准确率，这里求得的准确率为 0.912。（目前最好的模型的准确率为99.7%） 完整的代码及运行结果12345678910111213141516171819202122232425262728293031323334353637383940414243# coding: utf-8import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets('MNIST_data/', one_hot=True)# 打印数据集基本本信息print '=' * 30print 'train:', mnist.train.images.shape, mnist.train.labels.shapeprint 'test:', mnist.test.images.shape, mnist.test.labels.shapeprint 'validation:', mnist.validation.images.shape, mnist.validation.labels.shapeprint '=' * 30# 实现softmax regression模型x = tf.placeholder(tf.float32, [None, 784]) # x 使用占位符，在后续输入时填充W = tf.Variable(tf.zeros([784, 10])) # W 和 b 参数使用Variable，在迭代过程中不断更新b = tf.Variable(tf.zeros([10]))y = tf.nn.softmax(tf.matmul(x, W) + b) # 即 y = softmax(xW+b)# 用cross_entropy作损失函数y_ = tf.placeholder(tf.float32, [None, 10]) # y_表示 label的实际值cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) # 实现交叉熵函数# 训练模型train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)init = tf.global_variables_initializer() # 对所有的参数进行初始化sess = tf.Session() # 在一个Session里运行模型sess.run(init) # 执行初始化for i in range(5000): batch_xs, batch_ys = mnist.train.next_batch(100) # 每次随机取100个样本进行训练 sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;)# 判断预测值与真实值是否相等，返回的correct_prediction是一个布尔值的列表，例如 [True, False, True, True]。correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))# 将correct_prediction输出的bool值转换为float，再求平均accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))# 输出模型在测试及上的准确率print(sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)) 如果使用sess = tf.InteractiveSession()将当前这个session注册为默认的session，那么后续的有些写法能够简洁一些，例如sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})可以直接写为train_step.run({x: batch_xs, y_: batch_ys})，完整代码见 https://github.com/ywtail/ 输出：1234567891011121314Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.Extracting MNIST_data/train-images-idx3-ubyte.gzSuccessfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.Extracting MNIST_data/train-labels-idx1-ubyte.gzSuccessfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.Extracting MNIST_data/t10k-images-idx3-ubyte.gzSuccessfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.Extracting MNIST_data/t10k-labels-idx1-ubyte.gz==============================train: (55000, 784) (55000, 10)test: (10000, 784) (10000, 10)validation: (5000, 784) (5000, 10)==============================0.922 总结上面使用 TensorFlow 实现了一个简单的机器学习算法 Softmax Regression，这可以算作是一个没有隐含层的最浅的神经网络。整个流程可以分为4个部分： 定义算法公式，也就是神经网络的 forward 时的计算 定义 loss，选定优化器（这里选的是梯度下降），并指定优化器优化 loss 迭代地对数据进行训练 在测试集或验证集上对准确率进行测评 以上几个步骤是使用 TensorFlow 进行算法设计、训练的核心步骤。TensorFlow 和 Spark 类似，我们定义的各个公式其实只是 Computation Graph，在执行这行代码时，计算还没有实际发生，只有等调用 run 方法，并 feed 数据时计算才真正执行。比如 cross_entropy、train_step、accuracy 等都是计算图中的节点，而不是数据结果，我们可以通过调用 run 方法执行这些结点或者说运算操作来获取结果。 参考 图书：TensorFlow实战 / 黄文坚，唐源著 Jey Zhang 的博客：TensorFlow学习笔记1：入门 TensorFlow 中文社区：MNIST机器学习入门]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nowcoder(6):相邻最大差值; 最长递增子序列; 字符串的旋转]]></title>
    <url>%2F2017%2F05%2F16%2Fnowcoder-6-%E7%9B%B8%E9%82%BB%E6%9C%80%E5%A4%A7%E5%B7%AE%E5%80%BC-%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%97%8B%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[相邻最大差值题目描述题目链接 请设计一个复杂度为O(n)的算法，计算一个未排序数组中排序后相邻元素的最大差值。给定一个整数数组A和数组的大小n，请返回最大差值。保证数组元素个数大于等于2小于等于500。 测试样例 [9,3,1,10],4返回：6 代码 由于题中数组元素&gt;=2且&lt;=500（数组长度并不大），并且要求复杂度为O(n)，可以考虑桶排序。 申请长度为max(A) - min(A) + 1的bucket数组作为桶，遍历A，令bucket[A[i] - min(A)] = 1。 最后遍历bucket，连续0的长度的最大值+1即为最大差值。12345678910111213141516171819202122# -*- coding:utf-8 -*-class MaxDivision: def findMaxDivision(self, A, n): bucket = [0 for i in range(max(A) - min(A) + 1)] for i in range(n): bucket[A[i] - min(A)] = 1 count = 1 ans = 0 for i in range(len(bucket)): if bucket[i] == 0: count += 1 else: ans = max(ans, count) count = 1 return ans # 运行时间：100ms # 占用内存：3156kmaxdivision = MaxDivision()print maxdivision.findMaxDivision([208, 254, 473, 153, 389, 579, 398], 7) # 返回135 最长递增子序列题目描述题目链接 对于一个数字序列，请设计一个复杂度为O(nlogn)的算法，返回该序列的最长上升子序列的长度，这里的子序列定义为这样一个序列U1，U2…，其中Ui &lt; Ui+1，且A[Ui] &lt; A[Ui+1]。给定一个数字序列A及序列的长度n，请返回最长上升子序列的长度。 测试样例 [2,1,4,3,1,5,6],7返回：4 代码 复杂度为O(n^2)使用length[]数组维护以当前元素结尾的递增子序列的长度：如果A[j] &lt; A[i]，则length[i]=max(length[i],length[j]+1)，最后返回max(length)就是最长递增子序列长度。 123456789101112131415161718# -*- coding:utf-8 -*-class AscentSequence: def findLongest(self, A, n): length = [1 for i in range(n)] ans = 1 for i in range(1, n): for j in range(i): if A[j] &lt; A[i] and length[j] + 1 &gt; length[i]: length[i] = length[j] + 1 ans = max(ans, length[i]) return ans #运行时间：350ms #占用内存：3156kascentsequence = AscentSequence()print ascentsequence.findLongest([2, 1, 4, 3, 1, 5, 6], 7) 复杂度为O(nlogn)使用数组B[i]来维护长度为i+1的递增子序列的最小末尾：从左向右遍历数组A，如果A[i]大于B中最后一个元素，则将A[i]加入B中；如果A[i]小于B中最后一个元素，则在B中找合适的位置j，用A[i]替换B[j]。这里注意在B中找合适位置使用二分法，以减少复杂度。 123456789101112131415161718192021222324252627282930313233343536# -*- coding:utf-8 -*-class AscentSequence: def findLongest(self, A, n): B = [0 for i in range(n)] b_endindex = 0 # 记录B最后一个元素的下标 B[0] = A[0] for i in range(1, n): if A[i] &gt; B[b_endindex]: b_endindex += 1 B[b_endindex] = A[i] else: temp_index = self.findIndex(B, A[i], b_endindex) B[temp_index] = A[i] return b_endindex + 1 # 运行时间：130ms # 占用内存：3156k # 二分法查找B中第一个比b大的元素的下标，作为替换位置 def findIndex(self, B, b, b_endindex): left = 0 right = b_endindex while (left &lt; right): mid = (left + right) / 2 if b == B[mid]: return mid elif b &lt; B[mid]: #注意这里不是right=mid-1，因为要寻找的是第一个比b大的元素的下标，可能就是B[mid]，而B[mid-1]可能就小于b了。 right = mid else: left = mid + 1 return leftascentsequence = AscentSequence()print ascentsequence.findLongest([2, 1, 4, 3, 1, 5, 6], 7) 例如：序列A[0..8] = 2 1 5 3 6 4 8 9 7，最终B[0..4] = 1, 3, 4, 7, 9，而不是B[0..4] = 1, 3, 4, 8, 9，这个1,3,4,7,9不是LIS字符串，7代表的意思是存储4位长度递增子序列的最小末尾是7。当序列为A[0..10]= 2 1 5 3 6 4 8 9 7 8 9时，用B[i]来维护长度为i+1的递增子序列的最小末尾，最终B[0..5]=1, 3, 4, 7, 8, 9，得到正确答案6。 字符串的旋转题目描述题目链接 对于一个字符串，和字符串中的某一位置，请设计一个算法，将包括i位置在内的左侧部分移动到右边，将右侧部分移动到左边。给定字符串A和它的长度n以及特定位置p，请返回旋转后的结果。 测试样例 “ABCDEFGH”,8,4返回：”FGHABCDE” 代码 找到截断点，用截断点右侧字符串连接左侧字符串。 1234567891011# -*- coding:utf-8 -*-class StringRotation: def rotateString(self, A, n, p): return A[p + 1:] + A[:p + 1] # 运行时间：40ms # 占用内存：3156kstringrotation = StringRotation()print stringrotation.rotateString("ABCDEFGH", 8, 4) 两个A连接，从位置p+1开始，截取长度为n的串即为答案。 1234567891011# -*- coding:utf-8 -*-class StringRotation: def rotateString(self, A, n, p): return (A + A)[p + 1:p + 1 + n] # 运行时间：30ms # 占用内存：3156kstringrotation = StringRotation()print stringrotation.rotateString("ABCDEFGH", 8, 4)]]></content>
      <categories>
        <category>nowcoder</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nowcoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nowcoder(5):最长公共子串; 股票交易日; 之字形打印矩阵]]></title>
    <url>%2F2017%2F05%2F09%2Fnowcoder-5-%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E4%B8%B2-%E8%82%A1%E7%A5%A8%E4%BA%A4%E6%98%93%E6%97%A5-%E4%B9%8B%E5%AD%97%E5%BD%A2%E6%89%93%E5%8D%B0%E7%9F%A9%E9%98%B5%2F</url>
    <content type="text"><![CDATA[最长公共子串题目描述题目链接 对于两个字符串，请设计一个时间复杂度为O(m*n)的算法(这里的m和n为两串的长度)，求出两串的最长公共子串的长度。这里的最长公共子串的定义为两个序列U1,U2,..Un和V1,V2,…Vn，其中Ui + 1 == Ui+1,Vi + 1 == Vi+1，同时Ui == Vi。给定两个字符串A和B，同时给定两串的长度n和m。 测试样例 “1AB2345CD”,9,”12345EF”,7返回：4 代码 动态规划。123456789101112131415161718# -*- coding:utf-8 -*-class LongestSubstring: def findLongest(self, A, n, B, m): table = [[0 for i in range(m + 1)] for j in range(n + 1)] # 这样初始化不用考虑[i-1]和[j-1]是否越界的问题 ans = 0 for i in range(1, n + 1): for j in range(1, m + 1): if A[i - 1] == B[j - 1]: table[i][j] = table[i - 1][j - 1] + 1 ans = max(ans, table[i][j]) return ans # 运行时间：180ms # 占用内存：3156klongestsubstring = LongestSubstring()print longestsubstring.findLongest("1AB2345CD", 9, "12345EF", 7) 股票交易日题目描述题目链接 在股市的交易日中，假设最多可进行两次买卖(即买和卖的次数均小于等于2)，规则是必须一笔成交后进行另一笔(即买-卖-买-卖的顺序进行)。给出一天中的股票变化序列，请写一个程序计算一天可以获得的最大收益。请采用实践复杂度低的方法实现。给定价格序列prices及它的长度n，请返回最大收益。保证长度小于等于500。 测试样例 [10,22,5,75,65,80],6返回：87 代码 求出以i点为分割点，左半段最大收益的数组leftprof，和右半段最大收益的数组rightprof。然后遍历，找出最大的leftprof[i]+rightprof[i]组合。1234567891011121314151617181920212223242526# -*- coding:utf-8 -*-# coding=utf-8class Stock: def maxProfit(self, prices, n): leftmin = prices[0] rightmax = prices[n - 1] leftprof = [0 for i in range(n)] rightprof = [0 for i in range(n)] sum = 0 for i in range(1, n): leftmin = min(leftmin, prices[i]) # 从左向右找最小price记为leftmin leftprof[i] = max(leftprof[i - 1], prices[i] - leftmin) for j in range(0, n - 1)[::-1]: rightmax = max(rightmax, prices[j]) # 从右向左找最大值记为rightmax rightprof[j] = max(rightprof[j + 1], rightmax - prices[j]) for i in range(n): # 以i为分割点，左半段最大收益为leftprof[i]，右半段最大收益为rightprof[i] sum = max(sum, leftprof[i] + rightprof[i]) return sum # 运行时间：50ms # 占用内存：3156kstock = Stock()print stock.maxProfit([10, 22, 5, 75, 65, 80], 6) 之字形打印矩阵题目描述题目链接 对于一个矩阵，请设计一个算法，将元素按“之”字形打印。具体见样例。给定一个整数矩阵mat，以及他的维数nxm，请返回一个数组，其中元素依次为打印的数字。 测试样例 [[1,2,3],[4,5,6],[7,8,9],[10,11,12]],4,3返回：[1,2,3,6,5,4,7,8,9,12,11,10] 代码 行是奇数时从左到右，行是偶数时从右到左。1234567891011121314151617# -*- coding:utf-8 -*-class Printer: def printMatrix(self, mat, n, m): ans = [] for i in range(n): if i % 2 == 0: ans += mat[i] else: ans += mat[i][::-1] return ans # 运行时间：350ms # 占用内存：3148kprinter = Printer()print printer.printMatrix([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], 4, 3)]]></content>
      <categories>
        <category>nowcoder</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nowcoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nowcoder(4):左右最值最大差; 年终奖; 最长公共子序列]]></title>
    <url>%2F2017%2F05%2F05%2Fnowcoder-4-%E5%B7%A6%E5%8F%B3%E6%9C%80%E5%80%BC%E6%9C%80%E5%A4%A7%E5%B7%AE-%E5%B9%B4%E7%BB%88%E5%A5%96-%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[左右最值最大差题目描述题目链接 给定一个长度为N(N&gt;1)的整型数组A，可以将A划分成左右两个部分，左部分A[0..K]，右部分A[K+1..N-1]，K可以取值的范围是[0,N-2]。求这么多划分方案中，左部分中的最大值减去右部分最大值的绝对值，最大是多少？给定整数数组A和数组的大小n，请返回题目所求的答案。 测试样例 [2,7,3,1,1],5返回：6 代码 这一题思路很巧妙：先找最大值maxnum（这个最大值肯定是某一边的最值），再对比两个端点处(A[0]与A[n-1])的数值，数值大的与maxnum在一边，数值小的就是另一边的最值（假设A[n-1] &lt; A[0]，那么A[n-1]就是右边的最值。因为继续往左扩充，如果A[n-2] &lt; A[n-1]，那么右边的最大值依然是A[n-1]，如果A[n-2] &gt; A[n-1]，那么显然右侧只包含A[n-1]一个元素时，左部分中的最大值减去右部分最大值的绝对值最大，最值依然是A[n-1]），求得的这两个值的差值就是答案。1234567891011121314# -*- coding:utf-8 -*-class MaxGap: def findMaxGap(self, A, n): maxnum = max(A) minnum = min(A[0], A[n - 1]) return maxnum - minnummaxgap = MaxGap()print maxgap.findMaxGap([2, 7, 3, 1, 1], 5)# 运行时间：40ms# 占用内存：3156k 年终奖题目描述题目链接 小东所在公司要发年终奖，而小东恰好获得了最高福利，他要在公司年会上参与一个抽奖游戏，游戏在一个6 x 6的棋盘上进行，上面放着36个价值不等的礼物，每个小的棋盘上面放置着一个礼物，他需要从左上角开始游戏，每次只能向下或者向右移动一步，到达右下角停止，一路上的格子里的礼物小东都能拿到，请设计一个算法使小东拿到价值最高的礼物。给定一个6 x 6的矩阵board，其中每个元素为对应格子的礼物价值,左上角为[0,0],请返回能获得的最大价值，保证每个礼物价值大于100小于1000。 代码 典型的动态规划算法。123456789101112131415161718# -*- coding:utf-8 -*-class Bonus: def getMost(self, board): for i in range(6): for j in range(6): board[i][j] += max(board[i][j - 1] if j &gt; 0 else 0, board[i - 1][j] if i &gt; 0 else 0) return board[5][5]bonus = Bonus()print bonus.getMost([[200, 700, 300, 100, 100, 400], [200, 700, 300, 100, 100, 400], [200, 700, 300, 100, 100, 400], [200, 700, 300, 100, 100, 400], [200, 700, 300, 100, 100, 400], [200, 700, 300, 100, 100, 400]])# 输出5300# 运行时间：30ms# 占用内存：3156k 最长公共子序列题目描述题目链接 对于两个字符串，请设计一个高效算法，求他们的最长公共子序列的长度，这里的最长公共子序列定义为有两个序列U1,U2,U3…Un和V1,V2,V3…Vn,其中Ui&amp;ltUi+1，Vi&amp;ltVi+1。且A[Ui] == B[Vi]。给定两个字符串A和B，同时给定两个串的长度n和m，请返回最长公共子序列的长度。保证两串长度均小于等于300。 测试样例 “1A2C3D4B56”,10,”B1D23CA45B6A”,12返回：6 代码 动态规划，将公共长度存到ans[N+1][M+1]数组中，求ans[i][j]。123456789101112131415161718# -*- coding:utf-8 -*-class LCS: def findLCS(self, A, n, B, m): ans = [[0 for i in range(m + 1)] for j in range(n + 1)] # 这样初始化不用考虑[i-1]和[j-1]是否越界的问题 for i in range(1, n + 1): for j in range(1, m + 1): if A[i - 1] == B[j - 1]: ans[i][j] = ans[i - 1][j - 1] + 1 else: ans[i][j] = max(ans[i][j - 1], ans[i - 1][j]) return ans[n][m] # 运行时间：240ms # 占用内存：3148klcs = LCS()print lcs.findLCS("1A2C3D4B56", 10, "B1D23CA45B6A", 12)]]></content>
      <categories>
        <category>nowcoder</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nowcoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nowcoder(3):顺时针旋转矩阵; 抛小球; 数组单调和; 字符串通配]]></title>
    <url>%2F2017%2F04%2F11%2Fnowcoder-3-%E9%A1%BA%E6%97%B6%E9%92%88%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5-%E6%8A%9B%E5%B0%8F%E7%90%83-%E6%95%B0%E7%BB%84%E5%8D%95%E8%B0%83%E5%92%8C-%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%80%9A%E9%85%8D%2F</url>
    <content type="text"><![CDATA[顺时针旋转矩阵题目描述题目链接 有一个NxN整数矩阵，请编写一个算法，将矩阵顺时针旋转90度。给定一个NxN的矩阵，和矩阵的阶数N,请返回旋转后的NxN矩阵,保证N小于等于300。 测试样例 [[1,2,3],[4,5,6],[7,8,9]],3返回：[[7,4,1],[8,5,2],[9,6,3]] 代码 常规思路 123456789101112# -*- coding:utf-8 -*-class Rotate: def rotateMatrix(self, mat, n): rotate_mat = [[0 for i in range(n)] for j in range(n)] for i in range(n): for j in range(n): rotate_mat[i][j] = mat[n - j - 1][i] return rotate_mat# 运行时间：400ms# 占用内存：3148k 在评论中看到另一种：使用zip，只有一行代码 参考：Python中zip()函数用法实例教程 zip()是Python的一个内建函数，它接受一系列可迭代的对象作为参数，将对象中对应的元素打包成一个个tuple（元组），然后返回由这些tuples组成的list（列表）。若传入参数的长度不等，则返回list的长度和参数中长度最短的对象相同。利用*号操作符，可以将list unzip（解压）。 123456789&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6]&gt;&gt;&gt; c = [4,5,6,7,8]&gt;&gt;&gt; zipped = zip(a,b)[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; zip(a,c)[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; zip(*zipped)[(1, 2, 3), (4, 5, 6)] 根据以上zip的用法，这一题可以这样写： 12345678# -*- coding:utf-8 -*-class Rotate: def rotateMatrix(self, mat, n): return [x[::-1] for x in zip(*mat)]# 运行时间：380ms# 占用内存：3148k 抛小球题目描述题目链接 小东和三个朋友一起在楼上抛小球，他们站在楼房的不同层，假设小东站的楼层距离地面N米，球从他手里自由落下，每次落地后反跳回上次下落高度的一半，并以此类推知道全部落到地面不跳，求4个小球一共经过了多少米？(数字都为整数)给定四个整数A,B,C,D，请返回所求结果。 测试样例 100,90,80,70返回：1020 代码 看了讨论才知道这题需要用到极限。 设楼层距离地面n米，则第一次落地共经过n米，第二次共经过n+n*1/2*2米，第三次共经过n+n*1/2*2+n*1/4*2米，第四次共经过n+n*1/2*2+n*1/4*2+n*1/8*2米，第m次共经过n+n*1/2*2+...+n*(1/2)^(m-1)*2米，计算得n+2n(1/2+1/4+1/8+...+(1/2)^(m-1)=n+2n(1-(1/2)^(m-1))，m趋于无穷（每次1/2一直不会为0），即(1/2)^(m-1)=0，所以m次共经过n+2n(1-(1/2)^(m-1))=n+2n=3n米。 所以答案为 3*(A+B+C+D) 12345678# -*- coding:utf-8 -*-class Balls: def calcDistance(self, A, B, C, D): return 3*(A+B+C+D)# 运行时间：20ms# 占用内存：3156k 数组单调和题目描述题目链接 现定义数组单调和为所有元素i的f(i)值之和。这里的f(i)函数定义为元素i左边(不包括其自身)小于等于它的数字之和。请设计一个高效算法，计算数组的单调和。给定一个数组A同时给定数组的大小n，请返回数组的单调和。保证数组大小小于等于500，同时保证单调和不会超过int范围。 测试样例 [1,3,5,2,4,6],6返回：27 代码 题目提示动态规划，暂时没有想到动态规划的解法，以下是常规求解12345678910111213# -*- coding:utf-8 -*-class MonoSum: def calcMonoSum(self, A, n): ans = 0 for i in range(1, n): for j in range(i): if A[j] &lt;= A[i]: ans += A[j] return ans# 运行时间：100ms# 占用内存：3156k 字符串通配题目描述题目链接 对对于字符串A，其中绝对不含有字符’.’和’’。再给定字符串B，其中可以含有’.’或’’，’’字符不能是B的首字符，并且任意两个’’字符不相邻。exp中的’.’代表任何一个字符，B中的’’表示’’的前一个字符可以有0个或者多个。请写一个函数，判断A是否能被B匹配。给定两个字符串A和B,同时给定两个串的长度lena和lenb，请返回一个bool值代表能否匹配。保证两串的长度均小于等于300。 测试样例 “abcd”,4,”.*”,2返回：true 代码 在这一题中，B仅由.和组成，所以只需要考虑.和的个数就能够ac123456789101112131415161718# -*- coding:utf-8 -*-class WildMatch: def chkWildMatch(self, A, lena, B, lenb): dotcount = B.count('.') starcount = B.count('*') if starcount == 0: # 如果没有*，则.的个数必须和lena相同才返回Ture，否则返回False if dotcount == lena: return True else: return False else: # 如果有*，因为*可以匹配0或多个，所以只需要(dotcount - starcount) &lt;= lena 就返回Ture，否则返回False if (dotcount - starcount) &lt;= lena: return True else: return False# 运行时间：20ms# 占用内存：3156k]]></content>
      <categories>
        <category>nowcoder</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nowcoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nowcoder(2):二分查找; 首个重复字符; 血型遗传检测; 串的模式匹配]]></title>
    <url>%2F2017%2F04%2F08%2Fnowcoder-2-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE-%E9%A6%96%E4%B8%AA%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6-%E8%A1%80%E5%9E%8B%E9%81%97%E4%BC%A0%E6%A3%80%E6%B5%8B-%E4%B8%B2%E7%9A%84%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[二分查找题目描述题目链接 对于一个有序数组，我们通常采用二分查找的方式来定位某一元素，请编写二分查找的算法，在数组中查找指定元素。给定一个整数数组A及它的大小n，同时给定要查找的元素val，请返回它在数组中的位置(从0开始)，若不存在该元素，返回-1。若该元素出现多次，请返回第一次出现的位置。 测试样例 [1,3,5,7,9],5,3返回：1 代码 普通的二分，需要注意的是元素出现多次时返回第一次出现的位置。所以在找到元素后，继续向左查找第一次出现的位置。 1234567891011121314151617181920# -*- coding:utf-8 -*-class BinarySearch: def getPos(self, A, n, val): if n == 0: return -1 start = 0 end = n - 1 while (start &lt;= end): mid = (start + end) / 2 if val == A[mid]: for i in range(1, mid + 1): if A[mid - i] &lt; A[mid]: return mid - i + 1 return 0 elif val &lt; A[mid]: end = mid - 1 else: start = mid + 1 return -1 运行时间：50ms占用内存：3148k 在评论中看到另一种：在元素出现多次时，不是继续向左查找，而是end=mid，最后返回start指向的元素。 12345678910111213141516171819# -*- coding:utf-8 -*-class BinarySearch: def getPos(self, A, n, val): if n == 0: return -1 start = 0 end = n - 1 while (start &lt; end): mid = (start + end) / 2 if val == A[mid]: end=mid elif val &lt; A[mid]: end = mid - 1 else: start = mid + 1 if A[start]==val: return start return -1 运行时间：50ms占用内存：3148k 首个重复字符题目描述题目链接 对于一个字符串，请设计一个高效算法，找到第一次重复出现的字符。给定一个字符串(不一定全为字母)A及它的长度n。请返回第一个重复出现的字符。保证字符串中有重复字符，字符串的长度小于等于500。 测试样例 “qywyer23tdd”,11返回：y 代码 用字典记录，如果出现过就返回。 12345678910# -*- coding:utf-8 -*-class FirstRepeat: def findFirstRepeat(self, A, n): re = &#123;&#125; for k in A: if k in re: return k else: re[k] = 0 #只是将k放入字典中，不一定=0（等于多少对答案无影响） 运行时间：20ms占用内存：3156k 血型遗传检测题目描述题目链接 血型遗传对照表如下 父母血型 子女会出现的血型 子女不会出现的血型 O与O O A,B,AB A与O A,O B,AB A与A A,O B,AB A与B A,B,AB,O —— A与AB A,B,AB O B与O B,O A,AB B与B B,O A,AB B与AB A,B,AB O AB与O A,B O,AB AB与AB A,B,AB O 请实现一个程序，输入父母血型，判断孩子可能的血型。给定两个字符串father和mother，代表父母的血型,请返回一个字符串数组，代表孩子的可能血型(按照字典序排列)。 测试样例 ”A”,”A”返回：[”A”,“O”] 代码 总结了一下，一共就三种情况：（注意题目中说了要按字典序排序） 含AB（AB与O是特例），则孩子可能血型是[‘A’, ‘AB’, ‘B’]，特例（AB与O）则去掉’AB’这种可能 A和B，则孩子可能血型是[‘A’,’AB’, ‘B’, ‘O’] 普通，则孩子可能血型是{father, mother, ‘O’}，这里注意去重 12345678910111213# -*- coding:utf-8 -*-class ChkBloodType: def chkBlood(self, father, mother): if 'AB' in [father, mother]: ans = ['A', 'AB', 'B'] if 'O' in [father, mother]: ans.remove('AB') elif 'A' in [father, mother] and 'B' in [father, mother]: ans = ['A','AB', 'B', 'O'] else: ans = list(&#123;father, mother, 'O'&#125;) return ans 运行时间：30ms占用内存：3156k 串的模式匹配题目描述题目链接 对于两个字符串A，B。请设计一个高效算法，找到B在A中第一次出现的起始位置。若B未在A中出现，则返回-1。给定两个字符串A和B，及它们的长度lena和lenb，请返回题目所求的答案。 测试样例 “acbc”,4,”bc”,2返回：2 代码 find实现 12345# -*- coding:utf-8 -*-class StringPattern: def findAppearance(self, A, lena, B, lenb): return A.find(B) 运行时间：30ms占用内存：3156k 老实写一遍：当B长度小于A时，返回-1；遍历A，如果A[i]与B[0]相等，则截取A[i:i + lenb]与B对比，如果相同就返回当前i 1234567891011# -*- coding:utf-8 -*-class StringPattern: def findAppearance(self, A, lena, B, lenb): if lena &lt; lenb: return -1 for i in range(0, lena - lenb + 1): if A[i] == B[0]: if A[i:i + lenb] == B: return i return -1 运行时间：10ms占用内存：3156k]]></content>
      <categories>
        <category>nowcoder</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nowcoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TensorFlow (1): 对评论进行分类]]></title>
    <url>%2F2017%2F03%2F24%2FTensorFlow-1-%E5%AF%B9%E8%AF%84%E8%AE%BA%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[对评论进行分类是按照TensorFlow练习1: 对评论进行分类来做的，所做的只是代码理解+重新实现。 原作者：@斗大的熊猫，地址：http://blog.topspeedsnail.com/archives/10399 关于 TensorFlow引用TensorFlow中文社区中的解释： TensorFlow™ 是一个采用数据流图（data flow graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，图中的线（edges）则表示在节点间相互联系的多维数据数组，即张量（tensor）。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个CPU（或GPU），服务器，移动设备等等。TensorFlow 最初由Google大脑小组（隶属于Google机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。 流程总结所使用的是python 3.6 + tensorflow 1.0.0，具体实现流程如下 下载数据集 neg.txt：5331条负面电影评论下载) pos.txt：5331条正面电影评论 下载) 构建lex词汇表 使用nltk.tokenize.word_tokenize()对数据集中数据进行分词，结果保存到lex 使用nltk.stem.WordNetLemmatizer对lex中词汇进行词形还原（例如cats还原为cat），结果更新到lex 使用nltk.FreqDist()进行词频统计（统计完成也相当于去除了重复词汇），结果保存到lex_freq 筛选lex_freq中词频在20到2000之间的词汇，结果更新到lex 评论向量化，结果保存到dataset 对于每条评论，向量features的长度为lex长度，初始化为全0。如果评论中的的词出现在lex中，则这个词对应位置的值改为1 使用clf表示评论的分类，[0,1]代表负面评论 [1,0]代表正面评论 对每条评论，将[features,clf]作为向量加入dataset 构建神经网络 构建具有两层hidden layer的前馈神经网络 每一层的w和b均由tf.random_normal()生成 使用dataset中数据训练神经网络 取70%作为训练数据集，30%作为测试数据集 dataset中，features作为x，clf作为y，每次取50条数据训练，共训练15次 参考资料对于TensorFlow看不懂的部分，参考TensorFlow学习笔记1：入门 Sessions最后需要关闭，以释放相关的资源；你也可以使用with模块，session在with模块中自动会关闭 抓取(Fetches)：为了抓取ops的输出，需要先执行session的run函数。然后，通过print函数打印状态信息。 123456789101112input1 = tf.constant(3.0)input2 = tf.constant(2.0)input3 = tf.constant(5.0)intermed = tf.add(input2, input3)mul = tf.mul(input1, intermed)with tf.Session() as sess: result = sess.run([mul, intermed]) print(result)# output:# [array([ 21.], dtype=float32), array([ 7.], dtype=float32)] 所有tensors的输出都是一次性 [连贯] 执行的。 填充(Feeds):TensorFlow也提供这样的机制：先创建特定数据类型的占位符(placeholder)，之后再进行数据的填充。例如下面的程序： 123456789input1 = tf.placeholder(tf.float32)input2 = tf.placeholder(tf.float32)output = tf.mul(input1, input2)with tf.Session() as sess: print(sess.run([output], feed_dict=&#123;input1:[7.], input2:[2.]&#125;))# output:# [array([ 14.], dtype=float32)] 如果不对placeholder()的变量进行数据填充，将会引发错误，更多的例子可参考MNIST fully-connected feed tutorial (source code)。 完整代码及执行结果根据个人习惯对原作者的代码进行了调整，具体如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137# coding=utf-8import nltkfrom nltk.tokenize import word_tokenizefrom nltk.stem import WordNetLemmatizerimport tensorflow as tfimport randomimport numpy as np# 获得分词结果def create_tokens(filename): tokens = [] lines = open(filename, 'r').readlines() for line in lines: tokens += word_tokenize(line) return tokens# 整理词汇# 使用lemmatize进行词性还原# 使用FreqDist进行词频统计，统计完成相当于去重完成# 沿用参考博客的词汇筛选方法：选词频&gt;20且&lt;2000的词放入词汇表lex中def create_lexicon(lex): wnl = WordNetLemmatizer() lex = [wnl.lemmatize(w) for w in lex] lex_freq = nltk.FreqDist(lex) print('词性还原及去重后词汇数：', len(lex_freq)) lex = [w for w in lex_freq if lex_freq[w] &gt; 20 and lex_freq[w] &lt; 2000] print('词频在20到2000之间的词汇数：', len(lex)) return lex# 评论向量化# 每条评论向量的维数是len(lex),初始化为全0，若评论中的词在lex中存在，则词汇对应位置为1# lex是词汇表，clf是评论对应的分类，[0,1]代表负面评论 [1,0]代表正面评论def create_dataset(filename, lex, clf): lines = open(filename, 'r').readlines() dataset = [] for line in lines: features = [0 for i in range(len(lex))] words = word_tokenize(line) wnl = WordNetLemmatizer() words = [wnl.lemmatize(w) for w in words] for word in words: if word in lex: features[lex.index(word)] = 1 dataset.append([features, clf]) return dataset# 构造神经网络# 此处构建的是具有两层hidden layer的前馈神经网络def neural_network(data, n_input_layer, n_layer_1, n_layer_2, n_output_layer): layer_1_w_b = &#123;'w_': tf.Variable(tf.random_normal([n_input_layer, n_layer_1])), 'b_': tf.Variable(tf.random_normal([n_layer_1]))&#125; layer_2_w_b = &#123;'w_': tf.Variable(tf.random_normal([n_layer_1, n_layer_2])), 'b_': tf.Variable(tf.random_normal([n_layer_2]))&#125; layer_output_w_b = &#123;'w_': tf.Variable(tf.random_normal([n_layer_2, n_output_layer])), 'b_': tf.Variable(tf.random_normal([n_output_layer]))&#125; # w·x+b layer_1 = tf.add(tf.matmul(data, layer_1_w_b['w_']), layer_1_w_b['b_']) layer_1 = tf.nn.relu(layer_1) # 激活函数 layer_2 = tf.add(tf.matmul(layer_1, layer_2_w_b['w_']), layer_2_w_b['b_']) layer_2 = tf.nn.relu(layer_2) # 激活函数 layer_output = tf.add(tf.matmul(layer_2, layer_output_w_b['w_']), layer_output_w_b['b_']) return layer_output# 使用数据训练神经网络# epochs=15，训练15次def train_neural_network(X, Y, train_dataset, test_dataset, batch_size, predict): cost_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=Y)) optimizer = tf.train.AdamOptimizer().minimize(cost_func) epochs = 15 with tf.Session() as session: session.run(tf.global_variables_initializer()) random.shuffle(train_dataset) train_x = train_dataset[:, 0] train_y = train_dataset[:, 1] for epoch in range(epochs): epoch_loss = 0 for i in range(len(train_x) - batch_size)[::batch_size]: batch_x = train_x[i:i + batch_size] batch_y = train_y[i:i + batch_size] _, c = session.run([optimizer, cost_func], feed_dict=&#123;X: list(batch_x), Y: list(batch_y)&#125;) epoch_loss += c print(epoch, 'epoch_loss :', epoch_loss) test_x = test_dataset[:, 0] test_y = test_dataset[:, 1] correct = tf.equal(tf.argmax(predict, 1), tf.argmax(Y, 1)) accuracy = tf.reduce_mean(tf.cast(correct, 'float')) print('准确率：', accuracy.eval(&#123;X: list(test_x), Y: list(test_y)&#125;))def main(): pos_file = 'pos.txt' neg_file = 'neg.txt' lex = [] lex += create_tokens(pos_file) #正面评论分词 lex += create_tokens(neg_file) print('分词后词汇数：', len(lex)) lex = create_lexicon(lex) # 词汇整理 dataset = [] # 保存评论向量化结果 dataset += create_dataset(pos_file, lex, [1, 0]) # 正面评论 dataset += create_dataset(neg_file, lex, [0, 1]) # 负面评论 print('总评论数：', len(dataset)) random.shuffle(dataset) dataset = np.array(dataset) test_size = int(len(dataset) * 0.3) # 取30%的数据作为测试数据集 train_dataset = dataset[:-test_size] test_dataset = dataset[-test_size:] n_input_layer = len(lex) n_layer_1 = 1000 n_layer_2 = 1000 n_output_layer = 2 batch_size = 50 # 每次取50条评论进行训练 X = tf.placeholder('float', [None, len(train_dataset[0][0])]) Y = tf.placeholder('float') predict = neural_network(X, n_input_layer, n_layer_1, n_layer_2, n_output_layer) train_neural_network(X, Y, train_dataset, test_dataset, batch_size, predict)if __name__ == '__main__': main() 执行结果1234567891011121314151617181920分词后词汇数： 230193词性还原及去重后词汇数： 18643词频在20到2000之间的词汇数： 1065总评论数： 106620 epoch_loss : 48756.88961031 epoch_loss : 11542.50440792 epoch_loss : 4327.359955943 epoch_loss : 2536.122864084 epoch_loss : 1304.263917555 epoch_loss : 366.1688461846 epoch_loss : 237.6544071667 epoch_loss : 78.98218581388 epoch_loss : 28.40572603919 epoch_loss : 37.686425014710 epoch_loss : 40.793654361911 epoch_loss : 65.478250921112 epoch_loss : 56.002171637713 epoch_loss : 81.349359417614 epoch_loss : 113.843462383准确率： 0.605378]]></content>
      <categories>
        <category>TensorFlow</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>MachineLearning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nowcoder(1):最大差值 棋子翻转]]></title>
    <url>%2F2017%2F03%2F19%2Fnowcoder-1-%E6%9C%80%E5%A4%A7%E5%B7%AE%E5%80%BC-%E6%A3%8B%E5%AD%90%E7%BF%BB%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[最大差值题目链接 题目描述有一个长为n的数组A，求满足0≤a≤b&lt;n的A[b]-A[a]的最大值。给定数组A及它的大小n，请返回最大差值。 测试样例： [10,5],2返回：0 最简单的思路是遍历两遍，求最大差值。时间复杂度O(n^2)。 123456789# -*- coding:utf-8 -*-class LongestDistance: def getDis(self, A, n): ma = 0 for i in range(n): for j in range(i + 1, n): ma = max(A[j] - A[i], ma) return ma 运行时间：150ms 占用内存：3156k 另一种只遍历一遍，使用start来记录起始位置，star始终是遍历过的最小值。时间复杂度O(n)。 12345678910# -*- coding:utf-8 -*-class LongestDistance: def getDis(self, A, n): start = A[0] ma = 0 for i in range(n): start = min(start, A[i]) ma = max(ma, A[i] - start) return ma 运行时间：40ms 占用内存：3156k 棋子翻转题目链接 题目描述 在4x4的棋盘上摆满了黑白棋子，黑白两色的位置和数目随机其中左上角坐标为(1,1),右下角坐标为(4,4),现在依次有一些翻转操作，要对一些给定支点坐标为中心的上下左右四个棋子的颜色进行翻转，请计算出翻转后的棋盘颜色。 给定两个数组A和f,分别为初始棋盘和翻转位置。其中翻转位置共有3个。请返回翻转后的棋盘。 测试样例： [[0,0,1,1],[1,0,1,0],[0,1,1,0],[0,0,1,0]],[[2,2],[3,3],[4,4]]返回：[[0,1,1,1],[0,0,1,0],[0,1,1,0],[0,0,1,0]] 思路很简单，但是写起来费事，非常容易出现幼稚的细节错误（尤其是像下面写的这么啰嗦）。 1234567891011121314151617181920# -*- coding:utf-8 -*-class Flip: def flipChess(self, A, f): for (a, b) in f: if a == 1: A[a][b - 1] = (A[a][b - 1] + 1) % 2 elif a == 4: A[a - 2][b - 1] = (A[a - 2][b - 1] + 1) % 2 else: A[a][b - 1] = (A[a][b - 1] + 1) % 2 A[a - 2][b - 1] = (A[a - 2][b - 1] + 1) % 2 if b == 1: A[a - 1][b] = (A[a - 1][b] + 1) % 2 elif b == 4: A[a - 1][b - 2] = (A[a - 1][b - 2] + 1) % 2 else: A[a - 1][b] = (A[a - 1][b] + 1) % 2 A[a - 1][b - 2] = (A[a - 1][b - 2] + 1) % 2 return A 运行时间：40ms 占用内存：3156k 代码太长了，改短一点： 1234567891011121314# -*- coding:utf-8 -*-class Flip: def flipChess(self, A, f): for (a, b) in f: if a &lt; 4: A[a][b - 1] = (A[a][b - 1] + 1) % 2 if a &gt; 1: A[a - 2][b - 1] = (A[a - 2][b - 1] + 1) % 2 if b &lt; 4: A[a - 1][b] = (A[a - 1][b] + 1) % 2 if b &gt; 1: A[a - 1][b - 2] = (A[a - 1][b - 2] + 1) % 2 return A 运行时间：30ms 占用内存：3160k]]></content>
      <categories>
        <category>nowcoder</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>nowcoder</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Learn Python the Hard Way读书笔记]]></title>
    <url>%2F2017%2F03%2F14%2FLearn-Python-the-Hard-Way%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[import test不用加.py 调用.py中的函数使用filename.functionname() pop(0)弹出list第一个，弹出后list中就没有了。再pop(0)就是原本第二个了 pop(-1)弹出列表最后一个。 sorted(words)对列表中元素进行排序 if,elif,else只要检查到一个True就可以停下来了。 列表list=[1,’a’,2]，可以赋值给一个变量。 for number in list:这里number在循环开始时就被定义了，每次循环被重新定义一次。 列表和数组是不一样的吗？取决于语言和实现方式。在python里都叫列表。 for i in range(1,3)其实是i=1,i=2。不包括3。 for i in range(1,3)：list.append()在列表尾部追加元素。(list.insert(0,a)在index=0位置添加) print(10*&#39; &#39;)打印10个空格。必须是一个字符串*整数 添加元素到列表尾：append。 del list[5] 删除该元素 list[2:4] 元素2 3 元组fibs=(1,2,3);print(fibs[1])打印出2.元组与列表区别：元组一旦创建就不能修改了。 词语间的空格可以不打印出来。%把参数传过去，如果有多个，使用括号和逗号 123456789x=40y=50print "I have",x,y,"days"print "I have%ddays" %xprint "I have %d %d days" %(x,y)#I have 40 50 days#I have40days#I have 40 50 days 防止使用非ASCII字符遇到编码错误，在最顶端加上： 123# coding=utf-8或者# -*- coding: utf-8 -*- python pep:https://www.python.org/dev/peps/pep-0263/ 123456789101112131415161718To define a source code encoding, a magic comment must be placed into the source files either as first or second line in the file, such as: # coding=&lt;encoding name&gt; or (using formats recognized by popular editors) #!/usr/bin/python # -*- coding: &lt;encoding name&gt; -*- or #!/usr/bin/python # vim: set fileencoding=&lt;encoding name&gt; :More precisely, the first or second line must match the regular expression &quot;^[ \t\v]*#.*?coding[:=][ \t]*([-_.a-zA-Z0-9]+)&quot;. 四舍五入 12345print round(1.73)print round(1.49)#2.0#1.0 %r用来做调试，会显示原始数据（raw data），而%s和其他符号则是用来向用户显示输出的。如下多了引号。 打印&#39;&#39;&#39;和&quot;&quot;&quot;都行，风格问题 123456789101112131415161718192021222324x="Hello World"print "It is %s" %xprint "It is %r" %x#It is Hello World#It is 'Hello World'#用双引号打印单引号因为python会用最有效的方式打印出字符串，而不是完全按照写的方式。%r是用来调试和排错的，没有必要打印出好看的格式。x="Hello\nWorld"print "It is %s" %xprint "It is %r" %xprint """HelloHello worldHello Hello"""#输出 注意前后各多一个空行It is HelloWorldIt is 'Hello\nWorld'HelloHello worldHello Hello 创建字符串单双引号都可以，不过一般单引号用来创建简短的字符串。 raw_input()输入提示 12345x=raw_input("Age? ")print x#Age? 18#18 input()函数会把输入的东西当作python代码进行处理，会有安全问题，应该避开这个函数。使用raw_input() 可以接受参数的脚本。运行时 12345678910111213# coding:utf-8from sys import argv # 导入sys模块module中的argvfilename,a,b=argv # 将argv解包(unpack)，与其将所有参数放到一个变量下，不如将每个参数赋值给一个变量。print filenameprint a+"~"+b# argv即参数变量（argument variable）,这个变量保存着运行python脚本时传递给python脚本的参数。# input&amp;output：# $ python tempp.py hello world# tempp.py# hello~world 将-作为用户提示放入变量，不需要重复写raw_input()中的提示。 1234567891011121314151617181920212223# coding=utf-8from sys import argvscript,username=argvprompt='&gt;'print "Hi,"+usernameprint "How old"age=raw_input(prompt)print "Do u like me"likes=raw_input(prompt)print """You have been %s years old!Game over!I'm very OK""" %age# $ python tempp.py Lcc# Hi,Lcc# How old# &gt;18# Do u like me# &gt;No# You have been 18 years old!# Game over!# I'm very OK 读取文件，先open，再read。把文件名写死不是一个好主意，所以使用argv或者raw_input() 12345678910111213141516171819202122232425# coding=utf-8from sys import argvscript,filename=argvf1=open(filename) #返回的不是文件内容，是"file object"，read之后才返回内容print f1print f1.read()f1.close() #处理完后将其关闭file_again=raw_input("Please input filename:\n&gt;")f2=open(file_again)print f2.readline()f2.close()# $ cat a.txt# Hello!# word!# $ python tempp.py a.txt# &lt;open file 'a.txt', mode 'r' at 0x012BD230&gt;# Hello!# word!# Please input filename:# &gt;a.txt# Hello! 文件相关命令 close:关闭文件。跟编辑器的”保存”是一个意思read:读取文件内容。可以把结果赋值给一个变量readline:读取文本文件的一行truncate:清空文件，慎用write(stuff):将stuff写入文件 如果写了open(filename).read()，就不用再close了，因为read（）一旦运行，文件就被python关掉了。 写文件open(filename,&quot;w&quot;).write(stuff)，“w”是必须的，因为open对文件的写入态度是安全第一，所以只有特别指定后才会进行写入操作。 exists 12345678# coding=utf-8from os.path import existsprint "Does a.txt exists?"print exists("a.txt") #将文件名作为参数，如果存在返回Ture，否则返回False# $ python tempp.py a.txt# Does a.txt exists?# True 运行run函数、调用call函数和使用use函数时一个意思 尽量避免变量的名称相同：全局变量和函数变量 每次运行.seek(0)就回到文件开始。seek函数的处理对象是字节而非行，seek(0)会转到文件的0byte(也就是第一个字节)的位置。open(&quot;test.txt&quot;).seek(0) 运行readline会读取一行，让后将磁头移动到\n后面 为什么python中for循环可以使用未定义的变量？ 循环开始时变量就被定义了，每次循环都会被重新定义一次。 判断字符串s中是否有字母x，可以用if “x” in s: form sys import exit。exit(0)可以中断某个程序，正常退出。exit(1)表示发生错误。 for x,y in mydict.items(): Python dict.get()方法 get()方法返回给定键的值。如果键不可用，则返回默认值None。语法：以下是get()方法的语法：dict.get(key, default=None)参数：key — 这是要搜索在字典中的键。default — 这是要返回键不存在的的情况下默认值。返回值：该方法返回一个给定键的值。如果键不可用，则返回默认值为None。例子： 1234567dict = &#123;'Name': 'Zara', 'Age': 27&#125;print "Value : %s" % dict.get('Age')print "Value : %s" % dict.get('Sex', "Never")#Value : 27#Value : Never 类，为什创建init或者别的类函数时要多加一个self变量？ 如果不加self，那么lyrics=”Happy”这样的代码意义就不明确了，它指的可能是实例lyrics属性，也可能是一个叫做lyrics的局部变量。有了self.lyrics，就清楚地知道这指的是实例的属性self.lyrics 12345678910111213141516171819202122232425# coding=utf-8class Song(object): """docstring for Song""" def __init__(self, lyrics): self.lyrics = lyrics def sing_me_a_song(self): for line in self.lyrics: print linehappy_baby=Song(["Happy boy","Happy girl","Over"])bulls_on_parade=Song(["They rally around the family","With pockets full of shells"])happy_baby.sing_me_a_song()bulls_on_parade.sing_me_a_song()# $ python tempp.py# Happy boy# Happy girl# Over# They rally around the family# With pockets full of shells]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刷题使用过的python小技巧]]></title>
    <url>%2F2017%2F03%2F14%2F%E5%88%B7%E9%A2%98%E4%BD%BF%E7%94%A8%E8%BF%87%E7%9A%84python%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[在刷题的过程中，使用了一些python常用的技巧，汇总如下（出处或更详细的解释会在小标题下方标明）。 字符串replace str.replace(old, new[, max])，其中，old — 将被替换的子字符串；new — 新字符串，用于替换old子字符串；max — 可选字符串, 替换不超过 max 次。并且使用replace，不改变原字符串。12345678s='abcb'print s.replace('b','x')#axcxprint s.replace('b','x',1)#axcbprint s#abcb''' strip去空格或字符 去掉字符串前后空格，可以使用strip，lstrip，rstrip方法。其中strip表示去除前后的空格，而不会去除字符串中间的空格。 123456789a='aa b cd'.center(30)print '\''+a+'\''#' aa b cd 'print '\''+a.lstrip()+'\''#'aa b cd 'print '\''+a.rstrip()+'\''#' aa b cd'print '\''+a.strip()+'\''#'aa b cd' 这三个方法默认是去掉空格，也可以通过参数去掉其他字符，等价于replace(s,&#39;&#39;)。不同的是strip只有一个参数，不能设置最大删除次数。 123456789a='aa b cd'print a.replace('a','')# b cdprint a.replace('a','',1)#a b cdprint a.strip('a')# b cdprint a.strip('a',1)#TypeError: strip() takes at most 1 argument (2 given) 如果需要去除字符串中间空格，可以先split()，再join 123a='aa b cd'print ''.join(a.split())#aabcd 注意：join只能连接字符串列表！不能连接整数列表。对整数列表先转换为字符串列表。 12345x=[1,2,3]print ''.join(x)#TypeError: sequence item 0: expected string, int foundprint ''.join(map(str,x))#123 判断字符串是否为整数或字母isalnum s.isdigit()判断是否为数字，s.isalpha()判断是否为字母，s.isalnum()判断是否为数字或字母。注意:这里有括号。 与filter结合能够筛选出字符串中的整数、字母、整数字母构成的串。注意，这里无括号。123456789101112131415161718192021print '123'.isdigit()#Trueprint '123a'.isdigit()#Falseprint '123a'.isdigit#&lt;built-in method isdigit of str object at 0x017394C0&gt;print 'abc1'.isalpha()#Falseprint 'abc1'.isalnum()#Trueprint 'abc#1'.isalpha()#Falses='dade142.;!0142f[.,]ad'print filter(str.isdigit,s)#1420142print filter(str.isalpha,s)#dadefadprint filter(str.isalnum,s)#dade1420142fad 不使用int将字符串转为整数 使用 evel(s)-evel(&#39;0&#39;) evel(s)将字符串转为整数（例如’1234’转为1234） eval的功能是将字符串str当成有效的表达式来求值并返回计算结果。在python中，’9’-‘0’会报错，但是 evel(‘9’)-evel(‘0’)=9 全排列permutations参考PYTHON-进阶-ITERTOOLS模块小结 itertools.permutations(iterable[, r])创建一个迭代器，返回iterable中所有长度为r的项目序列，如果省略了r，那么序列的长度与iterable中的项目数量相同：返回p中任意取r个元素做排列的元组的迭代器12345678import itertoolsprint itertools.permutations('123',3)#&lt;itertools.permutations object at 0x016CAE70&gt;print list(itertools.permutations('123',3))#[('1', '2', '3'), ('1', '3', '2'), ('2', '1', '3'), ('2', '3', '1'), ('3', '1','2'), ('3', '2', '1')]for x in list(itertools.permutations('123',3)): print ''.join(x),#123 132 213 231 312 321 列表及字典去除列表中重复元素参考：Python去除列表中重复元素的方法 set如果re是列表 [[1, 3], [1, 3], [3, 5]]，set(re) 报错 TypeError: unhashable type: &#39;list&#39;，将列表内改为()则成功，例如 set([(1,2),(1,2),(1,3)])=set([(1, 2), (1, 3)]) 123456l1 = [1,4,5,6,2,3,1,3,5,3]print set(l1)#set([1, 2, 3, 4, 5, 6])l2 = list(set(l1))print l2#[1, 2, 3, 4, 5, 6] 还有一种据说速度更快的，没测试过两者的速度差别 123l1 = [1,4,5,6,2,3,1,3,5,3]print &#123;&#125;.fromkeys(l1).keys()#[1, 2, 3, 4, 5, 6] 这两种都有个缺点，祛除重复元素后排序变了。如果想要保持他们原来的排序，使用list类的sort方法 12345l1 = [1,4,5,6,2,3,1,3,5,3]l2 = list(set(l1))l2.sort(key=l1.index)print l2#[1, 4, 5, 6, 2, 3] 也可以按照如下的方式写 1234l1 = [1,4,5,6,2,3,1,3,5,3]l2 = sorted(set(l1),key=l1.index)print l2#[1, 4, 5, 6, 2, 3] 还可以使用最普通的遍历 1234567l1 = [1,4,5,6,2,3,1,3,5,3]l2 = []for x in l1: if x not in l2: l2.append(x)print l2#[1, 4, 5, 6, 2, 3] 遍历也可以按照如下的方式写 12345l1 = [1,4,5,6,2,3,1,3,5,3]l2=[][l2.append(x) for x in l1 if x not in l2]print l2#[1, 4, 5, 6, 2, 3] 统计元素出现次数 最简单的方法是从collections引入Counter包，出现频度最高的元素会默认在前面。可用dict()操作符将其转换为一个普通的dict来进行额外处理(转成dict并不是按出现频度排序的)。123456from collections import Counterl1 = [1,4,5,6,2,3,1,3,5,3]print Counter(l1)#Counter(&#123;3: 3, 1: 2, 5: 2, 2: 1, 4: 1, 6: 1&#125;)print dict(Counter(l1))#&#123;1: 2, 2: 1, 3: 3, 4: 1, 5: 2, 6: 1&#125; 列表排序参考python sort、sorted高级排序技巧 先对第一个数排序，再对第二个数排序。12345678from operator import itemgetterdata=[[1,3],[1,2],[2,3],[1,1],[3,1],[2,2]]print sorted(data,key=itemgetter(0))#[[1, 3], [1, 2], [1, 1], [2, 3], [2, 2], [3, 1]]print sorted(data,key=itemgetter(1))#[[1, 1], [3, 1], [1, 2], [2, 2], [1, 3], [2, 3]]print sorted(data,key=itemgetter(0,1))#[[1, 1], [1, 2], [1, 3], [2, 2], [2, 3], [3, 1]] 字典排序参考深入Python(1): 字典排序 关于sort()、reversed()、sorted() 函数原型：sorted(dic,value,reverse) 解释：dic为比较函数，value 为排序的对象（这里指键或键值），reverse：注明升序还是降序，True—降序，False—升序（默认） 123dic = &#123;'a':31, 'bc':5, 'c':3, 'asd':4, '33':56, 'd':0&#125;print sorted(dic.iteritems(), key=lambda d:d[1], reverse = False ) #[('d', 0), ('c', 3), ('asd', 4), ('bc', 5), ('a', 31), ('33', 56)] dic.iteritems()，返回字典键值对的元祖集合key=lambda d:d[1] 是将键值(value)作为排序对象。 其他import math math.ceil(1.2)=2.0 math.floor(1.6)=1.0 round(1.2)=1.0 round(1.6)=2.0 math.pi=3.141592653589793 math.sqrt(4)=2.0 下取整不一定import math ,math.floor(3.5)可以直接int(3.5) python2整数相除division在python3中不需要考虑这个问题。在python2中进行两个整数相除的时候，在默认情况下都是只能够得到整数的结果，而在需要进行对除所得的结果进行精确地求值时，想在运算后即得到浮点值，需要在进行除法运算前导入一个实除法的模块from __future__ import division，即可在两个整数进行相除的时候得到浮点的结果。 字符和ASCII转换参考：Python字符和字符值(ASCII或Unicode码值)转换方法 ASCII码（0~255范围） ord(‘A’)：将字符转换为对应的ASCII数值，即‘A’—&gt;65 chr(65)：将数值转换为对应的ASCII字符，即65—&gt;’A’ 按位与或非在python中，按位操作不需要转化成二进制，可直接使用整数操作。 按位与 ( bitwise and of x and y )&amp; 举例： 5&amp;3 = 1 解释： 101 11 相同位仅为个位1 ，故结果为 1 按位或 ( bitwise or of x and y )| 举例： 5|3 = 7 解释： 101 11 出现1的位是 1 1 1，故结果为 111 按位异或 ( bitwise exclusive or of x and y )^ 举例： 5^3 = 6 解释： 101 11 对位相加(不进位)是 1 1 0，故结果为 110 按位反转 (the bits of x inverted )~ 举例： ~5 = -6 解释： 将二进制数+1之后乘以-1，即~x = -(x+1)，-(101 + 1) = -11012345678&gt;&gt;&gt; 3&amp;51&gt;&gt;&gt; 3|57&gt;&gt;&gt; 3^56&gt;&gt;&gt; ~5-6 把if else写到一行 常规写法（只是举例，并不是要求最大值，如果要求最大值c=max(a,b)就ok了） 1234567a,b,c=1,2,3if a&gt;b: c=aelse: c=bprint c#2 表达式写法 1234a,b,c=1,2,3c=a if a&gt;b else bprint c#2 二维列表写法 1234a,b,c=1,2,3c=[b,a][a&gt;b]print c#2 print格式参考跟老齐学Python之print详解 %2d表示占2位，右对齐。注意逗号位置1234567a=[[1,2,3],[4,5,6]]for i in range(2): for j in range(3): print "%2d" %a[i][j], print ""# 1 2 3# 4 5 6 Tipspython的有些写法与其它不同，偶尔容易记混淆，以下是记错过的。 不支持i++(需要写成i+=1)，不支持a&gt;b?a:b 次方：2**3=8（^表示异或） mylist.insert(0,x)从索引0开始插入，再也不用[::-1]了 交换两个值：a,b=b,a ntimes=list1.count(&quot;RL&quot;)数字符串中有多少个RL list1.find(&quot;RL&quot;,start)，从start开始找RL，返回索引 sorted(times)排序 sum([1,2,3])列表求和 字符串中的字符不能直接赋值，可以使用切片来改变值。 字符串不能直接交换(a,b=b,a)，需要首先list(s)，再交换，最后join 多个变量赋值可以写一行a,b,c=1,2,3 二维列表：book=[[0 for i in range(4)] for j in range(5)] 5行4列 97%3=1 -97%3=2 在使用sorted过程中，sorted[&#39;6&#39;,&#39;534&#39;]=[&#39;534&#39;,&#39;6&#39;]。要注意转换 报错TypeError: expected a character buffer object，在向文件中写入数据时，要求数据格式为str类型，比如：outputFileHandler.write(0)参数为Int类型，则会引发类似错误。解决方法：将非str数据，强制转换为str类型，如上改为:outputFileHandler.write(str(0)) list.remove(ele)只能删除第一个匹配的 log(8)/log(2)=log2(8)=3，位数多了在要求精确计算的情况下就得换方法，例如：0.9999999999999999999直接等于1。在刷题要求精度时需考虑这一点，适当选择计算方法。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Codeforces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[codeforces（4）：659A 656A 634A]]></title>
    <url>%2F2016%2F10%2F23%2Fcodeforces-4%2F</url>
    <content type="text"><![CDATA[659A. Round House 题目地址 http://codeforces.com/problemset/problem/659/A 题目大意 一个圆房子，有n个入口，1到n顺时针排列。小明现在在a入口，问经过b个入口小明在哪个入口。b为正表示顺时针走，b为负逆时针。 输入输出 input6 2 -5output3input5 1 3output4input3 2 7output3 分析 逆时针经过b个入口（-b），表示顺时针经过(n-b)%n个入口。所以此刻在a+(n+b)%n入口，注意这个值有可能&gt;n，所以需要模n。 相关代码 12345n,a,b=map(int,raw_input().split())ans=a+(n+b)%nif ans&gt;n: ans=ans%nprint ans 656A. Da Vinci Powers 题目地址 http://codeforces.com/problemset/problem/656/A 题目大意 输入a(0 ≤ a ≤ 35)，输出一个整数。 输入输出 input3output8input10output1024input35output33940307968 分析 并不是求2的阶乘Da Vinci在计算2的13次方时，使用4096*2=8192,少进了一位，变成8092，后面的直接乘以2就都是错的 相关代码 123456n=int(raw_input())x=8092if n&lt;13: print 2**nelse: print 2**(n-13)*x 634A. Island Puzzle 题目地址 http://codeforces.com/problemset/problem/634/A 题目大意 有一个环形岛屿链，其中岛屿编号从1到n。给出这n个岛上雕像的个数，以及期望的雕像个数，问能不能通过移动雕像达到期望。在这n个岛中，只有一个岛上没有雕像，移动规则：每次只能把雕像移到雕像数为0的岛上。 输入输出 input31 0 22 0 1outputYESinput21 00 1outputYESinput41 2 3 00 3 2 1outputNO 分析 只能往没有雕像的岛屿移动，所以只有0在不停移动，这些岛屿中雕像数的相对位置是不变的。ai存当前雕像序列，bi存期望雕像序列，将0从序列中删除。temp=ai.index(bi[0])定位bi[0]在ai中的位置，bi序列只可能是ai[temp:]+ai[:temp]。 相关代码 12345678910111213141516def func(): n=int(raw_input()) ai=map(int,raw_input().split()) bi=map(int,raw_input().split()) del ai[ai.index(0)] del bi[bi.index(0)] temp=ai.index(bi[0]) ai=ai[temp:]+ai[:temp] for i in range(n-1): if ai[i]!=bi[i]: print "NO" return print "YES" returnfunc()]]></content>
      <categories>
        <category>codeforces</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Codeforces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[codeforces（3）：727A 724A 722A]]></title>
    <url>%2F2016%2F10%2F22%2Fcodeforces-3%2F</url>
    <content type="text"><![CDATA[727A. Transformation: from A to B 题目地址 http://codeforces.com/problemset/problem/727/A 题目大意 给2个数a,b，判断能不能通过以下两个步骤从a变换到b：(1) replace the number x by 2·x;(2) replace the number x by 10·x + 1如果不能输出”NO”，如果能，输出3行：”YES”；变换序列的长度；变换序列 输入输出 input2 162outputYES52 4 8 81 162input4 42outputNOinput100 40021outputYES5100 200 2001 4002 40021 分析 从b往a推：如果b是偶数，必然是通过变换(1)得到的；如果b是奇数，则只能通过(2)得到。如果b是奇数，且b-1不能被10整除，则直接输出”NO”。 相关代码 12345678910111213141516171819202122a,b=map(int,raw_input().split())outputs=[b]num=1while b&gt;a: if b%2==0: b=b/2 outputs.append(b) num+=1 else: if (b-1)%10==0: b=(b-1)/10 outputs.append(b) num+=1 else: breakif a==b: print "YES" print num for x in outputs[::-1]: print x,else: print "NO" 724A. Checking the Calendar 题目地址 http://codeforces.com/problemset/problem/724/A 题目大意 给出一周中的两天（星期几），判断能否分别出现在非闰年的某一个月的第一天，以及下个月的第一天，这两个月必须在同一年。非闰年每个月的天数分别为：31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31。 输入输出 inputmondaytuesdayoutputNOinputsundaysundayoutputYESinputsaturdaytuesdayoutputYES 分析 根据天数来判断。一年的最后一个月是31天，很多个月都是31天，所以“这两个月必须在同一年”这个条件对解题没有限制。天数只有28,30,31三种情况：经过28天，星期几不变，即a==b是可以满足条件的，经过30天，星期几往后数2天，同理，31往后数3天。为了方便计算，构建列表，用index将星期几映射为整数。 相关代码 1234567letters=["monday", "tuesday", "wednesday", "thursday", "friday", "saturday", "sunday"]a=letters.index(raw_input())b=letters.index(raw_input())if a==b or (a+2)%7==b or (a+3)%7==b: print "YES"else: print "NO" 722A. Broken Clock 题目地址 http://codeforces.com/problemset/problem/722/A 题目大意 校正时钟：指明是12小时制还是24小时制，给出一个时间，修改尽量少的位数来使时间显示达到要求。有多种答案时给出一个答案。校正标准：In 12-hours format hours change from 1 to 12, while in 24-hours it changes from 0 to 23. In both formats minutes change from 0 to 59. 输入输出 input2417:30output17:30input1217:30output07:30input2499:99output09:09 分析 “时”部分分情况讨论；“分”部分如果&gt;=60，则将第一位改为’0’ 相关代码 123456789101112131415161718192021n=int(raw_input())time=raw_input().split(':')h=int(time[0])m=int(time[1])if m&gt;=60: time[1]='0'+time[1][1]if n==24: if h&gt;23: time[0]='0'+time[0][1]else: if h==0: time[0]='10' elif h&gt;12: if time[0][1]=='0': time[0]='10' else: time[0]='0'+time[0][1]print time[0]+':'+time[1]]]></content>
      <categories>
        <category>codeforces</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Codeforces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[codeforces（2）：732A 731A 712A]]></title>
    <url>%2F2016%2F10%2F22%2Fcodeforces-2%2F</url>
    <content type="text"><![CDATA[732A. Buy a Shovel 题目地址 http://codeforces.com/problemset/problem/732/A 题目大意 某人去买大铁锹，口袋有无数个10元硬币，以及1个r元硬币 (1 ≤ r ≤ 9)。已知大铁锹的单价k和r，求至少买几把锹能不找钱。 输入输出 input117 3output9input237 7output1input15 2output2 分析 最后一位（“个”位）对上就行。例如单价117只要7*i的个位数是3或者0，剩余的钱用10元硬币支付就可以不找钱。最少买1把锹（题目要求），最多买10把（全用10元硬币支付）。 相关代码 123456k,r=map(int,raw_input().split())t=k%10for i in range(1,11): if t*i%10==0 or t*i%10==r: print i break 731A. Night at the Museum 题目地址 http://codeforces.com/problemset/problem/731/A 题目大意 一个大轮子上顺时针写着a-z，可以顺时针或逆时针转，初始位置是a。输入一个字符串，问最少转多少格。 输入输出 inputzeusoutput18inputmapoutput35inputaresoutput34 分析 把字符’a’加到输入字符串最前面，遍历这个字符串，如果相邻俩字符的差temp大于13，则逆时针转，走的格数是26-ttemp。 相关代码 12345678s='a'+raw_input()ans=0for i in range(1,len(s)): temp=abs(ord(s[i])-ord(s[i-1])) if temp&gt;13: temp=26-temp ans+=tempprint ans 712A. Memory and Crow 题目地址 http://codeforces.com/problemset/problem/712/A 题目大意 给出n个数：a1,a2,…,an,已知ai = bi - b(i + 1) + b(i + 2) - b(i + 3)….，求bi。例如在输入输出第一个例子中，6 = 2 - 4 + 6 - 1 + 3，- 4 = 4 - 6 + 1 - 3。 输入输出 input56 -4 8 -2 3output2 4 6 1 3input53 -2 -1 5 6output1 -3 4 11 6 分析 找规律发现，a1+a2=b1，a2+a3=b2，… ，an=bn 相关代码 12345n=int(raw_input())ai=map(int,raw_input().split())for i in range(n-1): print ai[i]+ai[i+1],print ai[n-1]]]></content>
      <categories>
        <category>codeforces</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Codeforces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Codeforces（1）：723A 716A 714A]]></title>
    <url>%2F2016%2F10%2F22%2Fcodeforces-1%2F</url>
    <content type="text"><![CDATA[723A. The New Year: Meeting Friends 题目地址 http://codeforces.com/problemset/problem/723/A 题目大意 三个朋友住在一条线上，给出这三个点位置。他们要在某一个点庆祝新年，求总距离的最小值。 输入输出 input7 1 4output6input30 20 10output20 分析 三个数排序，最小距离=最大值-最小值 相关代码 12xi=sorted(map(int,raw_input().split()))print xi[2]-xi[0] 716A. Crazy Computer 题目地址 http://codeforces.com/problemset/problem/716/A 题目大意 有n个词，如果两个词输入时间间超过c，那么屏幕清空。给出n,c以及每个词输入的时刻，求屏幕上最后有多少个词。 输入输出 input6 51 3 8 14 19 20output3input6 11 3 5 7 9 10output2 分析 遍历一遍，如果两个时刻相差大于c，那么计数器置为1，否则计数器+1。 相关代码 12345678910n,c=map(int,raw_input().split())ti=map(int,raw_input().split())num=1for i in range(1,n): if ti[i]-ti[i-1]&gt;c: num=1 else: num+=1print num 714A. Meeting of Old Friends 题目地址 http://codeforces.com/problemset/problem/714/A 题目大意 给出5个数：l1, r1, l2, r2, k，A将在l1到r1时段清醒，B将在l2到r2时段去拜访A，时刻k他俩是不能一起的。求他们能在一起玩多久。 输入输出 input1 10 9 20 1output2input1 100 50 200 75output50 分析 两个集合求交集的问题，分情况讨论。k如果在交集之中，最后结果需要-1。 相关代码 12345678910111213141516l1,r1,l2,r2,k=map(int,raw_input().split())if l2&gt;r1 or r2&lt;l1: print 0else: if r2&lt;=r1: temp=max(l1,l2) ans=r2-temp+1 if k&gt;=temp and k&lt;=r2: ans-=1 else: temp=max(l1,l2) ans=r1-temp+1 if k&gt;=temp and k&lt;=r1: ans-=1 print ans]]></content>
      <categories>
        <category>codeforces</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Codeforces</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git基础]]></title>
    <url>%2F2016%2F07%2F16%2Fgit%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[将内容添加到远程仓库 在github上Create a new repository 在本地新建文件夹test，里面存放需要放到github上的内容。 在test文件夹下： 12345git initgit remote add origin git@github.com:ywtail/repositoryName.gitgit add .git commit -a -m 'test'git push -u origin master 注意：test目录中必须有文件，需要先add,commit再push -u origin master。否则会报错：error: src refspec master does not match any. 以后对文件夹中内容修改后提交：123git add .git commit -a -m 'description'git push 其它问题如果在push -u origin master后报错如下12ssh: connect to host github.com port 22: Bad file numberfatal: Could not read from remote repository. 则可以通过以下方案解决： 该方案来自：http://stackoverflow.com/questions/7144811/git-ssh-error-connect-to-host-bad-file-number中文版：http://qa.helplib.com/221029 在.ssh文件夹中新建文件config，即创建文件~ / . ssh / config在config中贴入以下代码并保存：123456Host github.comUser gitHostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443 完成后再push -u origin master就成功了。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css绘制圆、三角形]]></title>
    <url>%2F2016%2F06%2F22%2Fcss%E7%BB%98%E5%88%B6%E5%9C%86%E3%80%81%E4%B8%89%E8%A7%92%E5%BD%A2%2F</url>
    <content type="text"><![CDATA[border-radius与圆（弧） border-radius 用来设置边框圆角。当使用一个半径时确定一个圆形；当使用两个半径时确定一个椭圆，这个(椭)圆与边框的交集形成圆角效果。 border-radius基础 基本语法：border-radius ： none | &lt;length&gt;{1,4} [/ &lt;length&gt;{1,4} ] &lt;length&gt;取值范围：由浮点数字和单位标识符组成的长度值。不可为负值。 简单说明：border-radius 是一种缩写方法。如果“/”前后的值都存在，那么“/”前面的值设置其水平半径，“/”后面值设置其垂直半径。如果没有“/”，则水平和垂直半径相等。另外其四个值是按照top-left、top-right、bottom-right、bottom-left的顺序来设置的其主要会有下面几种情形出现： 只有一个值，那么 top-left、top-right、bottom-right、bottom-left 四个值相等。 有两个值，那么 top-left 等于 bottom-right，并且取第一个值；top-right 等于 bottom-left，并且取第二个值。 有三个值，其中第一个值是设置top-left;而第二个值是 top-right 和 bottom-left 并且他们会相等,第三个值是设置 bottom-right。 有四个值，其中第一个值是设置 top-left 而第二个值是 top-right 第三个值 bottom-right 第四个值是设置 bottom-left。 举几个实例： border-radius： 2em 即 1234border-top-left-radius:2em;border-top-right-radius:2em;border-bottom-right-radius:2em;border-bottom-left-radius:2em; border-radius: 2em 1em 4em / 0.5em 3em 即 1234border-top-left-radius: 2em 0.5em;border-top-right-radius: 1em 3em;border-bottom-right-radius: 4em 0.5em;border-bottom-left-radius: 1em 3em; border-radius: 10px 15px 20px 30px / 20px 30px 10px 15px 即 1234border-top-left-radius: 10px 20px;border-top-right-radius: 15px 30px;border-bottom-right-radius: 20px 10px;border-bottom-left-radius: 30px 15px; border-radius画圆未进行处理时，div的边框是一个矩形。为了演示效果，我们画一个黄色的100px × 100px 的矩形。HTML相关代码如下：1&lt;div class="circle"&gt;&lt;/div&gt; CSS相关代码如下：12345.circle &#123; width: 100px; height: 100px; background-color: yellow;&#125; 效果如图： 圆 分析：对100px × 100px 的矩形来说，圆形即将每个角的水平半径和垂直半径都设置为50px，所以应在css文件中加入border-radius: 50px，即123456.circle &#123; width: 100px; height: 100px; background-color: yellow; border-radius: 50px;&#125; 效果如图： 1/4圆 分析：分析：对100px × 100px 的矩形来说，1/4圆即将某一个角的水平半径和垂直半径都设置为100px，这里我们设置右下角，在css文件中加入border-radius: 0 0 100px 0，即123456.circle &#123; width: 100px; height: 100px; background-color: yellow; border-radius: 0 0 100px 0;&#125; 效果如图： 其他圆（弧） 找到水平半径和垂直半径就可以，假设我们需要画地平线上刚升起的太阳。水平半径设为50px，垂直半径设为30px。123456.circle &#123; width: 100px; height: 100px; background-color: yellow; border-radius: 50px 50px 0 0/30px 30px 0 0;&#125; 效果如图:可以看到这并不是我们要的效果，这里需要注意将高度修改一下。因为这里我们设置的垂直半径为30px，所以将高度设置为30px以达到需要的效果。（画半圆的效果同理）123456.circle &#123; width: 100px; height: 30px; background-color: yellow; border-radius: 50px 50px 0 0/30px 30px 0 0;&#125; 效果如图： border与三角形怎么用 border 绘制三角形呢？首先我们梳理一下基础知识，知道 border 其实是由四部分组成的，通过将某些部分设置为透明来绘制三角形。 border基础 border 初始：首先我们设div的宽和高都为100px，为了演示效果，我们将border的宽度设的大一些，并给四边涂上不同的颜色。HTML相关代码如下：1&lt;div class="div1"&gt;&lt;/div&gt; css相关代码如下：123456.div1 &#123; width: 100px; height: 100px; border: 50px solid; border-color: #00BCD4 #FFEB3B #E91E63 #9E9E9E;&#125; 效果如下图。我们可以看到边框是由4个梯形组成的。 三角形怎么来？上图的梯形是由于div遮挡了三角形吗？如果我们设置div的宽和高都为0，能不能出现4个三角形呢？123456.div1 &#123; width: 0; height: 0; border: 50px solid; border-color: #00BCD4 #FFEB3B #E91E63 #9E9E9E;&#125; 效果如下图。 border-width border-width 属性如果单独使用的话是不会起作用的。需要先使用 border-style 属性（取值：solid等）来设置边框。border-width 简写属性为元素的所有边框设置宽度（默认值是medium），或者单独地为各边边框设置宽度。 border-width:thin;所有 4 个边框都是细边框 border-width:thin medium;上边框和下边框是细边框右边框和左边框是中等边框 border-width:10px medium thick;上边框是 10px右边框和左边框是中等边框下边框是粗边框 border-width:thin medium thick 10px;上边框是细边框右边框是中等边框下边框是粗边框左边框是 10px 宽的边框 举个例子:设border-width: 50px 20px，即123456.div1 &#123; width: 0; height: 0; border-style: solid; border-width: 50px 20px; border-color: #00BCD4 #FFEB3B #E91E63 #9E9E9E; 效果如下图。 border画三角形由上图可以看出，要想得到三角形，将其他的3个三角形设置为透明（transparent）的就ok了。123456.div1 &#123; width: 0; height: 0; border: 50px solid; border-color: transparent transparent #E91E63 transparent;&#125; 效果如下图。 可以看到上图是一个等腰直角三角形，如果需要锐角或钝角三角形，则调整border-width就可以。1234567.div1 &#123; width: 0; height: 0; border-style: solid; border-width: 50px 20px; border-color: transparent transparent #E91E63 transparent;&#125; 效果如下图。 其他图形 月牙最后来画个包大人的胎记吧。画两个圆，然后使用position调整。相关代码和效果图如下。12345678910111213141516.circle1 &#123; width: 100px; height: 100px; background-color: yellow; border-radius: 50px;&#125;.circle2 &#123; width: 100px; height: 100px; background-color: #fff; border-radius: 50px; position: relative; left: 25px; top: -110px;&#125; Pac-Mancss相关代码和效果图如下。1234567.div1 &#123; width: 0; height: 0; border: 50px solid; border-radius: 50px; border-color: yellow transparent yellow yellow;&#125; 更多图形见【转】纯CSS画的基本图形（矩形、圆形、三角形、多边形、爱心、八卦等） 参考 border-radius CSS3的圆角Border-radius CSS border-width 属性 用 CSS 实现三角形与平行四边形]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[css完全居中]]></title>
    <url>%2F2016%2F06%2F21%2Fcss%E5%AE%8C%E5%85%A8%E5%B1%85%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[列出两种方法备忘一下。主要参考如何只用CSS做到完全居中，英文原文在Absolute Centering in CSS。这是一篇很好的文章。 首先画一个矩形框来进行演示，为了截图效果，我们给body一个背景颜色。HTML相关内容如下：1234&lt;body&gt; &lt;div class="container"&gt; &lt;/div&gt;&lt;/body&gt; CSS相关内容如下：123456789body &#123; background-color: #999;&#125;.container &#123; background-color: #fff; width: 300px; height: 200px;&#125; 效果如图： 水平居中在css文件的.container中加上说明margin: auto。 123456.container &#123; background-color: #999; width: 300px; height: 200px; margin: auto;&#125; 效果如图： 完全居中 方法一设置position为absolute，具体如下。 123456789.container &#123; background-color: #fff; width: 300px; height: 200px; position: absolute; left: 50%; top: 50%; transform: translate(-50%,-50%);&#125; 方法二将position设置为absolute，将top,bottom,left,right都设置为0。 1234567891011.container &#123; background-color: #fff; width: 300px; height: 200px; margin: auto; position: absolute; top: 0; bottom: 0; left: 0; right: 0;&#125; 效果如图： 注意：在容器内完全居中将父元素的position设置为 relative。（经实测，父元素position: absolute也可以） 向左偏移令left:0; right:auto。 1234567891011.container &#123; background-color: #fff; width: 300px; height: 200px; margin: auto; position: absolute; top: 0; bottom: 0; left: 0; right: auto;&#125; 效果如图：]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用github展示项目主页]]></title>
    <url>%2F2016%2F06%2F03%2F%E4%BD%BF%E7%94%A8github%E5%B1%95%E7%A4%BA%E9%A1%B9%E7%9B%AE%E4%B8%BB%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[本文主要流程如下： 简单介绍git相关命令 使用github展示项目主页： 创建名为gh-pages的分支； 将要展示的内容放到gh-pages分支下（必须如此）； 访问 http://Github用户名.github.io/项目名。 多pc使用： 从github上克隆项目； 克隆分支； 将内容推送到gh-pages分支。 git相关命令12345678910111213查看分支：git branch创建分支：git branch &lt;name&gt;切换分支：git checkout &lt;name&gt;创建+切换分支：git checkout -b &lt;name&gt;合并某分支到当前分支：git merge &lt;name&gt;删除分支：git branch -d &lt;name&gt;查看远程分支 git branch -a 在学习使用分支的过程中发现，在本地删除了分支，但是github上依然存在，找了两个删除远程分支的方法。 123删除远程分支：git push origin :&lt;name&gt;删除远程分支：git push origin --delete &lt;name&gt; 使用github展示项目主页创建gh-pages分支 使用如下命令会给项目创建一个 gh-pages 分支并切换到该分支。其中，--orphan 表示该分支是全新的，不继承原分支的提交历史（默认 git branch gh-pages创建的分支会继承 master 分支的提交历史，所以就不纯净了）。 1git checkout --orphan gh-pages 接下来把新分支中的文件删掉（这一步可以不执行。这个命令会删除本地当前文件夹下所有内容，如果不想删就不执行这个。） 1git rm -rf . 注意：这里 git branch 是显示不出 gh-pages 分支的（需要做一次提交才行），不要着急，一直进行到push完毕才会显示的。 将要展示的内容放到gh-pages分支有以下两种方式： 直接把需要的拷贝过来(如果没有执行git rm -rf .可以直接提交，文件都在当前目录呢)，然后开始提交 123git add .git commit -a -m &quot;test&quot;git push origin gh-pages merge别的分支(例如merge master分支)，然后提交. 12git merge master #merge别的分支git push origin gh-pages #提交 注意： 必须将要展示的内容放到 gh-pages 分支下。 之前看的教程习惯使用git commit -m &quot;&lt;Explanation&gt;&quot;，但是如果在本地删除了文件，在github上依然存在。使用git commit -a -m &quot;&lt;Explanation&gt;&quot;只是多了-a，就能把删除行为加上，使github上显示和本地就完全相同。 第一次提交使用git push origin &lt;name&gt;这么长，以后直接git push就ok。 访问 访问 http://&lt;Github用户名&gt;.github.io/&lt;项目名&gt;就可以查看了。 多pc使用从github上clone知道仓库的地址，然后使用git clone命令克隆（Git支持多种协议，包括https，但通过ssh支持的原生git协议速度最快）。clone地址直接从github复制，格式大约如下。1git clone git@github.com:&lt;用户名&gt;/&lt;项目名&gt;.git 克隆分支git clone默认会把远程仓库整个给clone下来，但只会在本地默认创建一个master分支。所以首先查看有哪些分支，然后clone自己需要的分支（使用-t参数，它默认会在本地建立一个和远程分支名字一样的分支）。 12git branch -a #查看有哪些分支git checkout -t origin/&lt;分支名&gt; #clone分支 将内容推送到gh-pages分支本地更改后，将内容推送到gh-pages分支，就能够使用github展示项目主页。（最后可以将内容merge到master） 参考 深入 Github 主页 Git 分支 - 远程分支 廖雪峰：分支管理 Git clone远程分支]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网]]></title>
    <url>%2F2016%2F06%2F02%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[使用 XX-net 翻墙 科学上网。作者写的太详细了，按照这个里面的文档来就行。]]></content>
      <categories>
        <category>forfun</category>
      </categories>
      <tags>
        <tag>forfun</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 多pc同步（二）]]></title>
    <url>%2F2016%2F05%2F15%2Fhexo-2%2F</url>
    <content type="text"><![CDATA[因为有两台电脑，所以搜索了下多pc同步问题。这样，不论是重装系统，还是换机器，都能方便管理自己的博客。 首先介绍一下hexo和博客源文件之间的关系。 1.hexo帮助把博客发送到github，同时把md文件转换成网页文件。 2.hexo的安装编辑等都和github上显示的内容不是同一东西，也就是，用hexo生成发布了github博客后，hexo的那些文件是没有传到github上的，还是在本地，传到github上的只是由hexo生成的用来显示的网页文件。如果想两台电脑同时使用hexo进行同一博客维护，那么这两台电脑都得安装有hexo的，如果两台电脑只是单纯的把github上最后显示出来的文件clone下来是没有用的，而是要把第一台维护博客是的hexo的源文件clone下来（得先提交到github），再在同一份的hexo源文件中进行维护，然后再生成博客的网页文件。 举个栗子：hexo源文件就好比母本(本地的md文件)，而hexo deploy传到github上的只是母本的一个镜像(其实是网页文件)，我们要操作的时候在第二台电脑上要拿到母本，然后操作母本，那么第二台电脑再执行hexo deploy的时候就和第一台电脑一样了，如果第二台电脑拿到的是镜像，那怎么可能和第一台电脑一样进行维护呢？ 具体做法是：把hexo的文件上传到git托管云如github上，然后在第二台电脑要把这些hexo的源文件clone下来，因为这些源文件内还有了生成博客需要的md原始文件，所以只要有了源文件就可以再次生成博客展示的文件 所以在本文中，首先，将本台机器A中的内容推到github。 在github添加仓库，例如hexo。 将本台机器A中的内容推到github远程仓库中。 然后，在机器B将相关内容clone下来，完成后将最新内容推到github。在机器B操作流程如下： 安装git；添加ssh（参见hexo 简单搭建（一）。 在机器B上npm install -g hexo安装hexo。 在B上新建文件夹，从github中clone相关内容。 npm install安装依赖包。 写文章，做修改后将最新内容推到github远程仓库中。 具体如下。 在github添加仓库完成hexo 简单搭建（一），则已经安装好了git，也添加好了ssh。所以在本机A中，直接在github中添加远程仓库hexo。具体方法参见添加远程库。 将hexo推送到github介绍：在H:\hexo中有文件.gitignore，这个文件是hexo初始化带来的，作用是声明不被git记录的文件，.gitignore包含以下内容。123node_modules/public/.deploy*/ 使用github备份hexo，方法如下。 1.在H:\hexo中，右键选择Git Bash，输入如下，完成后会生成一个.git文件。1git init 2.输入如下。&lt;server&gt;是指在线仓库的地址（例如我的就是git@github.com:ywtail/hexo.git）。origin是本地分支,remote add操作会将本地仓库映射到云端。1git remote add origin &lt;server&gt; 3.输入如下，将内容推送到github。有疑问参见Git教程。123git add . #添加blog目录下所有文件，注意有个`.`（`.gitignore`声明过的文件不包含在内)git commit -m &quot;first commit&quot; #添加更新说明git push -u origin master #推送更新到云端服务器 完成后就能在github的对应仓库中看到推送的hexo相关内容了。 从github克隆换电脑后，重新安装git、node.js、添加ssh，任意目录下npm install -g hexo安装hexo。然后，新建一个文件夹hexo，在hexo下运行1234git initgit remote add origin &lt;server&gt; #将本地文件和云端仓库映射起来。这步不可以跳过git fetch --allgit reset --hard origin/master 其中，fetch是将云端所有内容拉取下来。reset则是不做任何合并处理，强制将本地内容指向刚刚同步下来的云端内容。 更新同步clone下来后使用npm install安装依赖包。完成后生成node_modules/等文件。 然后就可以自由地写博客了，写完后重新同步到github，方法如上。（git pull,git push） 参考 hexo和博客源文件之间的关系捋清 廖雪峰的Git教程 利用git解决hexo博客多PC间同步问题]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 简单搭建（一）]]></title>
    <url>%2F2016%2F05%2F14%2Fhexo-1%2F</url>
    <content type="text"><![CDATA[简单记录下搭建hexo的过程。 首先介绍一下本文中hexo搭建的大致流程： 完成准备工作：安装git；安装node.js；bash下hexo init安装hexo;bash下npm install安装依赖包。 本地查看：使用hexo g生成；使用hexo s打开服务器；在浏览器输入127.0.0.1:4000或localhost:4000查看。 部署到github：创建repository；添加ssh key；在hexo配置文件hexo_config.yml中修改，完成部署。 查看：浏览器访问yourname.github.io就可以查看了，看不到可以稍等几分钟。 写博客：创建博客hexo new &quot;testname&quot;；完成后hexo g生成，hexo s本地查看（修改）；定稿后hexo d发布。这样就可以在yourname.github.io查看到自己的博客了。 具体如下。 安装Git下载并安装。鼠标右键看到Git Bash说明安装成功。 安装Node.js下载，安装并配置环境变量。注意： 在官网下载的exe文件不能安装，会导致在安装hexo的过程中各种提示command not found，例如提示“sh: npm: command not found”。因此，直接点击“install”，保存.msi文件，再安装node.js。 安装hexo在任意位置点击鼠标右键，选择Git bash。输入以下命令： 1npm install -g hexo 创建hexo文件夹并安装依赖包在H:\hexo内右键，选Git bash。输入以下命令 12hexo initnpm install 本地查看输入以下命令后，在浏览器查看。端口为4000。（127.0.0.1:4000或localhost:4000） 12hexo generatehexo server generate也可简写为g，同理，server为s。 注意： 1.hexo s无效并出现如下提示信息时 12$ hexo sUsage: hexo &lt;command&gt; 使用以下命令安装server 1npm install hexo-server --save 2.打开localhost:4000，显示Cannot GET /重新npm install，就好了。 现在只能在本地查看，下面部署到github。 创建repository创建方法为+New repository —&gt; 输入Repository name —&gt; Create repository。注意： repository名字必须与github上名字一样！！即格式必须为yourname/yourname@github.com或yourname/yourname@github.io。 添加SSH key参照GitHub官网给出的方法。下面简单写一下。 1.检查电脑是否已经有SSH key在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到步骤3。或者用以下方式查看。 12$ ls -al ~/.ssh# Lists the files in your .ssh directory, if they exist 2.如果没有SSH key，则创建新的SSH key（Windows下打开Git Bash）。 12$ ssh-keygen -t rsa -b 4096 -C "your_email@example.com"# Creates a new ssh key, using the provided email as a label 觉得不需要设置密码就一路回车。完成成功后可以在用户主目录里找到.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露，id_rsa.pub是公钥，可以公开。 3.将.ssh文件中id_rsa.pub中的内容拷贝，添加到github。具体：在GitHub右上方点击头像，选择”Settings”，在右边的”Personal settings”侧边栏选择”SSH Keys”。接着粘贴key，点击”Add key”按钮。 部署编辑H:\hexo_config.yml。 1234deploy: type: git repository: https://github.com/yourname/yourname.github.io.git branch: master 执行以下命令完成部署。 12hexo ghexo d 其中，d为deploy。 休息一会，喝几口冷水，再在浏览器访问yourname.github.io就可以看到自己的博客了。 注意： 1.如果在执行hexo d时，报错如下（找不到git部署） 1ERROR Deployer not found: git 解决方法如下 1npm install hexo-deployer-git --save 再重新执行g，d即可访问。 2.如果执行hexo d时，提示如下 123456789*** Please tell me who you are.Run git config --global user.email "you@example.com" git config --global user.name "Your Name"to set your account's default identity.Omit --global to set the identity only in this repository. 按照上面的提示输入email和name。 12git config --global user.email "you@example.com"git config --global user.name "Your Name" 3.不论在创建repository时是yourname/yourname@github.com还是yourname/yourname@github.io，都必须访问yourname.github.io才能访问。yourname.github.com是不能够访问的。 写博客新建博客，在bash下输入以下命令就可以完成名为testname.md博客文件的新建，在H:\hexo\source\_posts可以找到。 1hexo new &quot;testname&quot; 写完博客后，使用如下命令生成并发表。 12hexo ghexo d 发表前可以使用hexo s本地查看一下，修改定稿后再hexo d发布。 参考 hexo系列教程：（二）搭建hexo博客 hexo你的博客 使用hexo和Github上创建自己的博客 廖雪峰的官方网站]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2016%2F05%2F13%2Fhello-world%2F</url>
    <content type="text"><![CDATA[这至少是第三次折腾hexo了，最早还是14年。仅仅是个记录，看看自己都折腾过什么。]]></content>
  </entry>
</search>
